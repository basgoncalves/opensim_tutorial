{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Git\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\code\n",
      "c:\\Git\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\n"
     ]
    }
   ],
   "source": [
    "import msk_modelling_python as msk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import opensim as osim\n",
    "from xml.etree import ElementTree as ET\n",
    "import c3d\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import xml.dom.minidom \n",
    "import scipy.signal as sig\n",
    "import neurokit2 as nk\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import scipy.stats as stats\n",
    "from scipy.interpolate import interp1d\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "one_dir_up = os.path.dirname(current_dir)\n",
    "print(one_dir_up)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kil yourself  (DONE)\n",
    "# Recover (DONE)\n",
    "# Reprocess EMG signals without max().max() (DONE)\n",
    "# Re-run calibrations (DONE)\n",
    "# Re-run simulations (DONE)\n",
    "# Plots again (DONE)\n",
    "# Check compare activations (DONE)\n",
    "# Add shaded area to plots from td crouch\n",
    "# Add PC levels to the plots legend \n",
    "# Bar plots for the mean muscle forces\n",
    "# compare CEINMS with SO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optional) Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"C:\\Git\\opensim_tutorial\\tutorials\\repeated_sprinting\\Simulations\\PC013\\trial3_r1\\Results_SO_and_MA\"\n",
    "file_mapping = {\n",
    "    '_MuscleAnalysis': 'MuscleAnalysis'\n",
    "}\n",
    "# loop through all files in the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        if any(substring in file for substring in file_mapping.keys()):\n",
    "            print(file)\n",
    "            new_file = file.replace(list(file_mapping.keys())[0], list(file_mapping.values())[0])\n",
    "            print(os.path.join(root, file))\n",
    "            \n",
    "            os.rename(os.path.join(root, file), os.path.join(root, new_file))\n",
    "            print(f\"Renamed {file} to {new_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class File:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.name = os.path.basename(path)\n",
    "        self.extension = os.path.splitext(path)[1]\n",
    "        \n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"\\033[93mFile not found: {path}\\033[0m\")\n",
    "            return        \n",
    "        \n",
    "        try:\n",
    "            endheader_line = self.find_file_endheader_line(path)\n",
    "        except:\n",
    "            print(f\"Error finding endheader line for file: {path}\")\n",
    "            endheader_line = 0\n",
    "        # Read file based on extension\n",
    "        try:\n",
    "            if self.extension == '.csv':\n",
    "                self.data = msk.pd.read_csv(path)\n",
    "            elif self.extension == '.json':\n",
    "                self.data = msk.bops.import_json_file(path)\n",
    "            elif self.extension == '.xml':\n",
    "                self.data = msk.bops.XMLTools.load(path)\n",
    "            else:\n",
    "                try:\n",
    "                    self.data = msk.pd.read_csv(path, sep=\"\\t\", skiprows=endheader_line)\n",
    "                except:\n",
    "                    self.data = None\n",
    "                    \n",
    "            # add time range for the data\n",
    "            try:\n",
    "                self.time_range = [self.data['time'].iloc[0], self.data['time'].iloc[-1]]\n",
    "                try:\n",
    "                    self.time_range = [self.data['Time'].iloc[0], self.data['Time'].iloc[-1]]\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                self.time_range = None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {path}\")\n",
    "            print(e)\n",
    "            self.data = None\n",
    "            self.time_range = None\n",
    "    def find_file_endheader_line(self, path):\n",
    "        with open(path, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if 'endheader' in line:\n",
    "                    return i + 1\n",
    "        return 0    \n",
    "    \n",
    "class Trial:\n",
    "    '''\n",
    "    Class to store trial information and file paths, and export files to OpenSim format\n",
    "    \n",
    "    Inputs: trial_path (str) - path to the trial folder\n",
    "    \n",
    "    Attributes:\n",
    "    path (str) - path to the trial folder\n",
    "    name (str) - name of the trial folder\n",
    "    og_c3d (str) - path to the original c3d file\n",
    "    c3d (str) - path to the c3d file in the trial folder\n",
    "    markers (str) - path to the marker trc file\n",
    "    grf (str) - path to the ground reaction force mot file\n",
    "    ...\n",
    "    \n",
    "    Methods: use dir(Trial) to see all methods\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, trial_path):        \n",
    "        self.path = trial_path\n",
    "        self.name = os.path.basename(self.path)\n",
    "        self.subject = os.path.basename(os.path.dirname(self.path))\n",
    "        self.c3d = os.path.join(os.path.dirname(self.path), self.name + '.c3d')\n",
    "        self.markers = File(os.path.join(self.path,'markers_experimental.trc'))\n",
    "        self.grf = File(os.path.join(self.path,'Visual3d_SIMM_grf.mot'))\n",
    "        self.emg_csv = File(os.path.join(self.path,'processed_emg_signals.csv'))\n",
    "        self.emg = File(os.path.join(self.path,'processed_emg_signals.mot'))\n",
    "        self.ik = File(os.path.join(self.path,'Visual3d_SIMM_input.mot'))\n",
    "        self.id = File(os.path.join(self.path,'inverse_dynamics.sto'))\n",
    "        self.so_force = File(os.path.join(self.path,'Results_SO_and_MA', f'{self.subject}_StaticOptimization_force.sto'))\n",
    "        self.so_activation = File(os.path.join(self.path, 'Results_SO_and_MA', f'{self.subject}_StaticOptimization_activation.sto'))\n",
    "        self.jra = File(os.path.join(self.path,'joint_reacton_loads.sto'))\n",
    "        \n",
    "        # load muscle analysis files\n",
    "        self.ma_targets = ['_MomentArm_', '_Length.sto']\n",
    "        self.ma_files = []\n",
    "        try:\n",
    "            files = os.listdir(os.path.join(self.path, 'Results_SO_and_MA'))\n",
    "            for file in files:\n",
    "                if file.__contains__(self.ma_targets[0]) or file.__contains__(self.ma_targets[1]):\n",
    "                    self.ma_files.append(File(os.path.join(self.path, 'Results_SO_and_MA', file)))\n",
    "        except:\n",
    "            self.ma_files = None\n",
    "                    \n",
    "        # settings files\n",
    "        self.grf_xml = File(os.path.join(self.path,'GRF_Setup.xml'))\n",
    "        self.actuators_so = File(os.path.join(self.path,'actuators_SO.xml'))\n",
    "        \n",
    "        self.settings_json = File(os.path.join(self.path,'settings.json'))\n",
    "        \n",
    "        # CEINMS files\n",
    "        self.ceinms_cal_setup = File(os.path.join(self.path,'ceinms','calibrationSetup.xml'))\n",
    "        self.ceinms_cal_cfg = File(os.path.join(self.path,'ceinms','calibrationCfg.xml'))\n",
    "        self.ceinms_trial = File(os.path.join(self.path,'ceinms','trial.xml'))\n",
    "        self.ceinms_uncalibrated_subject = File(os.path.join(self.path,'ceinms','uncalibratedSubject.xml'))\n",
    "        self.ceinms_excitation_generator = File(os.path.join(self.path,'ceinms','excitationGenerator.xml'))\n",
    "        self.ceinms_execution_setup = File(os.path.join(self.path, 'ceinms', 'executionSetup.xml'))\n",
    "        self.ceinms_execution_cfg = File(os.path.join(self.path, 'ceinms', 'executionCfg.xml'))\n",
    "\n",
    "                              \n",
    "    def check_files(self):\n",
    "        '''\n",
    "        Output: True if all files exist, False if any file is missing\n",
    "        '''\n",
    "        files = self.__dict__.values()\n",
    "        all_files_exist = True\n",
    "        for file in files:\n",
    "            try:\n",
    "                if not os.path.isfile(file):\n",
    "                    print('File not found: ' + file)\n",
    "                    all_files_exist = False\n",
    "            except:\n",
    "                pass\n",
    "        return all_files_exist\n",
    "    \n",
    "    def header_mot(self,df,name):\n",
    "\n",
    "            num_rows = len(df)\n",
    "            num_cols = len(df.columns) \n",
    "            inital_time = df['Time'].iloc[0]\n",
    "            final_time = df['Time'].iloc[-1]\n",
    "            df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "            return f'name {name}\\n datacolumns {num_cols}\\n datarows {num_rows}\\n range {df_range} \\n endheader'\n",
    "        \n",
    "    def csv_to_mot(self):\n",
    "        \n",
    "        emg_data = msk.bops.pd.read_csv(self.emg_csv)\n",
    "\n",
    "        fs = int(1/(emg_data['time'][1] - emg_data['time'][0]))\n",
    "\n",
    "        time = emg_data['time']\n",
    "\n",
    "        # start time from new time point\n",
    "        start_time = time.iloc[0]\n",
    "        end_time = time.iloc[-1] - time.iloc[0] + start_time\n",
    "\n",
    "        num_samples = len(emg_data)\n",
    "        #num_samples = int((end_time - start_time) / (1/fs))\n",
    "        new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "        emg_data['time'] = new_time\n",
    "\n",
    "        # Define a new file path \n",
    "        new_file_path = os.path.join(self.emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "        # Save the modified DataFrame\n",
    "        emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "        # save to mot\n",
    "        header = self.header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "        mot_path = new_file_path.replace('.csv','.mot')\n",
    "        with open(mot_path, 'w') as f:\n",
    "            f.write(header + '\\n')  \n",
    "            # print column names \n",
    "            f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "            for index, row in emg_data.iterrows():\n",
    "                f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "        \n",
    "        print(f\"File saved: {mot_path}\")\n",
    "\n",
    "    def create_settings_json(self, overwrite=False):\n",
    "        if os.path.isfile(self.settings_json) and not overwrite:\n",
    "            print('settings.json already exists')\n",
    "            return\n",
    "        \n",
    "        settings_dict = self.__dict__\n",
    "        msk.bops.save_json_file(settings_dict, self.settings_json)\n",
    "        print('trial settings.json created in ' + self.path)\n",
    "    \n",
    "    def exportC3D(self):\n",
    "        msk.bops.c3d_osim_export(self.og_c3d) \n",
    "\n",
    "    def change_grf_xml_path(self):\n",
    "\n",
    "        try:\n",
    "            self.tree = ET.parse(self.grf_xml.path)\n",
    "            self.root = self.tree.getroot()\n",
    "            self.root.find('.//datafile').text = self.grf.path\n",
    "            \n",
    "            self.tree.write(self.grf_xml.path)\n",
    "            \n",
    "            print(f\"GRF file path updated in {self.grf_xml.path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading XML file: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_json_file(self, data, jsonFilePath):\n",
    "        data = data.__dict__\n",
    "\n",
    "        with open(jsonFilePath, 'w') as f:\n",
    "            msk.bops.json.dump(data, f, indent=4)\n",
    "\n",
    "        json_data = msk.bops.import_json_file(jsonFilePath)\n",
    "        return json_data\n",
    "    \n",
    "    def to_json(self):\n",
    "        msk.bops.save_json_file(self.__dict__, jsonFilePath = self.settings_json)\n",
    "        print('settings.json created in ' + self.settings_json)\n",
    "    \n",
    "    def run_IK(osim_modelPath, trc_file, resultsDir):\n",
    "        '''\n",
    "        Function to run Inverse Kinematics using the OpenSim API.\n",
    "        \n",
    "        Inputs:\n",
    "                osim_modelPath(str): path to the OpenSim model file\n",
    "                trc_file(str): path to the TRC file\n",
    "                resultsDir(str): path to the directory where the results will be saved\n",
    "        '''\n",
    "\n",
    "        # Load the TRC file\n",
    "        import pdb; pdb.set_trace()\n",
    "        tuple_data = msk.bops.import_trc_file(trc_file)\n",
    "        df = pd.DataFrame.from_records(tuple_data, columns=[x[0] for x in tuple_data])\n",
    "        column_names = [x[0] for x in tuple_data]\n",
    "        if len(set(column_names)) != len(column_names):\n",
    "            print(\"Error: Duplicate column names found.\")\n",
    "        # Load the model\n",
    "        osimModel = osim.Model(osim_modelPath)                              \n",
    "        state = osimModel.initSystem()\n",
    "\n",
    "        # Define the time range for the analysis\n",
    "        \n",
    "        initialTime = msk.TRCData.getIndependentColumn()\n",
    "        finalTime = msk.TRCData.getLastTime()\n",
    "\n",
    "        # Create the inverse kinematics tool\n",
    "        ikTool = osim.InverseKinematicsTool()\n",
    "        ikTool.setModel(osimModel)\n",
    "        ikTool.setStartTime(initialTime)\n",
    "        ikTool.setEndTime(finalTime)\n",
    "        ikTool.setMarkerDataFileName(trc_file)\n",
    "        ikTool.setResultsDir(resultsDir)\n",
    "        ikTool.set_accuracy(1e-6)\n",
    "        ikTool.setOutputMotionFileName(os.path.join(resultsDir, \"ik.mot\"))\n",
    "\n",
    "        # print setup\n",
    "        ikTool.printToXML(os.path.join(resultsDir, \"ik_setup.xml\"))         \n",
    "\n",
    "        # Run inverse kinematics\n",
    "        print(\"running ik...\")                                             \n",
    "        ikTool.run()\n",
    "\n",
    "    def run_inverse_kinematics(model_file, marker_file, output_motion_file):\n",
    "        # Load model and create an InverseKinematicsTool\n",
    "        model = osim.Model(model_file)\n",
    "        ik_tool = osim.InverseKinematicsTool()\n",
    "\n",
    "        # Set the model for the InverseKinematicsTool\n",
    "        ik_tool.setModel(model)\n",
    "\n",
    "        # Set the marker data file for the InverseKinematicsTool\n",
    "        ik_tool.setMarkerDataFileName(marker_file)\n",
    "\n",
    "        # Specify output motion file\n",
    "        ik_tool.setOutputMotionFileName(output_motion_file)\n",
    "\n",
    "        # Save setup file\n",
    "        ik_tool.printToXML('setup_ik.xml')\n",
    "\n",
    "        # Run Inverse Kinematics\n",
    "        ik_tool.run()\n",
    "\n",
    "    def run_ID(self, osim_modelPath, coordinates_file, external_loads_file, output_file, LowpassCutoffFrequency=6, run_tool=True):\n",
    "        \n",
    "        try: \n",
    "            model = osim.Model(osim_modelPath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {osim_modelPath}\")\n",
    "            print(e)\n",
    "            return\n",
    "        \n",
    "        results_folder = os.path.dirname(output_file)\n",
    "        \n",
    "        # Setup for excluding muscles from ID\n",
    "        exclude = osim.ArrayStr()\n",
    "        exclude.append(\"Muscles\")\n",
    "        # Setup for setting time range\n",
    "        IKData = osim.Storage(coordinates_file)\n",
    "\n",
    "        # Create inverse dynamics tool, set parameters and run\n",
    "        id_tool = osim.InverseDynamicsTool()\n",
    "        id_tool.setModel(model)\n",
    "        id_tool.setCoordinatesFileName(coordinates_file)\n",
    "        id_tool.setExternalLoadsFileName(external_loads_file)\n",
    "        id_tool.setOutputGenForceFileName(output_file)\n",
    "        id_tool.setLowpassCutoffFrequency(LowpassCutoffFrequency)\n",
    "        id_tool.setStartTime(IKData.getFirstTime())\n",
    "        id_tool.setEndTime(IKData.getLastTime())\n",
    "        id_tool.setExcludedForces(exclude)\n",
    "        id_tool.setResultsDir(results_folder)\n",
    "        id_tool.printToXML(os.path.join(results_folder, \"setup_ID.xml\"))\n",
    "        \n",
    "        if run_tool:\n",
    "            id_tool.run()\n",
    "    \n",
    "\n",
    "    # CREATE CEINMS XML files\n",
    "    def create_calibration_setup(self, save_path = None):\n",
    "            root = ET.Element(\"ceinmsCalibration\")\n",
    "            \n",
    "            subject_file = ET.SubElement(root, \"subjectFile\")\n",
    "            subject_file.text = \".\\\\uncalibratedSubject.xml\"\n",
    "            \n",
    "            excitation_generator_file = ET.SubElement(root, \"excitationGeneratorFile\")\n",
    "            excitation_generator_file.text = \".\\\\excitationGenerator.xml\"\n",
    "            \n",
    "            calibration_file = ET.SubElement(root, \"calibrationFile\")\n",
    "            calibration_file.text = \".\\\\calibrationCfg.xml\"\n",
    "            \n",
    "            output_subject_file = ET.SubElement(root, \"outputSubjectFile\")\n",
    "            output_subject_file.text = \".\\\\calibratedSubject.xml\"\n",
    "            \n",
    "            tree = ET.ElementTree(root)\n",
    "            if save_path is not None:\n",
    "                save_pretty_xml(tree, save_path)\n",
    "                print(f\"XML file created at: {save_path}\")\n",
    "                \n",
    "            return tree\n",
    "\n",
    "    def create_calibration_cfg(self, save_path=None, osimModelFile=None, leg='r'):\n",
    "\n",
    "        if leg not in ['r', 'l']:\n",
    "            raise ValueError(\"Leg must be 'r' or 'l'\")\n",
    "\n",
    "        \n",
    "                \n",
    "        dofs = [f\"hip_flexion_{leg}\", f\"knee_angle_{leg}\", f\"ankle_angle_{leg}\"]\n",
    "\n",
    "        # muscle_groups = [\n",
    "        #     f\"addbrev_{leg} addlong_{leg} addmagDist_{leg} addmagIsch_{leg} addmagMid_{leg} addmagProx_{leg} grac_{leg}\",\n",
    "        #     f\"bflh_{leg} semimem_{leg} semiten_{leg}\",\n",
    "        #     f\"bfsh_{leg}\",\n",
    "        #     f\"glmax1_{leg} glmax2_{leg} glmax3_{leg}\",\n",
    "        #     f\"glmed1_{leg} glmed2_{leg} glmed3_{leg}\",\n",
    "        #     f\"glmin1_{leg} glmin2_{leg} glmin3_{leg}\",\n",
    "        #     f\"sart_{leg} recfem_{leg} tfl_{leg}\",\n",
    "        #     f\"iliacus_{leg} psoas_{leg}\",\n",
    "        #     f\"perbrev_{leg} perlong_{leg} tibant_{leg} tibpost_{leg}\",\n",
    "        #     f\"edl_{leg} ehl_{leg} fdl_{leg} fhl_{leg}\",\n",
    "        #     f\"soleus_{leg} gaslat_{leg} gasmed_{leg}\",\n",
    "        #     f\"vasint_{leg} vaslat_{leg} vasmed_{leg}\",\n",
    "        #     f\"quad_fem_{leg} gem_{leg} peri_{leg} per_tert_{leg} ercspn_{leg} intobl_{leg} extobl_{leg}\"\n",
    "        # ]  \n",
    "    \n",
    "\n",
    "        root = ET.Element(\"calibration\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "        \n",
    "        algorithm = ET.SubElement(root, \"algorithm\")\n",
    "        simulated_annealing = ET.SubElement(algorithm, \"simulatedAnnealing\")\n",
    "        ET.SubElement(simulated_annealing, \"noEpsilon\").text = \"4\"\n",
    "        ET.SubElement(simulated_annealing, \"rt\").text = \"0.3\"\n",
    "        ET.SubElement(simulated_annealing, \"T\").text = \"200000\"\n",
    "        ET.SubElement(simulated_annealing, \"NS\").text = \"15\"\n",
    "        ET.SubElement(simulated_annealing, \"NT\").text = \"5\"\n",
    "        ET.SubElement(simulated_annealing, \"epsilon\").text = \"1.E-5\"\n",
    "        ET.SubElement(simulated_annealing, \"maxNoEval\").text = \"200000\"\n",
    "        \n",
    "        nms_model = ET.SubElement(root, \"NMSmodel\")\n",
    "        model_type = ET.SubElement(nms_model, \"type\")\n",
    "        ET.SubElement(model_type, \"openLoop\")\n",
    "        tendon = ET.SubElement(nms_model, \"tendon\")\n",
    "        ET.SubElement(tendon, \"equilibriumElastic\")\n",
    "        activation = ET.SubElement(nms_model, \"activation\")\n",
    "        ET.SubElement(activation, \"exponential\")\n",
    "        \n",
    "        calibration_steps = ET.SubElement(root, \"calibrationSteps\")\n",
    "        step = ET.SubElement(calibration_steps, \"step\")\n",
    "        ET.SubElement(step, \"dofs\").text = \" \".join(dofs)\n",
    "        \n",
    "        objective_function = ET.SubElement(step, \"objectiveFunction\")\n",
    "        torque_error_normalised = ET.SubElement(objective_function, \"torqueErrorNormalised\")\n",
    "        ET.SubElement(torque_error_normalised, \"targets\").text = \"all\"\n",
    "        ET.SubElement(torque_error_normalised, \"weight\").text = \"1\"\n",
    "        ET.SubElement(torque_error_normalised, \"exponent\").text = \"1\"\n",
    "        \n",
    "        penalty = ET.SubElement(objective_function, \"penalty\")\n",
    "        ET.SubElement(penalty, \"targets\").text = \"all\"\n",
    "        ET.SubElement(penalty, \"targetsType\").text = \"normalisedFibreLength\"\n",
    "        ET.SubElement(penalty, \"weight\").text = \"100\"\n",
    "        ET.SubElement(penalty, \"exponent\").text = \"2\"\n",
    "        ET.SubElement(penalty, \"range\").text = \"0.6 1.4\"\n",
    "        \n",
    "        parameter_set = ET.SubElement(step, \"parameterSet\")\n",
    "            \n",
    "        parameters = [\n",
    "            {\"name\": \"c1\", \"range\": \"-0.95 -0.05\"},\n",
    "            {\"name\": \"c2\", \"range\": \"-0.95 -0.05\"},\n",
    "            {\"name\": \"shapeFactor\", \"range\": \"-2.999 -0.001\"},\n",
    "            {\"name\": \"tendonSlackLength\", \"range\": \"0.85 1.15\", \"relative\": True},\n",
    "            {\"name\": \"optimalFibreLength\", \"range\": \"0.85 1.15\", \"relative\": True},\n",
    "            {\"name\": \"strengthCoefficient\", \"range\": \"0.8 2\"}\n",
    "        ]\n",
    "        \n",
    "        for param in parameters:\n",
    "            parameter = ET.SubElement(parameter_set, \"parameter\")\n",
    "            ET.SubElement(parameter, \"name\").text = param[\"name\"]\n",
    "            \n",
    "            # Check if this parameter has a muscle group\n",
    "            if \"muscleGroups\" in param:\n",
    "                muscle_groups = ET.SubElement(parameter, \"muscleGroups\")\n",
    "                for muscle in param[\"muscleGroups\"]:\n",
    "                    ET.SubElement(muscle_groups, \"muscles\").text = muscle\n",
    "            else:\n",
    "                # If no muscle group, assume it's a single muscle parameter\n",
    "                ET.SubElement(parameter, \"single\")\n",
    "\n",
    "\n",
    "            if \"relative\" in param and param[\"relative\"]:\n",
    "                relative = ET.SubElement(parameter, \"relativeToSubjectValue\")\n",
    "                ET.SubElement(relative, \"range\").text = param[\"range\"]\n",
    "            else:\n",
    "                absolute = ET.SubElement(parameter, \"absolute\")\n",
    "                ET.SubElement(absolute, \"range\").text = param[\"range\"]\n",
    "           \n",
    "        \n",
    "        ET.SubElement(root, \"trialSet\").text = \".\\\\trial.xml\"\n",
    "        \n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "        \n",
    "        return tree\n",
    "\n",
    "    def create_ceinms_trial_xml(self, savepath = None):\n",
    "        root = ET.Element(\"inputData\")\n",
    "\n",
    "        muscle_tendon_length_file = ET.SubElement(root, \"muscleTendonLengthFile\")\n",
    "        muscle_tendon_length_file.text = f\"../Results_SO_and_MA/MuscleAnalysis_Length.sto\"\n",
    "\n",
    "        excitations_file = ET.SubElement(root, \"excitationsFile\")\n",
    "        excitations_file.text = \"../processed_emg_signals.mot\"\n",
    "\n",
    "        moment_arms_files = ET.SubElement(root, \"momentArmsFiles\")\n",
    "        moment_arms_file_ankle_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"ankle_angle_l\")\n",
    "        moment_arms_file_ankle_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_ankle_angle_l.sto\"\n",
    "        moment_arms_file_ankle_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"ankle_angle_r\")\n",
    "        moment_arms_file_ankle_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_ankle_angle_r.sto\"\n",
    "        moment_arms_file_hip_adduction_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_adduction_l\")\n",
    "        moment_arms_file_hip_adduction_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_adduction_l.sto\"\n",
    "        moment_arms_file_hip_adduction_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_adduction_r\")\n",
    "        moment_arms_file_hip_adduction_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_adduction_r.sto\"\n",
    "        moment_arms_file_hip_flexion_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_flexion_l\")\n",
    "        moment_arms_file_hip_flexion_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_flexion_l.sto\"\n",
    "        moment_arms_file_hip_flexion_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_flexion_r\")\n",
    "        moment_arms_file_hip_flexion_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_flexion_r.sto\"\n",
    "        moment_arms_file_hip_rotation_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_rotation_l\")\n",
    "        moment_arms_file_hip_rotation_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_rotation_l.sto\"\n",
    "        moment_arms_file_hip_rotation_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"hip_rotation_r\")\n",
    "        moment_arms_file_hip_rotation_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_hip_rotation_r.sto\"\n",
    "        moment_arms_file_knee_l = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"knee_angle_l\")\n",
    "        moment_arms_file_knee_l.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_knee_angle_l.sto\"\n",
    "        moment_arms_file_knee_r = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"knee_angle_r\")\n",
    "        moment_arms_file_knee_r.text = \"../Results_SO_and_MA/MuscleAnalysis_MomentArm_knee_angle_r.sto\"\n",
    "\n",
    "        external_torques_file = ET.SubElement(root, \"externalTorquesFile\")\n",
    "        external_torques_file.text = \"../inverse_dynamics.sto\"\n",
    "\n",
    "        external_loads_file = ET.SubElement(root, \"externalLoadsFile\")\n",
    "        external_loads_file.text = \"../GRF_Setup.xml\"\n",
    "\n",
    "        motion_file = ET.SubElement(root, \"motionFile\")\n",
    "        motion_file.text = \"../Visual3d_SIMM_input.mot\"\n",
    "\n",
    "        start_stop_time = ET.SubElement(root, \"startStopTime\")\n",
    "\n",
    "        inverse_dynamics_file = os.path.join(self.path, 'inverse_dynamics.sto')\n",
    "        if os.path.isfile(inverse_dynamics_file):\n",
    "            with open(inverse_dynamics_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Find where the header ends\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.strip() == 'endheader':\n",
    "                    header_end_index = i\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Error: 'endheader' not found in file.\")\n",
    "                header_end_index = None\n",
    "\n",
    "            if header_end_index is not None:\n",
    "                # Read data into pandas\n",
    "                from io import StringIO\n",
    "                data_str = ''.join(lines[header_end_index + 1:])  # includes column names and data\n",
    "                df = pd.read_csv(StringIO(data_str), delim_whitespace=True)\n",
    "\n",
    "                if 'time' in df.columns:\n",
    "                    start_time = df['time'].iloc[0]\n",
    "                    end_time = df['time'].iloc[-1]\n",
    "                    start_stop_time.text = f\"{start_time} {end_time}\"\n",
    "                else:\n",
    "                    print(\"Error: 'time' column not found in inverse_dynamics.sto\")\n",
    "        else:\n",
    "            print(\"Error: File inverse_dynamics.sto not found\")\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        if savepath is not None:\n",
    "            save_pretty_xml(tree, savepath)\n",
    "            print(f\"XML file created at: {savepath}\")\n",
    "\n",
    "    def create_subject_uncalibrated(self, save_path=None, osimModelFile=None, leg='r'):\n",
    "        if osimModelFile == None:\n",
    "            print(\"\\033[93mNo OpenSim model not file provided. FAILED!!\\033[0m\")\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                model = osim.Model(osimModelFile)\n",
    "                coordinate_set = model.getCoordinateSet()\n",
    "                muscles = model.getMuscles() # ForceSet\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading OpenSim model: {e}\")\n",
    "                return None\n",
    "        \n",
    "        osim_model_file_name = os.path.basename(osimModelFile) \n",
    "        root = ET.Element(\"subject\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "        \n",
    "        mtu_default = ET.SubElement(root, \"mtuDefault\")\n",
    "        ET.SubElement(mtu_default, \"emDelay\").text = \"0.015\"\n",
    "        ET.SubElement(mtu_default, \"percentageChange\").text = \"0.15\"\n",
    "        ET.SubElement(mtu_default, \"damping\").text = \"0.1\"\n",
    "        \n",
    "        curves = [\n",
    "            {\n",
    "                \"name\": \"activeForceLength\",\n",
    "                \"xPoints\": \"-5 0 0.401 0.402 0.4035 0.52725 0.62875 0.71875 0.86125 1.045 1.2175 1.4387 1.6187 1.62 1.621 2.2 5\",\n",
    "                \"yPoints\": \"0 0 0 0 0 0.22667 0.63667 0.85667 0.95 0.99333 0.77 0.24667 0 0 0 0 0\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"passiveForceLength\",\n",
    "                \"xPoints\": \"-5 0.998 0.999 1 1.1 1.2 1.3 1.4 1.5 1.6 1.601 1.602 5\",\n",
    "                \"yPoints\": \"0 0 0 0 0.035 0.12 0.26 0.55 1.17 2 2 2 2\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"forceVelocity\",\n",
    "                \"xPoints\": \"-10 -1 -0.6 -0.3 -0.1 0 0.1 0.3 0.6 0.8 10\",\n",
    "                \"yPoints\": \"0 0 0.08 0.2 0.55 1 1.4 1.6 1.7 1.75 1.75\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"tendonForceStrain\",\n",
    "                \"xPoints\": \"0 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009 0.01 0.011 0.012 0.013 0.014 0.015 0.016 0.017 0.018 0.019 0.02 0.021 0.022 0.023 0.024 0.025 0.026 0.027 0.028 0.029 0.03 0.031 0.032 0.033 0.034 0.035 0.036 0.037 0.038 0.039 0.04 0.041 0.042 0.043 0.044 0.045 0.046 0.047 0.048 0.049 0.05 0.051 0.052 0.053 0.054 0.055 0.056 0.057 0.058 0.059 0.06 0.061 0.062 0.063 0.064 0.065 0.066 0.067 0.068 0.069 0.07 0.071 0.072 0.073 0.074 0.075 0.076 0.077 0.078 0.079 0.08 0.081 0.082 0.083 0.084 0.085 0.086 0.087 0.088 0.089 0.09 0.091 0.092 0.093 0.094 0.095 0.096 0.097 0.098 0.099 0.1\",\n",
    "                \"yPoints\": \"0 0.0012652 0.0073169 0.016319 0.026613 0.037604 0.049078 0.060973 0.073315 0.086183 0.099678 0.11386 0.12864 0.14386 0.15928 0.17477 0.19041 0.20658 0.22365 0.24179 0.26094 0.28089 0.30148 0.32254 0.34399 0.36576 0.38783 0.41019 0.43287 0.45591 0.4794 0.50344 0.52818 0.55376 0.58022 0.60747 0.63525 0.66327 0.69133 0.71939 0.74745 0.77551 0.80357 0.83163 0.85969 0.88776 0.91582 0.94388 0.97194 1 1.0281 1.0561 1.0842 1.1122 1.1403 1.1684 1.1964 1.2245 1.2526 1.2806 1.3087 1.3367 1.3648 1.3929 1.4209 1.449 1.477 1.5051 1.5332 1.5612 1.5893 1.6173 1.6454 1.6735 1.7015 1.7296 1.7577 1.7857 1.8138 1.8418 1.8699 1.898 1.926 1.9541 1.9821 2.0102 2.0383 2.0663 2.0944 2.1224 2.1505 2.1786 2.2066 2.2347 2.2628 2.2908 2.3189 2.3469 2.375 2.4031 2.4311\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for curve in curves:\n",
    "            curve_element = ET.SubElement(mtu_default, \"curve\")\n",
    "            ET.SubElement(curve_element, \"name\").text = curve[\"name\"]\n",
    "            ET.SubElement(curve_element, \"xPoints\").text = curve[\"xPoints\"]\n",
    "            ET.SubElement(curve_element, \"yPoints\").text = curve[\"yPoints\"]\n",
    "        \n",
    "        mtu_set = ET.SubElement(root, \"mtuSet\")\n",
    "        try:\n",
    "            mtus = []\n",
    "            for muscle in muscles:\n",
    "                if self.subject.startswith('PC'):\n",
    "                    ofl = muscle.getOptimalFiberLength() * 0.7  # Adjust for CP children Rabbi, M. F. et al. -2024- Biomech. Model. Mechanobiol. 23, 1077â€“1090\n",
    "                else:\n",
    "                    ofl = muscle.getOptimalFiberLength()\n",
    "\n",
    "                mtu = {\n",
    "                    \"name\": muscle.getName(),\n",
    "                    \"c1\": \"-0.5\",\n",
    "                    \"c2\": \"-0.5\",\n",
    "                    \"shapeFactor\": \"0.1\",\n",
    "                    \"optimalFibreLength\": str(ofl),\n",
    "                    \"pennationAngle\": str(muscle.getPennationAngleAtOptimalFiberLength()),\n",
    "                    \"tendonSlackLength\": str(muscle.getTendonSlackLength()),\n",
    "                    \"maxIsometricForce\": str(muscle.getMaxIsometricForce()),\n",
    "                    \"strengthCoefficient\": \"1\"\n",
    "                }\n",
    "                mtus.append(mtu)\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding OpenSim muscles: {e}\")\n",
    "            return None\n",
    "                        \n",
    "        for mtu in mtus:\n",
    "            mtu_element = ET.SubElement(mtu_set, \"mtu\")\n",
    "            ET.SubElement(mtu_element, \"name\").text = mtu[\"name\"]\n",
    "            ET.SubElement(mtu_element, \"c1\").text = mtu[\"c1\"]\n",
    "            ET.SubElement(mtu_element, \"c2\").text = mtu[\"c2\"]\n",
    "            ET.SubElement(mtu_element, \"shapeFactor\").text = mtu[\"shapeFactor\"]\n",
    "            ET.SubElement(mtu_element, \"optimalFibreLength\").text = mtu[\"optimalFibreLength\"]\n",
    "            ET.SubElement(mtu_element, \"pennationAngle\").text = mtu[\"pennationAngle\"]\n",
    "            ET.SubElement(mtu_element, \"tendonSlackLength\").text = mtu[\"tendonSlackLength\"]\n",
    "            ET.SubElement(mtu_element, \"maxIsometricForce\").text = mtu[\"maxIsometricForce\"]\n",
    "            ET.SubElement(mtu_element, \"strengthCoefficient\").text = mtu[\"strengthCoefficient\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        dof_set = ET.SubElement(root, \"dofSet\")\n",
    "\n",
    "\n",
    "        dofs = [\n",
    "            {\"name\": f\"hip_flexion_{leg}\", \n",
    "             \"mtuNameSet\": f\"add_brev_{leg} add_long_{leg} glut_med1_{leg} glut_min1_{leg} grac_{leg} iliacus_{leg} pect_{leg} psoas_{leg} rect_fem_{leg} sar_{leg} tfl_{leg}\"},\n",
    "            {\"name\": f\"knee_angle_{leg}\", \n",
    "             \"mtuNameSet\": f\"bifemlh_{leg} bifemsh_{leg} grac_{leg} lat_gas_{leg} med_gas_{leg} sar_{leg} semimem_{leg} semiten_{leg} rect_fem_{leg} vas_int_{leg} vas_lat_{leg} vas_med_{leg}\"},\n",
    "            {\"name\": f\"ankle_angle_{leg}\", \n",
    "             \"mtuNameSet\": f\"ext_dig_{leg} ext_hal_{leg} per_tert_{leg} tib_ant_{leg} flex_dig_{leg} flex_hal_{leg} lat_gas_{leg} med_gas_{leg} per_brev_{leg} per_long_{leg} soleus_{leg} tib_post_{leg}\"}\n",
    "        ]\n",
    "\n",
    "        for dof in dofs:\n",
    "            dof_element = ET.SubElement(dof_set, \"dof\")\n",
    "            ET.SubElement(dof_element, \"name\").text = dof[\"name\"]\n",
    "            ET.SubElement(dof_element, \"mtuNameSet\").text = dof[\"mtuNameSet\"]\n",
    "       \n",
    "        \n",
    "        calibration_info = ET.SubElement(root, \"calibrationInfo\")\n",
    "        uncalibrated = ET.SubElement(calibration_info, \"uncalibrated\")\n",
    "        ET.SubElement(uncalibrated, \"subjectID\").text = osim_model_file_name\n",
    "        ET.SubElement(uncalibrated, \"additionalInfo\").text = \"TendonSlackLength and OptimalFibreLength scaled with Winby-Modenese\"\n",
    "        \n",
    "        ET.SubElement(root, \"opensimModelFile\").text = \"..\\\\..\\\\\" + osim_model_file_name\n",
    "        \n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "        \n",
    "        return tree\n",
    "\n",
    "    def create_excitation_generator(self, save_path=None, leg='r', input_signals=None):\n",
    "        if leg not in ['l', 'r']:\n",
    "            raise ValueError(\"Leg must be 'l' or 'r'\")\n",
    "\n",
    "        # Define the input signals and excitations\n",
    "        input_signals = ['GLTMED', 'RF', 'ADDLONG', 'ST', 'TA', 'GM']\n",
    "        excitations = [\n",
    "            'add_brev', 'add_long', 'bifemlh', 'bifemsh', 'ext_dig', 'ext_hal', \n",
    "            'flex_dig', 'flex_hal', 'lat_gas', 'med_gas', 'glut_max1', 'glut_max2', \n",
    "            'glut_max3', 'glut_med1', 'glut_med2', 'glut_med3', 'glut_min1', \n",
    "            'glut_min2', 'glut_min3', 'grac', 'iliacus', 'per_brev', 'per_long', \n",
    "            'psoas', 'rect_fem', 'sar', 'semimem', 'semiten', 'soleus', 'tfl', \n",
    "            'tib_ant', 'tib_post', 'vas_int', 'vas_lat', 'vas_med', 'add_mag1', \n",
    "            'add_mag2', 'add_mag3', 'pect', 'quad_fem', 'gem', 'peri', 'per_tert', \n",
    "            'ercspn', 'intobl', 'extobl'\n",
    "        ]\n",
    "        # Define the correct mapping of muscles to EMG signals\n",
    "        muscle_to_signal = {\n",
    "            \"add_brev\": \"ADDLONG\",\n",
    "            \"add_long\": \"ADDLONG\",\n",
    "            \"grac\": \"ADDLONG\",\n",
    "            \"bifemlh\": \"ST\",\n",
    "            \"bifemsh\": \"ST\",\n",
    "            \"semimem\": \"ST\",\n",
    "            \"semiten\": \"ST\",\n",
    "            \"ext_dig\": \"TA\",\n",
    "            \"ext_hal\": \"TA\",\n",
    "            \"tib_ant\": \"TA\",\n",
    "            \"lat_gas\": \"GM\",\n",
    "            \"med_gas\": \"GM\",\n",
    "            \"soleus\": \"GM\",\n",
    "            \"glut_max1\": \"GLTMED\",\n",
    "            \"glut_max2\": \"GLTMED\",\n",
    "            \"glut_max3\": \"GLTMED\",\n",
    "            \"glut_med1\": \"GLTMED\",\n",
    "            \"glut_med2\": \"GLTMED\",\n",
    "            \"glut_med3\": \"GLTMED\",\n",
    "            \"glut_min1\": \"GLTMED\",\n",
    "            \"glut_min2\": \"GLTMED\",\n",
    "            \"glut_min3\": \"GLTMED\",\n",
    "            \"vas_int\": \"RF\",\n",
    "            \"vas_lat\": \"RF\",\n",
    "            \"vas_med\": \"RF\",\n",
    "            \"rect_fem\": \"RF\",\n",
    "        }\n",
    "        # Create the root element\n",
    "        root = ET.Element('excitationGenerator', {\n",
    "            'xmlns:xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n",
    "            'xsi:noNamespaceSchemaLocation': 'excitationGenerator.xsd'\n",
    "        })\n",
    "\n",
    "        # Create the inputSignals element (Only include signals for the selected leg)\n",
    "        input_signals_element = ET.SubElement(root, 'inputSignals', {'type': 'EMG'})\n",
    "        input_signals_element.text = ' '.join([f'{leg.upper()}{signal}' for signal in input_signals])\n",
    "\n",
    "        # Create the mapping element\n",
    "        mapping_element = ET.SubElement(root, 'mapping')\n",
    "\n",
    "        # Add excitations to the mapping element\n",
    "        for excitation in excitations:\n",
    "            excitation_element = ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_{leg}'})\n",
    "            if excitation in muscle_to_signal:\n",
    "                input_element = ET.SubElement(excitation_element, 'input')\n",
    "                input_element.set('weight', '1')\n",
    "                input_element.text = f\"{leg.upper()}{muscle_to_signal[excitation]}\"\n",
    "\n",
    "        # Add left leg muscles without assigning any input\n",
    "        if leg == 'r':\n",
    "            for excitation in excitations:\n",
    "                ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_l'})\n",
    "        elif leg == 'l':\n",
    "            for excitation in excitations:\n",
    "                ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_r'})\n",
    "\n",
    "        # Create the tree and write to file\n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:    \n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "\n",
    "    def create_execution_setup(self, save_path=None):\n",
    "        root = ET.Element(\"ceinms\")\n",
    "\n",
    "        subject_file = ET.SubElement(root, \"subjectFile\")\n",
    "        subject_file.text = \".\\\\calibratedSubject.xml\"\n",
    "\n",
    "        input_data_file = ET.SubElement(root, \"inputDataFile\")\n",
    "        input_data_file.text = \".\\\\trial.xml\"\n",
    "\n",
    "        execution_file = ET.SubElement(root, \"executionFile\")\n",
    "        execution_file.text = \".\\\\executionCfg.xml\"\n",
    "\n",
    "        excitation_generator_file = ET.SubElement(root, \"excitationGeneratorFile\")\n",
    "        excitation_generator_file.text = \".\\\\excitationGenerator.xml\"\n",
    "\n",
    "        output_directory = ET.SubElement(root, \"outputDirectory\")\n",
    "        output_directory.text = \".\\\\execution\"\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"Execution setup file created at: {save_path}\")\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def create_execution_cfg(self,save_path=None,leg='r'):\n",
    "        root = ET.Element(\"execution\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "\n",
    "        nms_model = ET.SubElement(root, \"NMSmodel\")\n",
    "        model_type = ET.SubElement(nms_model, \"type\")\n",
    "        hybrid = ET.SubElement(model_type, \"hybrid\")\n",
    "\n",
    "        ET.SubElement(hybrid, \"alpha\").text = \"1\"\n",
    "        ET.SubElement(hybrid, \"beta\").text = \"5\"\n",
    "        ET.SubElement(hybrid, \"gamma\").text = \"10\"\n",
    "        ET.SubElement(hybrid, \"dofSet\").text = \" \".join([f\"hip_flexion_{leg}\", f\"knee_angle_{leg}\", f\"ankle_angle_{leg}\"])\n",
    "        ET.SubElement(hybrid, \"synthMTUs\").text = f\"flex_dig_{leg} flex_hal_{leg} iliacus_{leg} per_brev_{leg} per_long_{leg} psoas_{leg} sar_{leg} tfl_{leg} tib_post_{leg} add_mag1_{leg} add_mag2_{leg} add_mag3_{leg} quad_fem_{leg} gem_{leg} peri_{leg} per_tert_{leg} ercspn_{leg} intobl_{leg} extobl_{leg} pect_{leg}\"\n",
    "        ET.SubElement(hybrid, \"adjustMTUs\").text = f\"add_brev_{leg} add_long_{leg} bifemlh_{leg} bifemsh_{leg} ext_dig_{leg} ext_hal_{leg} lat_gas_{leg} med_gas_{leg} glut_max1_{leg} glut_max2_{leg} glut_max3_{leg} glut_med1_{leg} glut_med2_{leg} glut_med3_{leg} glut_min1_{leg} glut_min2_{leg} glut_min3_{leg} grac_{leg} semimem_{leg} semiten_{leg} soleus_{leg} tib_ant_{leg} vas_int_{leg} vas_lat_{leg} vas_med_{leg} rect_fem_{leg}\"\n",
    "\n",
    "        algorithm = ET.SubElement(hybrid, \"algorithm\")\n",
    "        simulated_annealing = ET.SubElement(algorithm, \"simulatedAnnealing\")\n",
    "        ET.SubElement(simulated_annealing, \"noEpsilon\").text = \"4\"\n",
    "        ET.SubElement(simulated_annealing, \"rt\").text = \"0.3\"\n",
    "        ET.SubElement(simulated_annealing, \"T\").text = \"20000\"\n",
    "        ET.SubElement(simulated_annealing, \"NS\").text = \"15\"\n",
    "        ET.SubElement(simulated_annealing, \"NT\").text = \"5\"\n",
    "        ET.SubElement(simulated_annealing, \"epsilon\").text = \"0.001\"\n",
    "        ET.SubElement(simulated_annealing, \"maxNoEval\").text = \"200000\"\n",
    "\n",
    "        tendon = ET.SubElement(nms_model, \"tendon\")\n",
    "        equilibrium_elastic = ET.SubElement(tendon, \"equilibriumElastic\")\n",
    "        ET.SubElement(equilibrium_elastic, \"tolerance\").text = \"1e-09\"\n",
    "\n",
    "        activation = ET.SubElement(nms_model, \"activation\")\n",
    "        ET.SubElement(activation, \"exponential\")\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"Execution configuration file created at: {save_path}\")\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def create_ceinms_files(self, osim_model_path = None, leg=None, input_signals = None):\n",
    "        \n",
    "        if not osim_model_path:\n",
    "            print(\"No OpenSim model file provided.\")\n",
    "            return\n",
    "        \n",
    "        if not input_signals:\n",
    "            print(\"No input signals provided.\")\n",
    "            return\n",
    "\n",
    "        if not leg:\n",
    "            print(\"No leg provided.\")\n",
    "            return\n",
    "        \n",
    "        # Calibration Setup\n",
    "        # savepath = self.ceinms_cal_setup.path\n",
    "        # self.create_calibration_setup(savepath)\n",
    "\n",
    "        # # Calibration Configuration\n",
    "        # savepath = self.ceinms_cal_cfg.path\n",
    "        # self.create_calibration_cfg(savepath, osimModelFile=osim_model_path,leg=leg)\n",
    "\n",
    "        # # Trial\n",
    "        # savepath = self.ceinms_trial.path\n",
    "        # self.create_ceinms_trial_xml(savepath)\n",
    "\n",
    "        # Uncalibrated Model \n",
    "        # savepath = self.ceinms_uncalibrated_subject.path\n",
    "        # self.create_subject_uncalibrated(save_path=savepath,osimModelFile=osim_model_path, leg=leg)\n",
    "\n",
    "        # Excitation Generator\n",
    "        # savepath = self.ceinms_excitation_generator.path\n",
    "        # self.create_excitation_generator(save_path=savepath, leg=leg, input_signals=input_signals)\n",
    "\n",
    "        # Execution Setup\n",
    "        # savepath = self.ceinms_execution_setup.path\n",
    "        # self.create_execution_setup(save_path=savepath)\n",
    "\n",
    "        # Execution Configuration\n",
    "        savepath = self.ceinms_execution_cfg.path\n",
    "        self.create_execution_cfg(save_path=savepath,leg=leg)\n",
    "\n",
    "class openSim:\n",
    "    def __init__(self, legs = ['r', 'l'], subjects =['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026'], trials_to_load = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3'], trial_number = 1):\n",
    "        try:\n",
    "            self.code_path = os.path.dirname(__file__)\n",
    "        except:\n",
    "            self.code_path = os.getcwd()\n",
    "        \n",
    "        self.simulations_path = os.path.join(os.path.dirname(self.code_path), 'Simulations')\n",
    "        self.subjects = {}\n",
    "        \n",
    "        for subject in subjects:\n",
    "            self.subjects[subject] = {}\n",
    "            self.subjects[subject]['model'] = os.path.join(self.simulations_path, subject, subject + '_scaled.osim')\n",
    "            for leg in legs: \n",
    "                for trial in trials_to_load:            \n",
    "                    self.trial_path = os.path.join(self.simulations_path, subject, f'{trial}_{leg}{trial_number}')\n",
    "                    try:\n",
    "                        trial = Trial(self.trial_path)\n",
    "                        self.subjects[subject][trial.name] = trial \n",
    "                    except Exception as e:\n",
    "                        self.subjects[subject][trial] =  None\n",
    "                        # print(f\"Error loading trial: {self.trial_path}\")\n",
    "                        # print(e)\n",
    "            \n",
    "        \n",
    "        self.ik_columns = [\"hip_flexion_leg\", \"hip_adduction_leg\", \"hip_rotation_leg\", \"knee_angle_leg\", \"ankle_angle_leg\"]\n",
    "        self.id_columns = [\"hip_flexion_leg\" + \"_moment\", \"hip_adduction_leg\" + \"_moment\", \"hip_rotation_leg\" + \"_moment\", \"knee_angle_leg\" + \"_moment\", \"ankle_angle_leg\" + \"_moment\"]\n",
    "        self.force_columns = [\"add_long_leg\", \"rect_fem_leg\", \"med_gas_leg\", \"semiten_leg\",\"tib_ant_leg\"]\n",
    "\n",
    "\n",
    "        self.titles = [\"Hip Flexion\", \"Hip Adduction\", \"Hip Rotation\", \"Knee Flexion\", \"Ankle Plantarflexion\"]\n",
    "        self.titles_muscles = [\"Adductor Longus\", \"Rectus Femoris\", \"Medial Gastrocnemius\", \"Semitendinosus\", \"Tibialis Anterior\"]\n",
    "\n",
    "    # Time Normalisation Function \n",
    "    def time_normalised_df(self, df, fs=None):\n",
    "        if not isinstance(df, msk.pd.DataFrame):\n",
    "            raise Exception('Input must be a pandas DataFrame')\n",
    "        \n",
    "        if not fs:\n",
    "            try:\n",
    "                fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "            except KeyError:\n",
    "                raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "            \n",
    "        normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        for column in df.columns:\n",
    "            if column == 'time':  # Skip time column\n",
    "                continue\t\n",
    "            normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "            currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "            timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "            Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "            normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "        return normalised_df\n",
    "\n",
    "    def plot_single_trial(self, show = False):\n",
    "        #Read .mot files\n",
    "        with open(self.mot_file, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the line where actual data starts (usually after 'endheader')\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"endheader\" in line:\n",
    "                start_row = i + 1  # Data starts after this line\n",
    "                break\n",
    "        else:\n",
    "            start_row = 0  # If 'endheader' is not found, assume no header\n",
    "\n",
    "        # Load data using Pandas\n",
    "        self.df_ik = msk.pd.read_csv(self.mot_file, delim_whitespace=True, start_row=start_row)\n",
    "        self.df_id = msk.pd.read_csv(self.id_file, sep=\"\\t\", start_row=6)\n",
    "        self.df_force = msk.pd.read_csv(self.force_file, sep=\"\\t\", start_row=14)\n",
    "\n",
    "        # Apply normalisation to both IK (angles) and ID (moments) data\n",
    "        self.df_ik_normalized = self.time_normalised_df(df=self.df_ik)\n",
    "        self.df_id_normalized = self.time_normalised_df(df=self.df_id)\n",
    "        self.df_force_normalized = self.time_normalised_df(df=self.df_force)\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)  \n",
    " \n",
    "        # select the specified columns         \n",
    "        self.ik_data = self.df_ik_normalized[self.ik_columns]\n",
    "        self.id_data = self.df_id_normalized[self.id_columns]\n",
    "        self.force_data = self.df_force_normalized[self.force_columns]\n",
    "            \n",
    "        # Define the layout \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(15, 4)) \n",
    "\n",
    "        #Plot IK (angles)\n",
    "        for i, col in enumerate(self.ik_columns):\n",
    "            ax = axes[0,i]\n",
    "            ax.plot(time_normalized, self.ik_data[col], color='red')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Angle (deg)\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        #Plot ID (moments)\n",
    "        for i, col in enumerate(self.id_columns):\n",
    "            ax = axes[1,i]\n",
    "            ax.plot(time_normalized, self.id_data[col], color='blue')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Moment (Nm)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        # PLOT MUSCLE FORCES \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 4), sharex=True)\n",
    "\n",
    "        for i, col in enumerate(self.force_columns):\n",
    "            ax = axes[i]\n",
    "            ax.plot(time_normalized, self.force_data[col], color='green')\n",
    "            ax.set_title(self.titles_muscles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Force (N)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_multiple_trials(self, show=False):\n",
    "        self.df_ik_list = []  # Store loaded DataFrames\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "            for trial in self.subjects[subject]:\n",
    "                trial_obj = self.subjects[subject][trial]\n",
    "                if trial_obj:\n",
    "                    self.df_ik_list.append(trial_obj.ik.data)\n",
    "                    \n",
    "        for file in self.mot_files:  # Loop through each file\n",
    "            with open(file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Load data using Pandas\n",
    "            df = msk.pd.read_csv(file, delim_whitespace=True, skiprows=5)\n",
    "            self.df_ik_list.append(df)\n",
    "\n",
    "        # Normalize all loaded IK data\n",
    "        self.df_ik_normalized_list = []  # Store normalized DataFrames\n",
    "\n",
    "        for df in self.df_ik_list:  # Loop through each loaded DataFrame\n",
    "            df_normalized = self.time_normalised_df(df=df)  # Apply normalization\n",
    "            self.df_ik_normalized_list.append(df_normalized)  # Store normalized DataFrame\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)\n",
    "\n",
    "        # Select the specified columns from normalized data\n",
    "        self.ik_data_list = []  # Store DataFrames with only the required columns\n",
    "\n",
    "        for df_normalized in self.df_ik_normalized_list:  # Loop through each normalized DataFrame\n",
    "            if set(self.ik_columns).issubset(df_normalized.columns):  # Check if columns exist\n",
    "                self.ik_data_list.append(df_normalized[self.ik_columns])  # Select only specified columns\n",
    "            else:\n",
    "                print(\"Warning: Some specified columns are missing in a file.\")\n",
    "\n",
    "        # Plot mean and sd\n",
    "        # Check if IK data exists\n",
    "        if not self.ik_data_list:\n",
    "            print(\"No IK data available to plot!\")\n",
    "        else:\n",
    "            # Convert list of DataFrames to a single NumPy array\n",
    "            combined_df = np.array([df.values for df in self.ik_data_list])  # Shape: (num_trials, num_timepoints, num_columns)\n",
    "\n",
    "            # Check if data is properly structured\n",
    "            if combined_df.shape[0] < 2:\n",
    "                print(\"Not enough trials to calculate mean and standard deviation!\")\n",
    "            else:\n",
    "                # Compute Mean and Standard Deviation\n",
    "                mean_values = np.mean(combined_df, axis=0)\n",
    "                std_values = np.std(combined_df, axis=0)\n",
    "\n",
    "                # Normalize time from 0 to 100% Gait Cycle\n",
    "                time_values = np.linspace(0, 100, combined_df.shape[1])\n",
    "\n",
    "                # Create a shared figure for all subplots\n",
    "                fig, axes = plt.subplots(nrows=1, ncols=len(self.ik_columns), figsize=(20, 5), sharex=True)\n",
    "\n",
    "                if len(self.ik_columns) == 1:\n",
    "                    axes = [axes]  # If only one column, ensure it's iterable\n",
    "\n",
    "                for i, col in enumerate(self.ik_columns):\n",
    "                    ax = axes[i]\n",
    "\n",
    "                    # Plot mean line\n",
    "                    ax.plot(time_values, mean_values[:, i], color='red', label=\"Mean\", linewidth=2)\n",
    "\n",
    "                    # Shade the standard deviation range\n",
    "                    ax.fill_between(time_values, mean_values[:, i] - std_values[:, i],\n",
    "                                    mean_values[:, i] + std_values[:, i], color='red', alpha=0.2, label=\"SD Range\")\n",
    "\n",
    "                    # Formatting\n",
    "                    ax.set_title(col)\n",
    "                    ax.set_xlabel(\"Gait Cycle (%)\")\n",
    "                    ax.set_xlim(0, 100)  # X-axis from 0% to 100% of the gait cycle\n",
    "                    ax.grid(True)\n",
    "\n",
    "                    # Set Y-label only for the first subplot\n",
    "                    if i == 0:\n",
    "                        ax.set_ylabel(\"Angle (Degrees)\")\n",
    "                        ax.legend()\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                if show:\n",
    "                    plt.show()\n",
    "\n",
    "def export_c3d(c3dFilePath):\n",
    "    analog_file_path = os.path.join(os.path.dirname(c3dFilePath),'analog.csv')\n",
    "    \n",
    "    # if the file already exists, return the file\n",
    "    if os.path.isfile(analog_file_path):\n",
    "        df = msk.pd.read_csv(analog_file_path)\n",
    "        return df\n",
    "    \n",
    "    print('Exporting analog data to csv ...')\n",
    "    \n",
    "    # read c3d file\n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    first_frame = reader.first_frame\n",
    "    num_frames = reader.frame_count\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    initial_time = first_frame / fs\n",
    "    final_time = (first_frame + num_frames-1) / fs\n",
    "    time = np.arange(first_frame / fs, final_time, 1 / fs) \n",
    "\n",
    "    df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "    df['time'] = time\n",
    "    \n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]    \n",
    "    \n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # convert analog data to list\n",
    "        analog_list  = analog.data.tolist()\n",
    "        \n",
    "        # loop through analog channels and add to dataframe\n",
    "        for i_channel in range(len(analog_list)):\n",
    "            channel_name = analog_labels[i_channel]\n",
    "            \n",
    "            # add channel to dataframe\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # save emg data to csv   \n",
    "    df.to_csv(analog_file_path)\n",
    "    print('analog.csv exported to ' + analog_file_path)  \n",
    "    \n",
    "    return df\n",
    "\n",
    "def export_analog(c3dFilePath=None, columns_to_mot='all'):\n",
    "    if not c3dFilePath:\n",
    "        print('C3D file path not provided')\n",
    "        return\n",
    "    \n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "    \n",
    "    # remove those not in columns_to_mot (fix: use column names to filter and get indices)\n",
    "    if columns_to_mot != 'all':\n",
    "        indices = [i for i, label in enumerate(analog_labels) if label in columns_to_mot]\n",
    "        analog_labels = [analog_labels[i] for i in indices]\n",
    "    else:\n",
    "        indices = list(range(len(analog_labels)))\n",
    "        columns_to_mot = analog_labels\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    marker_fs = reader.point_rate  # This is the actual frame rate for kinematics\n",
    "   \n",
    "\n",
    "    first_time = reader.first_frame / marker_fs\n",
    "    final_time = (reader.first_frame + reader.frame_count - 1) / marker_fs\n",
    "    time = msk.np.arange(first_time, final_time + 1 / marker_fs, 1 / marker_fs)\n",
    "  \n",
    "    num_frames = len(time)\n",
    "    df = msk.pd.DataFrame(index=range(num_frames), columns=analog_labels)\n",
    "    df['time'] = time\n",
    "\n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols] \n",
    "\n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # loop through selected analog channels and add to dataframe (fix: iterate over filtered indices)\n",
    "        for idx, i_channel in enumerate(indices):\n",
    "            channel_name = analog_labels[idx]\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # remove rows with NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # save emg data to csv\n",
    "    analog_csv_path = c3dFilePath.replace('.c3d', '_analog.csv')\n",
    "    df.to_csv(analog_csv_path, index=False)\n",
    "    \n",
    "    # save to mot\n",
    "    # self.csv_to_mot()\n",
    "    \n",
    "    return analog_csv_path\n",
    "\n",
    "def header_mot(df,name):\n",
    "\n",
    "        num_rows = len(df)\n",
    "        num_cols = len(df.columns) \n",
    "        inital_time = df['time'].iloc[0]\n",
    "        final_time = df['time'].iloc[-1]\n",
    "        df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "        return f'name {name}\\nnRows={num_rows}\\nnColumns={num_cols}\\n \\nendheader'\n",
    "\n",
    "def csv_to_mot(emg_csv, columns = 'all'):\n",
    "    \n",
    "    emg_data = msk.bops.pd.read_csv(emg_csv)\n",
    "    \n",
    "    try:\n",
    "        time = emg_data['time']\n",
    "    except:\n",
    "        time = emg_data['Time']\n",
    "\n",
    "    # start time from new time point\n",
    "    start_time = time.iloc[0]\n",
    "    end_time = time.iloc[-1]\n",
    "\n",
    "    num_samples = len(emg_data)\n",
    "    new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "    # remove columns not in columns_to_mot\n",
    "    if columns != 'all':\n",
    "        emg_data = emg_data[columns]\n",
    "\n",
    "    emg_data['time'] = new_time\n",
    "    # Ensure 'time' column is the first column\n",
    "    cols = emg_data.columns.tolist()\n",
    "    cols.insert(0, cols.pop(cols.index('time')))\n",
    "    emg_data = emg_data[cols]\n",
    "\n",
    "    # Define a new file path \n",
    "    new_file_path = os.path.join(emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "    # Save the modified DataFrame\n",
    "    emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "    # save to mot\n",
    "    header = header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "    mot_path = new_file_path.replace('.csv','.mot')\n",
    "    with open(mot_path, 'w') as f:\n",
    "        f.write(header + '\\n')  \n",
    "        # print column names \n",
    "        f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "        for index, row in emg_data.iterrows():\n",
    "            f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "    \n",
    "    print(f\"File saved: {mot_path}\")\n",
    "    \n",
    "    return mot_path\n",
    "\n",
    "def time_normalised_df(df, fs=None):\n",
    "    if not isinstance(df, msk.pd.DataFrame):\n",
    "        raise Exception('Input must be a pandas DataFrame')\n",
    "    \n",
    "    if not fs:\n",
    "        try:\n",
    "            fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "        except KeyError:\n",
    "            raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "        \n",
    "    normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for column in df.columns:\n",
    "        normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "        currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "        timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "        Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "        normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "    return normalised_df\n",
    "\n",
    "def save_pretty_xml(tree, save_path):\n",
    "            \"\"\"Saves the XML tree to a file with proper indentation.\"\"\"\n",
    "            # Convert to string and format with proper indents\n",
    "            rough_string = ET.tostring(tree.getroot(), 'utf-8')\n",
    "            reparsed = xml.dom.minidom.parseString(rough_string)\n",
    "            pretty_xml = reparsed.toprettyxml(indent=\"   \")\n",
    "\n",
    "            # Write to file\n",
    "            with open(save_path, 'w') as file:\n",
    "                file.write(pretty_xml)\n",
    "\n",
    "def filter_emg(signal, sample_rate=1000, low_pass_cutoff=6):\n",
    "    \"\"\"\n",
    "    Processes EMG signal: clean, rectify, and filter to get the envelope.\n",
    "    \"\"\"\n",
    "    cleaned_signal = nk.emg_clean(signal, sampling_rate=sample_rate, method='biosppy')\n",
    "    rectified_signal = np.abs(cleaned_signal)\n",
    "    low_pass = low_pass_cutoff / (sample_rate / 2)\n",
    "    b, a = sig.butter(4, low_pass, btype='lowpass')\n",
    "    emg_envelope = np.abs(sig.filtfilt(b, a, rectified_signal))\n",
    "\n",
    "    return emg_envelope\n",
    "\n",
    "def filter_emg_signals(csv_file, muscles, sample_rate=1000):\n",
    "    df = msk.pd.read_csv(csv_file)\n",
    "    filtered_data = {'time': df['time']}  # Add time column\n",
    "    \n",
    "    for muscle in muscles:\n",
    "        if muscle in df.columns:\n",
    "            filtered_data[muscle] = filter_emg(df[muscle].values, sample_rate)\n",
    "    \n",
    "    df_filtered = msk.pd.DataFrame(filtered_data)\n",
    "    \n",
    "    filtered_emg_path = csv_file.replace('.csv', '_filtered_emg.csv')\n",
    "    df_filtered.to_csv(filtered_emg_path, index=False)\n",
    "    \n",
    "    return filtered_emg_path\n",
    "\n",
    "def amplitude_normalise(processed_emg_path):\n",
    "    emg_data = pd.read_csv(processed_emg_path)\n",
    "    \n",
    "    # Separate time and signal\n",
    "    time = emg_data['time']\n",
    "    signal_data = emg_data.drop(columns=['time'])\n",
    "    \n",
    "    # Avoid divide-by-zero errors\n",
    "    max_vals = signal_data.max()\n",
    "    max_vals[max_vals == 0] = 1  # prevent division by zero\n",
    "\n",
    "    # Normalise each EMG signal\n",
    "    signal_normalised = signal_data / max_vals\n",
    "\n",
    "    # Combine back with time\n",
    "    emg_data_normalised = pd.concat([time, signal_normalised], axis=1)\n",
    "\n",
    "    # Save the result\n",
    "    normalised_emg_path = processed_emg_path.replace('.csv', '_normalised.csv')\n",
    "    emg_data_normalised.to_csv(normalised_emg_path, index=False)\n",
    "    \n",
    "    return normalised_emg_path\n",
    "\n",
    "\n",
    "def filter_force(signal, sample_rate=1000, low_pass_cutoff=20):\n",
    "    \"\"\"\n",
    "    Processes EMG signal: clean, rectify, and filter to get the envelope.\n",
    "    \"\"\"\n",
    "    return nk.signal_filter(signal, sampling_rate=sample_rate, highcut=low_pass_cutoff, method='butter')\n",
    "\n",
    "def normalize_time_act(df, start_time, duration):\n",
    "    df_norm = df.copy()\n",
    "    df_norm['time'] = 100 * (df_norm['time'] - start_time) / duration\n",
    "    return df_norm  \n",
    "\n",
    "def find_file_endheader_line(path):\n",
    "        with open(path, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if 'endheader' in line:\n",
    "                    return i + 1\n",
    "        return 0  \n",
    "\n",
    "def import_file(path):\n",
    "    \n",
    "    endline = find_file_endheader_line(path)\n",
    "    data = pd.read_csv(path, skiprows=endline, sep='\\t')\n",
    "    return data\n",
    "\n",
    "def rmse_calc(y_true,y_predict):\n",
    "    return np.sqrt(np.mean((y_true - y_predict) ** 2))\n",
    "\n",
    "\n",
    "def compute_rmse_r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute RMSE and RÂ² between two 1D arrays (or Series).\n",
    "    Assumes the arrays have the same length.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    rmse = rmse_calc(y_true, y_pred)\n",
    "    \n",
    "    # r2 = r2_score(y_true, y_pred)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(y_true, y_pred)\n",
    "    r2 = r_value ** 2\n",
    "    \n",
    "    return rmse, r2\n",
    "\n",
    "def resample_curve(x, y, target_length):\n",
    "    \"\"\"\n",
    "    Resample curve (x and y) to have target_length samples using linear interpolation.\n",
    "    x is assumed to be 1D (e.g., a pandas Series).\n",
    "    \"\"\"\n",
    "    # Create a new time grid between x.min() and x.max()\n",
    "    new_x = np.linspace(x.iloc[0], x.iloc[-1], target_length)\n",
    "    new_y = np.interp(new_x, x, y)\n",
    "    return new_x, new_y\n",
    "\n",
    "def normalize_time(df):\n",
    "    df = df.copy()\n",
    "    df['time'] = 100 * (df['time'] - start_time) / sls_duration\n",
    "    return df\n",
    "\n",
    "def crop_time(df):\n",
    "    return df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
    "\n",
    "def load_sto(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    start_idx = next(i for i, line in enumerate(lines) if 'endheader' in line.lower()) + 1\n",
    "    return pd.read_csv(StringIO(''.join(lines[start_idx:])), delim_whitespace=True)\n",
    "\n",
    "def resample_to_percent_phase(df, target_len=101):\n",
    "    n = df.shape[0]\n",
    "    old_x = np.linspace(0, 100, n)\n",
    "    new_x = np.linspace(0, 100, target_len)\n",
    "    return pd.DataFrame({\n",
    "        col: interp1d(old_x, df[col].values, kind='linear')(new_x)\n",
    "        for col in df.columns\n",
    "    })\n",
    "\n",
    "# END\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Import, filter, and save force data\n",
    "\n",
    "# # Define the file path\n",
    "# file_path = os.path.join(one_dir_up, 'Simulations', 'PC006', 'trial2.csv')\n",
    "\n",
    "# # Import the file\n",
    "# force_data = pd.read_csv(file_path)\n",
    "\n",
    "# # Apply the filter_force function to each column (excluding the 'time' column)\n",
    "# filtered_force_data = force_data.copy()\n",
    "# for column in force_data.columns:\n",
    "#     if column != 'Time':  # Skip the 'time' column\n",
    "#         filtered_force_data[column] = filter_force(force_data[column].values, sample_rate=1000, low_pass_cutoff=75)\n",
    "\n",
    "# # Save the filtered data in the same folder\n",
    "# filtered_file_path = file_path.replace('.csv', '_filtered.csv')\n",
    "# filtered_force_data.to_csv(filtered_file_path, index=False)\n",
    "\n",
    "# print(f\"Filtered data saved at: {filtered_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optional) Name coordinates for the respective leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik_columns = [\"hip_flexion_leg\", \"hip_adduction_leg\", \"hip_rotation_leg\", \"knee_angle_leg\", \"ankle_angle_leg\"]\n",
    "ik_columns = [col.replace('_leg', '_r') for col in ik_columns]\n",
    "ik_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert c3d files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3dFilePath = msk.ui.select_file()\n",
    "\n",
    "subject = os.path.basename(os.path.dirname(c3dFilePath))\n",
    "trial_folder = os.path.basename(c3dFilePath).replace('.c3d','')\n",
    "\n",
    "print(f\"Subject: {subject}\")\n",
    "print(f\"Trial: {trial_folder}\")\n",
    "legs = ['r', 'l']\n",
    "\n",
    "for leg in legs:\n",
    "    leg_folder_name = trial_folder + f'_{leg}1'\n",
    "    leg_folder = os.path.join(os.path.dirname(c3dFilePath), leg_folder_name)\n",
    "    if not os.path.exists(leg_folder):\n",
    "        os.mkdir(leg_folder)\n",
    "        print(f\"Folder created: {leg_folder}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {leg_folder}\")\n",
    "        \n",
    "    if leg == 'r':\n",
    "        columns_to_mot = ['RGLTMED','RRF','RADDLONG','RST', 'RBF','RTA','RGM']\n",
    "    else:\n",
    "        columns_to_mot = ['LGLTMED','LRF','LADDLONG','LST','LBF','LTA','LGM'] \n",
    "    \n",
    "    \n",
    "    # Export analog data to csv\n",
    "    analog_csv_path = export_analog(c3dFilePath, columns_to_mot=columns_to_mot)\n",
    "    \n",
    "    print(f\"Exported Analog CSV Path: {analog_csv_path}\")\n",
    "\n",
    "\n",
    "    # Process EMG signals\n",
    "    filtered_emg_path = filter_emg_signals(analog_csv_path, columns_to_mot)\n",
    "\n",
    "    # Normalise amplitude of EMG signals\n",
    "    normalised_emg_path = amplitude_normalise(filtered_emg_path)\n",
    "    \n",
    "    # convert to mot\n",
    "    emg_mot_path = csv_to_mot(normalised_emg_path)\n",
    "    \n",
    "    # move the file to the leg folder\n",
    "    want_it = True\n",
    "    if want_it:\n",
    "        # move the file to the folder\n",
    "        new_analog_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'analog_emg_signals.csv')\n",
    "        new_emg_mot_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'processed_emg_signals.mot')\n",
    "\n",
    "        try:\n",
    "            shutil.move(analog_csv_path, new_analog_path)\n",
    "            shutil.move(emg_mot_path, new_emg_mot_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually processing EMG data for TD children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emg_signals_manually(raw_emg_csv_path):\n",
    "    raw_emg_csv_path = Path(raw_emg_csv_path)\n",
    "\n",
    "    # === Manually define EMG channels depending on leg side ===\n",
    "\n",
    "    # For RIGHT leg trials â€” uncomment this block when needed\n",
    "    # columns_to_mot = [\n",
    "    #     'RGLTMED',\n",
    "    #     'RRF',\n",
    "    #     'RADDLONG',\n",
    "    #     'RST',\n",
    "    #     'RTA',\n",
    "    #     'RGM'\n",
    "    # ]\n",
    "\n",
    "    #For LEFT leg trials â€” uncomment this block instead\n",
    "    columns_to_mot = [\n",
    "        'LGLTMED',\n",
    "        'LRF',\n",
    "        'LADDLONG',\n",
    "        'LST',\n",
    "        'LTA',\n",
    "        'LGM'\n",
    "    ]\n",
    "\n",
    "    # === Process ===\n",
    "\n",
    "    print(f\"Processing EMG from: {raw_emg_csv_path}\")\n",
    "    print(f\"Using columns: {columns_to_mot}\")\n",
    "\n",
    "    # Step 1: Filter EMG\n",
    "    filtered_emg_path = filter_emg_signals(str(raw_emg_csv_path), columns_to_mot)\n",
    "\n",
    "    # Step 2: Normalize EMG\n",
    "    normalised_emg_path = amplitude_normalise(filtered_emg_path)\n",
    "\n",
    "    # Step 3: Convert to .mot\n",
    "    emg_mot_path = csv_to_mot(normalised_emg_path)\n",
    "\n",
    "    # Step 4: Move final .mot file to same folder\n",
    "    processed_emg_mot_path = raw_emg_csv_path.parent / 'processed_emg_signals.mot'\n",
    "    shutil.move(emg_mot_path, processed_emg_mot_path)\n",
    "\n",
    "    print(f\"Saved: {processed_emg_mot_path}\")\n",
    "    return str(processed_emg_mot_path)\n",
    "\n",
    "\n",
    "\n",
    "process_emg_signals_manually(\n",
    "    r\"C:\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\Simulations\\TD026\\normal3_l1\\trial3.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_folder = os.path.basename(c3dFilePath).replace('.c3d','')\n",
    "\n",
    "print(f\"Subject: {subject}\")\n",
    "print(f\"Trial: {trial_folder}\")\n",
    "legs = ['r', 'l']\n",
    "\n",
    "for leg in legs:\n",
    "    leg_folder_name = trial_folder + f'_{leg}1'\n",
    "    leg_folder = os.path.join(os.path.dirname(c3dFilePath), leg_folder_name)\n",
    "    if not os.path.exists(leg_folder):\n",
    "        os.mkdir(leg_folder)\n",
    "        print(f\"Folder created: {leg_folder}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {leg_folder}\")\n",
    "        \n",
    "    if leg == 'r':\n",
    "        columns_to_mot = ['RGLTMED','RRF','RADDLONG','RBF','RTA','RGM']\n",
    "    else:\n",
    "        columns_to_mot = ['LGLTMED','LRF','LADDLONG','LBF','LTA','LGM'] \n",
    "    \n",
    "    \n",
    "    # Export analog data to csv\n",
    "    analog_csv_path = export_analog(c3dFilePath, columns_to_mot=columns_to_mot)\n",
    "    \n",
    "    # Process EMG signals\n",
    "    filtered_emg_path = filter_emg_signals(analog_csv_path, columns_to_mot)\n",
    "\n",
    "    # Normalise amplitude of EMG signals\n",
    "    normalised_emg_path = amplitude_normalise(filtered_emg_path)\n",
    "    \n",
    "    # convert to mot\n",
    "    emg_mot_path = csv_to_mot(normalised_emg_path)\n",
    "    \n",
    "    # move the file to the leg folder\n",
    "    want_it = True\n",
    "    if want_it:\n",
    "        # move the file to the folder\n",
    "        new_analog_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'analog_emg_signals.csv')\n",
    "        new_emg_mot_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'processed_emg_signals.mot')\n",
    "\n",
    "        try:\n",
    "            shutil.move(analog_csv_path, new_analog_path)\n",
    "            shutil.move(emg_mot_path, new_emg_mot_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start all files from Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_l1'\n",
    "data = os_analysis.subjects[subject][trial_name].emg.data\n",
    "\n",
    "if data is None:\n",
    "    print(f\"EMG data for subject {subject}, trial {trial_name} is not loaded correctly.\")\n",
    "else:\n",
    "    print(\"EMG data loaded successfully.\")\n",
    "    data['time'] = data['time'] - data['time'].iloc[0]\n",
    "\n",
    "print(data)\n",
    "\n",
    "def save_new_emg_file(data, file_path):\n",
    "    header = header_mot(data, \"new_emg_signals\")\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(header + '\\n')\n",
    "        f.write('\\t'.join(map(str, data.columns)) + '\\n')\n",
    "        for index, row in data.iterrows():\n",
    "            f.write('\\t'.join(map(str, row.values)) + '\\n')\n",
    "    print(f\"New EMG data saved at: {file_path}\")\n",
    "\n",
    "new_emg_file_path = os.path.join(one_dir_up, 'Simulations', subject, trial_name, 'new_emg_signals.mot')\n",
    "save_new_emg_file(data, new_emg_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()\n",
    "\n",
    "subject = 'PC003'\n",
    "trial_name = 'trial1_l1'\n",
    "\n",
    "# Define relative paths to the files\n",
    "id_file = os_analysis.subjects[subject][trial_name].id.path\n",
    "ik_file = os_analysis.subjects[subject][trial_name].ik.path\n",
    "emg_file = os_analysis.subjects[subject][trial_name].emg.path\n",
    "\n",
    "# Load the files into Pandas DataFrames\n",
    "id_df = pd.read_csv(id_file, sep=\"\\t\", skiprows=6)  \n",
    "ik_df = pd.read_csv(ik_file, sep=\"\\t\", skiprows=5)\n",
    "emg_df = pd.read_csv(emg_file, sep=\"\\t\", skiprows=5) \n",
    "\n",
    "# Extract the time columns\n",
    "id_time = id_df['time'] if 'time' in id_df.columns else id_df.iloc[:, 0]\n",
    "ik_time = ik_df['time'] if 'time' in ik_df.columns else ik_df.iloc[:, 0]\n",
    "emg_time = emg_df['time'] if 'time' in emg_df.columns else emg_df.iloc[:, 0]\n",
    "\n",
    "\n",
    "# Convert time columns to float, handling any non-numeric values\n",
    "def convert_to_numeric(series):\n",
    "    return pd.to_numeric(series, errors='coerce').dropna()  # Convert and drop NaNs\n",
    "\n",
    "id_time = convert_to_numeric(id_time)\n",
    "ik_time = convert_to_numeric(ik_time)\n",
    "emg_time = convert_to_numeric(emg_time)\n",
    "\n",
    "# Combine time values into a set to remove duplicates\n",
    "unique_times = sorted(set(id_time).union(set(ik_time), set(emg_time)))\n",
    "\n",
    "# Convert to numpy array\n",
    "unique_time_array = np.array(unique_times)\n",
    "\n",
    "# Create a base DataFrame with unique_time_array as the time column\n",
    "new_df = pd.DataFrame({'time': unique_time_array})\n",
    "\n",
    "# Merge with id_df, ik_df, and emg_df using left join on 'time' column\n",
    "new_id_df = new_df.merge(id_df, on='time', how='left')\n",
    "new_ik_df = new_df.merge(ik_df, on='time', how='left')\n",
    "new_emg_df = new_df.merge(emg_df, on='time', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "def fill_nan_values(*dfs):\n",
    "    return [df.fillna(0) for df in dfs]\n",
    "\n",
    "new_id_df, new_ik_df, new_emg_df = fill_nan_values(new_id_df, new_ik_df, new_emg_df)\n",
    "\n",
    "# Save the synchronized DataFrames\n",
    "def save_files(base_path, id_df, ik_df, emg_df):\n",
    "    id_path = os.path.join(base_path, \"inverse_dynamics_synced.sto\")\n",
    "    ik_path = os.path.join(base_path, \"Visual3d_SIMM_input_synced.mot\")\n",
    "    emg_path = os.path.join(base_path, \"processed_emg_signals_synced.csv\")\n",
    "    \n",
    "    # Save EMG DataFrame as CSV\n",
    "    emg_df.to_csv(emg_path, index=False)\n",
    "    \n",
    "    # Save ID DataFrame as .sto\n",
    "    with open(id_path, 'w') as f:\n",
    "        f.write(\"inverse dynamics data\\nversion=1\\nnRows={}\\nnColumns={}\\ninDegrees=yes\\nendheader\\n\".format(len(id_df), len(id_df.columns)))\n",
    "        id_df.to_csv(f, sep='\\t', index=False)\n",
    "    \n",
    "    # Save IK DataFrame as .mot\n",
    "    with open(ik_path, 'w') as f:\n",
    "        f.write(\"Coordinates\\nversion=1\\nnRows={}\\nnColumns={}\\ninDegrees=yes\\nendheader\\n\".format(len(ik_df), len(ik_df.columns)))\n",
    "        ik_df.to_csv(f, sep='\\t', index=False)\n",
    "    \n",
    "    print(f\"Files saved:\\n{id_path}\\n{ik_path}\\n{emg_path}\")\n",
    "\n",
    "# Define the base path where the files will be saved\n",
    "base_path = os.path.join(one_dir_up, \"Simulations\", \"PC002\", \"trial2_r1\")\n",
    "\n",
    "# Save the synchronized DataFrames\n",
    "save_files(base_path, new_id_df, new_ik_df, new_emg_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check times in all files for simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()\n",
    "\n",
    "subject = 'TD026'\n",
    "trial_name = 'normal3_l1'\n",
    "\n",
    "#check times\n",
    "print(os_analysis.subjects[subject][trial_name].ik.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].id.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].emg.time_range)\n",
    "\n",
    "# Define relative paths to the files\n",
    "id_file = os_analysis.subjects[subject][trial_name].id.path\n",
    "ik_file = os_analysis.subjects[subject][trial_name].ik.path\n",
    "emg_file = os_analysis.subjects[subject][trial_name].emg.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial in trial_list:\n",
    "        try:\n",
    "            os_analysis.subjects[subject][trial].change_grf_xml_path()\n",
    "            os_analysis.subjects[subject][trial].run_ID(osim_modelPath=os_analysis.subjects[subject]['model'], \n",
    "                                                            coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "                                                            output_file=os_analysis.subjects[subject][trial].id.path, \n",
    "                                                            external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "                                                            LowpassCutoffFrequency=6, \n",
    "                                                            run_tool=True)\n",
    "            \n",
    "            print(f\"ID ran successfully for {subject} - {trial}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running ID for {subject} - {trial}\")\n",
    "            print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_SO(model_path, coordinates_file, actuators_file_path, run_tool=True):\n",
    "    '''\n",
    "    Function to run Static Optimization using the OpenSim API.\n",
    "    \n",
    "    Inputs:\n",
    "            modelpath(str): path to the OpenSim model file\n",
    "            trialpath(str): path to the trial folder\n",
    "            actuators_file_path(str): path to the actuators file\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    trialpath = os.path.dirname(coordinates_file)   \n",
    "    # create directories\n",
    "    results_directory = os.path.relpath(trialpath, trialpath)\n",
    "    coordinates_file =  os.path.relpath(trialpath, coordinates_file)\n",
    "    modelpath_relative = os.path.relpath(model_path, trialpath)\n",
    "\n",
    "    # create a local copy of the actuator file path and update name\n",
    "    actuators_file_path = os.path.relpath(actuators_file_path, trialpath)\n",
    "\n",
    "    # start model\n",
    "    OsimModel = msk.osim.Model(modelpath_relative)\n",
    "\n",
    "    # Get mot data to determine time range\n",
    "    motData = msk.osim.Storage(coordinates_file)\n",
    "\n",
    "    # Get initial and intial time\n",
    "    initial_time = motData.getFirstTime()\n",
    "    final_time = motData.getLastTime()\n",
    "\n",
    "    # Static Optimization\n",
    "    so = msk.osim.StaticOptimization()\n",
    "    so.setName('StaticOptimization')\n",
    "    so.setModel(OsimModel)\n",
    "\n",
    "    # Set other parameters as needed\n",
    "    so.setStartTime(initial_time)\n",
    "    so.setEndTime(final_time)\n",
    "    so.setMaxIterations(25)\n",
    "\n",
    "    analyzeTool_SO = msk.classes.osimSetup.create_analysis_tool(coordinates_file,modelpath_relative,results_directory)\n",
    "    analyzeTool_SO.getAnalysisSet().cloneAndAppend(so)\n",
    "    analyzeTool_SO.getForceSetFiles().append(actuators_file_path)\n",
    "    analyzeTool_SO.setReplaceForceSet(False)\n",
    "    OsimModel.addAnalysis(so)\n",
    "\n",
    "    analyzeTool_SO.printToXML(\".\\setup_so.xml\")\n",
    "\n",
    "    analyzeTool_SO = msk.osim.AnalyzeTool(\".\\setup_so.xml\")\n",
    "\n",
    "    trial = os.path.basename(trialpath)\n",
    "    print(f\"so for {trial}\")\n",
    "\n",
    "    # run\n",
    "    if run_tool:\n",
    "        analyzeTool_SO.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_SO(model_path=os_analysis.subjects[subject]['model'], \n",
    "        coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "        actuators_file_path=os_analysis.subjects[subject][trial].id.path, \n",
    "        external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "        LowpassCutoffFrequency=6, \n",
    "        run_tool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create CEINMS XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC006'\n",
    "trial_name = 'trial2_l1'\n",
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#check times\n",
    "print(os_analysis.subjects[subject][trial_name].ik.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].id.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].emg.time_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ['GLTMED', 'RF', 'ADDLONG', 'ST', 'TA', 'GM']\n",
    "\n",
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "            leg = trial_name[-2]\n",
    "            try:\n",
    "                trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "                subject_path = os.path.dirname(trial_path)\n",
    "                model = os.path.join(subject_path, f'{subject}_v3.osim')\n",
    "                \n",
    "                # check if IK file exists\n",
    "                if not os.path.exists(os_analysis.subjects[subject][trial_name].ik.path):\n",
    "                    try:\n",
    "                        shutil.rmtree(trial_path)\n",
    "                    except:\n",
    "                        pass \n",
    "                    \n",
    "                    print(f\"IK file not found for {subject} - {trial_name}. Skipping...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    # make ceims folder \n",
    "                    os.makedirs(os.path.join(trial_path, 'ceinms'), exist_ok=True)\n",
    "                \n",
    "                os_analysis.subjects[subject][trial_name].create_ceinms_files(osim_model_path=model,\n",
    "                                                                            leg=leg,\n",
    "                                                                            input_signals=signals)\n",
    "            except:\n",
    "                print(f\"Error creating CEINMS files for {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            print(f\"CEINMS files created for {subject} - {trial_name} - {leg}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEINMS calibration run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Git\\python-envs\\msk_modelling\\lib\\site-packages\\msk_modelling_python\\msk_modelling_python\\src\\ceinms2\\src\\CEINMScalibrate.exe -S c:\\Git\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\Simulations\\PC003\\trial1_r1\\ceinms\\calibrationSetup.xml\n"
     ]
    }
   ],
   "source": [
    "subject = 'PC003'\n",
    "trial_name = 'trial1_r1'\n",
    "xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_cal_setup.path\n",
    "os.path.join(os.path.dirname(current_dir), 'Simulations', subject, trial_name, 'ceinms', 'calibrationSetup.xml')\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "print(str(command))\n",
    "#print(os.getcwd())\n",
    "\n",
    "# result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "\n",
    "ceinms_install_path = r'C:\\Git\\python-envs\\msk_modelling\\Lib\\site-packages\\msk_modelling_python\\src\\ceinms2\\src'\n",
    "command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "result = subprocess.run(command, capture_output=True, text=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CEINMS execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC013'\n",
    "\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "xml_setup_file = r\"C:\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\Simulations\\PC013\\trial3_r1\\ceinms\\executionSetup.xml\"\n",
    "command = \" \".join([ceinms_install_path + \"\\CEINMS.exe -S\", xml_setup_file])\n",
    "\n",
    "os.chdir(os.path.dirname(xml_setup_file))\n",
    "print(command)\n",
    "result = subprocess.run(command)\n",
    "print(f'file save in {os.path.dirname(xml_setup_file)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data for TD children (only right leg)\n",
    "\n",
    "# subject_list = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "# trial_list = ['normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "# os_analysis = openSim(legs=['r'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "# # clear output\n",
    "# clear_output()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.getcwd()\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "\n",
    "# Uncomment the following line to run calibration for all subjects\n",
    "pc_subject_list = subject_list\n",
    "\n",
    "# Filter subject list to include only PC children\n",
    "#pc_subject_list = [subj for subj in subject_list if subj.startswith('PC')]\n",
    "\n",
    "for subject in pc_subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "        leg = trial_name[-2]\n",
    "        try:\n",
    "            trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "            # Change working directory to trial path\n",
    "            os.chdir(trial_path)\n",
    "            \n",
    "            xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_cal_setup.path\n",
    "            \n",
    "            command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "            \n",
    "            result = subprocess.run(command, capture_output=True, text=True, check=True)            \n",
    "\n",
    "            print(f\"Calibration successful for {subject} - {trial_name} - {leg}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running calibration for {subject} - {trial_name} - {leg}\")\n",
    "            print(e)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.getcwd()\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "\n",
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "            leg = trial_name[-2]\n",
    "            try:\n",
    "                trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "                \n",
    "                \n",
    "                xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_execution_setup.path\n",
    "                tree = ET.parse(xml_setup_file)\n",
    "                root = tree.getroot()\n",
    "                output_dir = root.find('.//outputDirectory').text\n",
    "                output_dir = os.path.join(os.path.dirname(xml_setup_file), output_dir)\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                \n",
    "                # change working directory to trial path\n",
    "                os.chdir(output_dir)\n",
    "                                \n",
    "                command = \" \".join([ceinms_install_path + \"\\CEINMS.exe -S\", xml_setup_file])\n",
    "                \n",
    "                result = subprocess.run(command)            \n",
    "\n",
    "                print(f\"Execution successful for {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            except:\n",
    "                print(f\"Error on {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            print(f\"CEINMS done for {subject} - {trial_name} - {leg}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(xml_setup_file)\n",
    "root = tree.getroot()\n",
    "output_dir = root.find('.//outputDirectory').text\n",
    "output_dir = os.path.join(os.path.dirname(xml_setup_file), output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare CEINMS forces with SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_r1'\n",
    "simulations_dir = r\"C:\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\Simulations\"\n",
    "ceinms_forces = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'MuscleForces.sto'))\n",
    "so_forces = import_file(os.path.join(simulations_dir, subject, trial_name, 'Results_SO_and_MA', 'StaticOptimization_force.sto'))\n",
    "\n",
    "# print(ceinms_forces)\n",
    "# print(so_forces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the data to the same time range\n",
    "start_time = max(ceinms_forces['time'].iloc[0], so_forces['time'].iloc[0])\n",
    "end_time = min(ceinms_forces['time'].iloc[-1], so_forces['time'].iloc[-1])\n",
    "\n",
    "ceinms_forces = ceinms_forces[(ceinms_forces['time'] >= start_time) & (ceinms_forces['time'] <= end_time)]\n",
    "so_forces = so_forces[(so_forces['time'] >= start_time) & (so_forces['time'] <= end_time)]\n",
    "\n",
    "muscles_to_plot = [\n",
    "    'glut_med1_r', 'glut_med2_r', 'glut_med3_r', 'glut_min1_r', 'glut_min2_r', 'glut_min3_r', \n",
    "    'semimem_r', 'semiten_r', 'bifemlh_r', 'bifemsh_r', 'sar_r', 'add_long_r', 'add_brev_r', \n",
    "    'add_mag1_r', 'add_mag2_r', 'add_mag3_r', 'tfl_r', 'pect_r', 'grac_r', 'glut_max1_r', \n",
    "    'glut_max2_r', 'glut_max3_r', 'iliacus_r', 'psoas_r', 'quad_fem_r', 'gem_r', 'peri_r', \n",
    "    'rect_fem_r', 'vas_med_r', 'vas_int_r', 'vas_lat_r', 'med_gas_r', 'lat_gas_r', 'soleus_r', \n",
    "    'tib_post_r', 'flex_dig_r', 'flex_hal_r', 'tib_ant_r', 'per_brev_r', 'per_long_r', 'per_tert_r', \n",
    "    'ext_dig_r', 'ext_hal_r', 'glut_med1_l', 'glut_med2_l', 'glut_med3_l', 'glut_min1_l', 'glut_min2_l', \n",
    "    'glut_min3_l', 'semimem_l', 'semiten_l', 'bifemlh_l', 'bifemsh_l', 'sar_l', 'add_long_l', 'add_brev_l', \n",
    "    'add_mag1_l', 'add_mag2_l', 'add_mag3_l', 'tfl_l', 'pect_l', 'grac_l', 'glut_max1_l', 'glut_max2_l', \n",
    "    'glut_max3_l', 'iliacus_l', 'psoas_l', 'quad_fem_l', 'gem_l', 'peri_l', 'rect_fem_l', 'vas_med_l', \n",
    "    'vas_int_l', 'vas_lat_l', 'med_gas_l', 'lat_gas_l', 'soleus_l', 'tib_post_l', 'flex_dig_l', 'flex_hal_l', \n",
    "    'tib_ant_l', 'per_brev_l', 'per_long_l', 'per_tert_l', 'ext_dig_l', 'ext_hal_l', 'ercspn_r', 'ercspn_l', \n",
    "    'intobl_r', 'intobl_l', 'extobl_r', 'extobl_l'\n",
    "]\n",
    "colours = ['b', 'r']\n",
    "fig, axes = plt.subplots(len(muscles_to_plot), 1, figsize=(10, 5 * len(muscles_to_plot)))\n",
    "\n",
    "for i, muscle in enumerate(muscles_to_plot):\n",
    "    \n",
    "    if muscle not in ceinms_forces.columns:\n",
    "        continue\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ceinms_color = 'b'\n",
    "    so_color = 'r'\n",
    "    ax.plot(ceinms_forces['time'], ceinms_forces[muscle], label=f'CEINMS - {muscle}', color=ceinms_color)\n",
    "    ax.plot(so_forces['time'], so_forces[muscle], label=f'SO - {muscle}', color=so_color)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Force (N)')\n",
    "    ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Force (N)')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading files for the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC013'\n",
    "trial_name = 'trial3_r1'\n",
    "leg = 'r'\n",
    "simulations_dir = Path(r\"C:\\Git\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\Simulations\")\n",
    "ceinms_activations = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'Activations.sto'))\n",
    "so_activations = import_file(os.path.join(simulations_dir, subject, trial_name, 'Results_SO_and_MA', 'StaticOptimization_activation.sto'))\n",
    "emg_data = import_file(os.path.join(simulations_dir, subject, trial_name, 'processed_emg_signals.mot'))\n",
    "so_force = import_file(os.path.join(simulations_dir, subject, trial_name, 'Results_SO_and_MA', 'StaticOptimization_force.sto'))\n",
    "torques = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'Torques.sto'))\n",
    "id = import_file(os.path.join(simulations_dir, subject, trial_name, 'inverse_dynamics.sto'))\n",
    "pc_muscle_forces = import_file(os.path.join(simulations_dir, subject, trial_name, 'ceinms', 'execution', 'MuscleForces.sto'))\n",
    "\n",
    "\n",
    "joint_suffix = {\n",
    "    'hip': {\n",
    "        'so': f'hip_flexion_{leg}',\n",
    "        'ceinms': f'hip_flexion_{leg}',\n",
    "        'id': f'hip_flexion_{leg}_moment'\n",
    "    },\n",
    "    'knee': {\n",
    "        'so': f'knee_angle_{leg}',\n",
    "        'ceinms': f'knee_angle_{leg}',\n",
    "        'id': f'knee_angle_{leg}_moment'\n",
    "    },\n",
    "    'ankle': {\n",
    "        'so': f'ankle_angle_{leg}',\n",
    "        'ceinms': f'ankle_angle_{leg}',\n",
    "        'id': f'ankle_angle_{leg}_moment'\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Load moment arm files ===\n",
    "moment_arm_files = {\n",
    "    joint: os.path.join(\n",
    "        simulations_dir, subject, trial_name, 'Results_SO_and_MA',\n",
    "        f'MuscleAnalysis_MomentArm_{joint_suffix[joint][\"so\"]}.sto'\n",
    "    )\n",
    "    for joint in ['hip', 'knee', 'ankle']\n",
    "}\n",
    "\n",
    "# === Load the files into DataFrames\n",
    "moment_arms = {\n",
    "    joint_suffix[joint]['so']: import_file(path)\n",
    "    for joint, path in moment_arm_files.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop data to the common range for the activation comparison\n",
    "\n",
    "start_time = max(ceinms_activations['time'].iloc[0], so_activations['time'].iloc[0], emg_data['time'].iloc[0])\n",
    "end_time   = min(ceinms_activations['time'].iloc[-1], so_activations['time'].iloc[-1], emg_data['time'].iloc[-1])\n",
    "\n",
    "ceinms_activations = ceinms_activations[(ceinms_activations['time'] >= start_time) & (ceinms_activations['time'] <= end_time)]\n",
    "so_activations     = so_activations[(so_activations['time'] >= start_time) & (so_activations['time'] <= end_time)]\n",
    "emg_data           = emg_data[(emg_data['time'] >= start_time) & (emg_data['time'] <= end_time)]\n",
    "\n",
    "\n",
    "# Normalize Time to Percentage of Single Leg Support\n",
    "\n",
    "sls_duration = end_time - start_time\n",
    "so_activations     = normalize_time_act(so_activations, start_time, sls_duration)\n",
    "ceinms_activations = normalize_time_act(ceinms_activations, start_time, sls_duration)\n",
    "emg_data           = normalize_time_act(emg_data, start_time, sls_duration)\n",
    "\n",
    "\n",
    "# EMG MAPPING and Filter Valid Muscles\n",
    "\n",
    "\n",
    "emg_mappings = {\n",
    "    'glut_med1_r': 'RGLTMED', 'glut_med2_r': 'RGLTMED', 'glut_med3_r': 'RGLTMED',\n",
    "    'glut_min1_r': 'RGLTMED', 'glut_min2_r': 'RGLTMED', 'glut_min3_r': 'RGLTMED',\n",
    "    'glut_max1_r': 'RGLTMED', 'glut_max2_r': 'RGLTMED', 'glut_max3_r': 'RGLTMED',\n",
    "    'add_brev_r': 'RADDLONG', 'add_long_r': 'RADDLONG', 'grac_r': 'RADDLONG',\n",
    "    'bifemlh_r': 'RBF', 'bifemsh_r': 'RBF', 'semimem_r': 'RBF', 'semiten_r': 'RBF',\n",
    "    'tib_ant_r': 'RTA', 'ext_dig_r': 'RTA', 'ext_hal_r': 'RTA',\n",
    "    'vas_med_r': 'RRF', 'vas_int_r': 'RRF', 'vas_lat_r': 'RRF', 'rect_fem_r': 'RRF',\n",
    "    'med_gas_r': 'RGM', 'lat_gas_r': 'RGM', 'soleus_r': 'RGM'\n",
    "}\n",
    "\n",
    "valid_muscles = [\n",
    "    muscle for muscle, emg_channel in emg_mappings.items()\n",
    "    if muscle in ceinms_activations.columns and\n",
    "       muscle in so_activations.columns and\n",
    "       emg_channel in emg_data.columns\n",
    "]\n",
    "\n",
    "\n",
    "# Plotting the Activation Comparisons with RMSE/RÂ² Annotations\n",
    "\n",
    "n = len(valid_muscles)\n",
    "cols = 6\n",
    "rows = int(np.ceil(n / cols))\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# We'll use so_activations as the reference for the common time grid\n",
    "target_length = len(so_activations['time'])\n",
    "\n",
    "for i, muscle in enumerate(valid_muscles):\n",
    "    emg_channel = emg_mappings[muscle]\n",
    "    \n",
    "    # Extract the curves from each DataFrame\n",
    "    x_so = so_activations['time']\n",
    "    y_so = so_activations[muscle]\n",
    "    \n",
    "    x_ceinms = ceinms_activations['time']\n",
    "    y_ceinms = ceinms_activations[muscle]\n",
    "    \n",
    "    x_emg = emg_data['time']\n",
    "    y_emg = emg_data[emg_channel]\n",
    "    \n",
    "    # Resample CEINMS and EMG curves to the target length if needed:\n",
    "    if len(x_ceinms) != target_length:\n",
    "        x_ceinms, y_ceinms = resample_curve(x_ceinms, y_ceinms, target_length)\n",
    "    if len(x_emg) != target_length:\n",
    "        x_emg, y_emg = resample_curve(x_emg, y_emg, target_length)\n",
    "\n",
    "    \n",
    "    # Plot the activation curves using the same time grid \n",
    "    axes[i].plot(x_so, y_ceinms, label='CEINMS', color='blue')\n",
    "    axes[i].plot(x_so, y_so, label='SO', color='orange')\n",
    "    axes[i].plot(x_so, y_emg, label='EMG', color='black')\n",
    "    axes[i].set_title(muscle)\n",
    "    axes[i].set_ylim(0, 1)\n",
    "    axes[i].set_xlim(0, 100)\n",
    "    \n",
    "    # Compute RMSE and RÂ²: compare to EMG \n",
    "    so_rmse, so_r2 = compute_rmse_r2(y_emg, y_so)\n",
    "    ceinms_rmse, ceinms_r2 = compute_rmse_r2(y_emg, y_ceinms)\n",
    "    \n",
    "    # Annotate the subplot with the computed metrics\n",
    "    annotation_text = (f\"SO: RMSE={so_rmse:.2f}, RÂ²={so_r2:.2f}\\n\"\n",
    "                       f\"CEINMS: RMSE={ceinms_rmse:.2f}, RÂ²={ceinms_r2:.2f}\")\n",
    "    axes[i].text(0.03, 0.97, annotation_text, transform=axes[i].transAxes, fontsize=8,\n",
    "                 verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5, pad=4))\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[n:]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "fig.suptitle(\"CEINMS vs SO Activations vs EMG\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Single Leg Support (%)', ha='center')  \n",
    "fig.text(0.001, 0.5, 'Excitation / EMG Amplitude', va='center', rotation='vertical')  \n",
    "fig.legend(['CEINMS', 'SO', 'EMG'], loc='lower right')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# save figure in the folder\n",
    "fig.savefig(os.path.join(simulations_dir, subject, trial_name, 'activations_comparison.png'), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare joint moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop all data to shared time range for joint moment comparison\n",
    "start_time = max(\n",
    "    so_force['time'].iloc[0],\n",
    "    torques['time'].iloc[0],\n",
    "    id['time'].iloc[0]\n",
    ")\n",
    "end_time = min(\n",
    "    so_force['time'].iloc[-1],\n",
    "    torques['time'].iloc[-1],\n",
    "    id['time'].iloc[-1]\n",
    ")\n",
    "\n",
    "\n",
    "so_force = crop_time(so_force)\n",
    "torques = crop_time(torques)\n",
    "inverse_dynamics = crop_time(id)\n",
    "\n",
    "for ma_key in moment_arms:\n",
    "    moment_arms[ma_key] = crop_time(moment_arms[ma_key])\n",
    "\n",
    "# Normalize time to percentage of single leg support \n",
    "sls_duration = end_time - start_time\n",
    "\n",
    "so_force = normalize_time(so_force)\n",
    "torques = normalize_time(torques)\n",
    "inverse_dynamics = normalize_time(inverse_dynamics)\n",
    "for ma_key in moment_arms:\n",
    "    moment_arms[ma_key] = normalize_time(moment_arms[ma_key])\n",
    "\n",
    "# Compute SO joint moments (sum force Ã— moment arm)\n",
    "so_moments = {'time': so_force['time']}\n",
    "for joint_key in joint_suffix:\n",
    "    so_name = joint_suffix[joint_key]['so']\n",
    "    ma_df = moment_arms[so_name]\n",
    "    common_muscles = [m for m in ma_df.columns if m in so_force.columns and m != 'time']\n",
    "    moment = sum(so_force[m] * ma_df[m] for m in common_muscles)\n",
    "    so_moments[so_name] = moment.values  # ensure the moment values are arrays\n",
    "\n",
    "so_df = pd.DataFrame(so_moments)\n",
    "\n",
    "# Plot the results and compute metrics\n",
    "label_map = {\n",
    "    'hip': 'Hip flex/ext',\n",
    "    'knee': 'Knee flex/ext',\n",
    "    'ankle': 'Ankle dorsi/plantar'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, joint_key in enumerate(['hip', 'knee', 'ankle']):\n",
    "    joint_names = joint_suffix[joint_key]\n",
    "\n",
    "    # Extract columns\n",
    "    time_id = inverse_dynamics['time']\n",
    "    id_moment = inverse_dynamics[joint_names['id']]\n",
    "    \n",
    "    time_so = so_df['time']\n",
    "    so_moment = so_df[joint_names['so']]\n",
    "    \n",
    "    time_ceinms = torques['time']\n",
    "    ceinms_moment = torques[joint_names['ceinms']]\n",
    "\n",
    "    # Compute RMSE and RÂ² (SO vs ID)\n",
    "    so_rmse, so_r2 = compute_rmse_r2(id_moment, so_moment)\n",
    "    \n",
    "    # Compute RMSE and RÂ² (CEINMS vs ID)\n",
    "    ceinms_rmse, ceinms_r2 = compute_rmse_r2(id_moment, ceinms_moment)\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.plot(time_id, id_moment, label='Inverse Dynamics', color='black', linewidth=2.0)\n",
    "    ax.plot(time_so, so_moment, label='Static Optimization', color='orange', linewidth=2.0, linestyle='--')\n",
    "    ax.plot(time_ceinms, ceinms_moment, label='CEINMS', color='blue', linewidth=2.0)\n",
    "\n",
    "\n",
    "    ax.axhline(0, color='gray', linestyle='--')\n",
    "    ax.set_title(label_map[joint_key])\n",
    "    ax.set_xlim(0, 100)  # clamp x-axis to 0â€“100%\n",
    "    ax.set_xlabel('Single Leg Support (%)')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Moment (Nm)')\n",
    "    if i == 2:\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "    # Remove top/right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Annotate the subplot with RMSE and RÂ²\n",
    "    annotation_text = (f\"SO: RMSE={so_rmse:.2f}, RÂ²={so_r2:.2f}\\n\"\n",
    "                       f\"CEINMS: RMSE={ceinms_rmse:.2f}, RÂ²={ceinms_r2:.2f}\")\n",
    "    ax.text(0.05, 0.90, annotation_text, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5, pad=5))\n",
    "\n",
    "fig.suptitle(f'Joint Moment Comparison (Leg: {leg.upper()}, Subject: {subject}, Trial: {trial_name})', fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare muscle forces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject groups\n",
    "cp_subjects = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "\n",
    "# Trial types\n",
    "cp_trials = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "# Muscle groups (right leg only)\n",
    "muscle_groups = {\n",
    "    'hip_extensors': ['add_long_r', 'add_mag1_r', 'add_mag2_r', 'add_mag3_r', 'bifemlh_r', 'glut_max1_r', 'glut_max2_r', 'glut_max3_r', 'glut_med3_r', 'glut_min3_r', 'semimem_r', 'semiten_r'],\n",
    "    'hip_flexors': ['add_brev_r', 'add_long_r', 'glut_med1_r', 'glut_min1_r', 'grac_r', 'iliacus_r', 'pect_r', 'psoas_r', 'rect_fem_r', 'sar_r', 'tfl_r'],\n",
    "    'knee_extensors': ['rect_fem_r', 'vas_int_r', 'vas_lat_r', 'vas_med_r'],\n",
    "    'knee_flexors': ['bifemlh_r', 'bifemsh_r', 'grac_r', 'lat_gas_r', 'med_gas_r', 'sar_r', 'semimem_r', 'semiten_r'],\n",
    "    'ankle_plantarflexors': ['flex_dig_r', 'flex_hal_r', 'lat_gas_r', 'med_gas_r', 'per_brev_r', 'per_long_r', 'soleus_r', 'tib_post_r'],\n",
    "    'ankle_dorsiflexors': ['ext_dig_r', 'ext_hal_r', 'per_tert_r', 'tib_ant_r']\n",
    "}\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "def load_sto(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    start_idx = next(i for i, line in enumerate(lines) if 'endheader' in line.lower()) + 1\n",
    "    return pd.read_csv(StringIO(''.join(lines[start_idx:])), delim_whitespace=True)\n",
    "\n",
    "def resample_to_percent_phase(series, target_len=101):\n",
    "    n = series.shape[0]\n",
    "    old_x = np.linspace(0, 100, n)\n",
    "    new_x = np.linspace(0, 100, target_len)\n",
    "    if isinstance(series, pd.Series):\n",
    "        f = interp1d(old_x, series.values, kind='linear')\n",
    "        return pd.Series(f(new_x))\n",
    "    elif isinstance(series, pd.DataFrame):\n",
    "        return pd.DataFrame({col: interp1d(old_x, series[col].values, kind='linear')(new_x) for col in series.columns})\n",
    "\n",
    "def process_subject(subject, trial):\n",
    "    trial_path = simulations_dir / subject / trial / 'ceinms' / 'execution' / 'MuscleForces.sto'\n",
    "    if not trial_path.exists():\n",
    "        print(f\"File not found: {trial_path}\")\n",
    "        return {}\n",
    "    df = load_sto(trial_path)\n",
    "    trial_data = {}\n",
    "    for group_name, muscle_list in muscle_groups.items():\n",
    "        valid_cols = [m for m in muscle_list if m in df.columns]\n",
    "        if valid_cols:\n",
    "            group_df = df[valid_cols]\n",
    "            group_df_resampled = resample_to_percent_phase(group_df)\n",
    "            trial_data[group_name] = group_df_resampled\n",
    "    return trial_data\n",
    "\n",
    "# === LOAD DATA ===\n",
    "cp_data_all = []\n",
    "td_crouch_data_all = []\n",
    "td_normal_data_all = []\n",
    "\n",
    "for subject in cp_subjects:\n",
    "    for trial in cp_trials:\n",
    "        data = process_subject(subject, trial)\n",
    "        if data:\n",
    "            cp_data_all.append(data)\n",
    "\n",
    "for subject in td_subjects:\n",
    "    for trial in td_crouch_trials:\n",
    "        data = process_subject(subject, trial)\n",
    "        if data:\n",
    "            td_crouch_data_all.append(data)\n",
    "\n",
    "for subject in td_subjects:\n",
    "    for trial in td_normal_trials:\n",
    "        data = process_subject(subject, trial)\n",
    "        if data:\n",
    "            td_normal_data_all.append(data)\n",
    "\n",
    "print(f\"Loaded {len(cp_data_all)} CP trials\")\n",
    "print(f\"Loaded {len(td_crouch_data_all)} TD crouch trials\")\n",
    "print(f\"Loaded {len(td_normal_data_all)} TD normal trials\")\n",
    "\n",
    "# === PLOTTING ===\n",
    "\n",
    "group_labels = ['CP', 'TD_crouch', 'TD_normal']\n",
    "group_data_list = [cp_data_all, td_crouch_data_all, td_normal_data_all]\n",
    "group_trial_map = dict(zip(group_labels, group_data_list))\n",
    "\n",
    "num_groups = len(muscle_groups)\n",
    "cols = 2\n",
    "rows = (num_groups + 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), constrained_layout=True, gridspec_kw={'left': 0.8})\n",
    "axes = axes.flatten()\n",
    "\n",
    "x_label_groups = ['ankle_plantarflexors', 'ankle_dorsiflexors']\n",
    "y_tick_groups = ['hip_extensors', 'knee_extensors', 'ankle_plantarflexors']\n",
    "legend_handles = []\n",
    "\n",
    "# Custom y-limits\n",
    "custom_y_max = {\n",
    "    'hip_flexors': 500,\n",
    "    'knee_flexors': 1400,\n",
    "    'ankle_dorsiflexors': 700,\n",
    "    'ankle_plantarflexors': 700\n",
    "}\n",
    "\n",
    "# === Start plotting ===\n",
    "for idx, (group_name, _) in enumerate(muscle_groups.items()):\n",
    "    ax = axes[idx]\n",
    "    plotted = False\n",
    "\n",
    "    for label, data_all in zip(group_labels, group_data_list):\n",
    "        all_series = []\n",
    "\n",
    "        for trial_data in data_all:\n",
    "            if group_name in trial_data:\n",
    "                series = trial_data[group_name]\n",
    "                if isinstance(series, pd.DataFrame):\n",
    "                    all_series.extend([series[col] for col in series.columns])\n",
    "                elif isinstance(series, pd.Series):\n",
    "                    all_series.append(series)\n",
    "\n",
    "        if all_series:\n",
    "            df_group = pd.concat(all_series, axis=1)\n",
    "            mean = df_group.mean(axis=1)\n",
    "            std_err = df_group.std(axis=1) / np.sqrt(df_group.shape[1])\n",
    "            ci = 1.96 * std_err\n",
    "\n",
    "            x_percent = np.linspace(0, 100, len(mean))\n",
    "            line, = ax.plot(x_percent, mean, label=label)\n",
    "            ax.fill_between(x_percent, mean - ci, mean + ci, alpha=0.2, color=line.get_color())\n",
    "\n",
    "            if label not in [h.get_label() for h in legend_handles]:\n",
    "                legend_handles.append(line)\n",
    "\n",
    "            plotted = True\n",
    "\n",
    "    ax.set_title(group_name.replace('_', ' ').title())\n",
    "    ax.set_xlim(0, 100)\n",
    "\n",
    "    # Apply custom y-limits\n",
    "    if group_name in custom_y_max:\n",
    "        ax.set_ylim(top=custom_y_max[group_name])\n",
    "\n",
    "    if group_name in x_label_groups:\n",
    "        ax.set_xlabel(\"Single Leg Support Phase (%)\")\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    if group_name in y_tick_groups:\n",
    "        ax.tick_params(axis='y', labelleft=True)\n",
    "    else:\n",
    "        ax.tick_params(axis='y', left=False, labelleft=False)\n",
    "\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    if not plotted:\n",
    "        ax.text(50, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "# Hide unused axes\n",
    "for i in range(len(muscle_groups), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Shared legend and y-axis label\n",
    "fig.legend(handles=legend_handles[:len(group_labels)], labels=group_labels,\n",
    "           loc='center left', bbox_to_anchor=(1.01, 0.5), frameon=False)\n",
    "fig.suptitle(\"Muscle Force Comparison (Right Leg, 0â€“100% SLS)\", fontsize=16)\n",
    "fig.text(-0.01, 0.5, \"Force (N)\", va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muscle force plots only for CP children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subjects = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "pc_trials = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "\n",
    "all_trials = []\n",
    "\n",
    "for subject in pc_subjects:\n",
    "    for trial in pc_trials:\n",
    "        path = simulations_dir / subject / trial / 'ceinms' / 'execution' / 'MuscleForces.sto'\n",
    "        if path.exists():\n",
    "            df = load_sto(path)\n",
    "            trial_data = {}\n",
    "            for group, muscles in muscle_groups.items():\n",
    "                valid = [m for m in muscles if m in df.columns]\n",
    "                if valid:\n",
    "                    group_df = df[valid]\n",
    "                    trial_data[group] = resample_to_percent_phase(group_df)\n",
    "            all_trials.append((subject, trial_data))\n",
    "        else:\n",
    "            print(f\" Missing: {path}\")\n",
    "\n",
    "# Plotting\n",
    "\n",
    "colors = {\n",
    "    'PC002': 'tab:blue',\n",
    "    'PC003': 'tab:orange',\n",
    "    'PC006': 'tab:green',\n",
    "    'PC013': 'tab:red'\n",
    "}\n",
    "\n",
    "num_groups = len(muscle_groups)\n",
    "cols = 2\n",
    "rows = (num_groups + 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "legend_labels = {}\n",
    "\n",
    "for idx, (group, _) in enumerate(muscle_groups.items()):\n",
    "    ax = axes[idx]\n",
    "    for subject, trial_data in all_trials:\n",
    "        if group in trial_data:\n",
    "            df = trial_data[group]\n",
    "            mean_force = df.mean(axis=1)\n",
    "            x = np.linspace(0, 100, len(mean_force))\n",
    "            label = subject if subject not in legend_labels else None\n",
    "            ax.plot(x, mean_force, color=colors[subject], label=label)\n",
    "            legend_labels[subject] = colors[subject]\n",
    "    ax.set_title(group.replace('_', ' ').title())\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_xlabel(\"Single Leg Support Phase (%)\")\n",
    "    ax.set_ylabel(\"Force (N)\")\n",
    "    ax.grid(False)\n",
    "\n",
    "# Hide extra axes\n",
    "for i in range(len(muscle_groups), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Custom clean legend\n",
    "handles = [plt.Line2D([0], [0], color=clr, lw=2) for subj, clr in legend_labels.items()]\n",
    "labels = list(legend_labels.keys())\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.01, 0.5), frameon=False)\n",
    "\n",
    "fig.suptitle(\"Individual Muscle Forces - PC Subjects\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muscle forces CP Children (normalised to MVIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subjects = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "pc_trials = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "\n",
    "all_trials = []\n",
    "\n",
    "for subject in pc_subjects:\n",
    "    for trial in pc_trials:\n",
    "        path = simulations_dir / subject / trial / 'ceinms' / 'execution' / 'MuscleForces.sto'\n",
    "        ceinms_model_path = simulations_dir / subject / trial / 'ceinms' / 'calibratedSubject.xml'\n",
    "        \n",
    "        xml_ceimns = msk.XMLTools(ceinms_model_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subjects = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "pc_trials = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "\n",
    "all_trials = []\n",
    "\n",
    "for subject in pc_subjects:\n",
    "    for trial in pc_trials:\n",
    "        path = simulations_dir / subject / trial / 'ceinms' / 'execution' / 'MuscleForces.sto'\n",
    "        ceinms_model_path = simulations_dir / subject / trial / 'ceinms' / 'calibratedSubject.xml'\n",
    "        \n",
    "        xml_ceimns = msk.XMLTools.load(ceinms_model_path)\n",
    "        \n",
    "        if path.exists():\n",
    "            df = load_sto(path)\n",
    "            trial_data = {}\n",
    "            for group, muscles in muscle_groups.items():\n",
    "                valid = [m for m in muscles if m in df.columns]\n",
    "                if valid:\n",
    "                    group_df = df[valid]\n",
    "                    trial_data[group] = resample_to_percent_phase(group_df)\n",
    "            all_trials.append((subject, trial_data))\n",
    "        else:\n",
    "            print(f\" Missing: {path}\")\n",
    "\n",
    "# Plotting\n",
    "\n",
    "colors = {\n",
    "    'PC002': 'tab:blue',\n",
    "    'PC003': 'tab:orange',\n",
    "    'PC006': 'tab:green',\n",
    "    'PC013': 'tab:red'\n",
    "}\n",
    "\n",
    "num_groups = len(muscle_groups)\n",
    "cols = 2\n",
    "rows = (num_groups + 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), constrained_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "legend_labels = {}\n",
    "\n",
    "for idx, (group, _) in enumerate(muscle_groups.items()):\n",
    "    ax = axes[idx]\n",
    "    for subject, trial_data in all_trials:\n",
    "        if group in trial_data:\n",
    "            df = trial_data[group]\n",
    "            mean_force = df.mean(axis=1)\n",
    "            os_analysis.subjects[subject][trial_name]\n",
    "            x = np.linspace(0, 100, len(mean_force))\n",
    "            label = subject if subject not in legend_labels else None\n",
    "            ax.plot(x, mean_force, color=colors[subject], label=label)\n",
    "            legend_labels[subject] = colors[subject]\n",
    "    ax.set_title(group.replace('_', ' ').title())\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_xlabel(\"Single Leg Support Phase (%)\")\n",
    "    ax.set_ylabel(\"Force (N)\")\n",
    "    ax.grid(False)\n",
    "\n",
    "# Hide extra axes\n",
    "for i in range(len(muscle_groups), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Custom clean legend\n",
    "handles = [plt.Line2D([0], [0], color=clr, lw=2) for subj, clr in legend_labels.items()]\n",
    "labels = list(legend_labels.keys())\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.01, 0.5), frameon=False)\n",
    "\n",
    "fig.suptitle(\"Individual Muscle Forces - PC Subjects\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating RMSE and R squared for muscle activations and joint moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "\n",
    "def resample_to_percent_phase(df, target_len=101):\n",
    "    \"\"\"\n",
    "    Resample a DataFrame with a time (or percent phase) column to exactly `target_len` rows.\n",
    "    The function assumes that the rows are in order along the phase/time axis.\n",
    "    \"\"\"\n",
    "    n = df.shape[0]\n",
    "    old_x = np.linspace(0, 100, n)\n",
    "    new_x = np.linspace(0, 100, target_len)\n",
    "    resampled_data = {}\n",
    "    for col in df.columns:\n",
    "        if col == 'time':\n",
    "            resampled_data[col] = new_x\n",
    "        else:\n",
    "            f = interp1d(old_x, df[col].values, kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled_data[col] = f(new_x)\n",
    "    return pd.DataFrame(resampled_data)\n",
    "\n",
    "def crop_time(df, start_time, end_time):\n",
    "    \"\"\"Crop DataFrame rows to data between start_time and end_time.\"\"\"\n",
    "    return df[(df['time'] >= start_time) & (df['time'] <= end_time)].reset_index(drop=True)\n",
    "\n",
    "def normalize_time(df, start_time, duration):\n",
    "    \"\"\"\n",
    "    Normalize the 'time' column to a percentage scale (0-100) using given start_time and duration.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['time'] = 100 * (df['time'] - start_time) / duration\n",
    "    return df\n",
    "\n",
    "def compute_rmse_r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute RMSE and RÂ² between two 1D arrays (or Series).\n",
    "    If arrays have different lengths, y_pred is interpolated onto y_true's grid.\n",
    "    Ignores indices with NaN values.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    # If lengths differ, interpolate y_pred onto y_true's grid:\n",
    "    if len(y_true) != len(y_pred):\n",
    "        x_old = np.linspace(0, 1, len(y_pred))\n",
    "        x_new = np.linspace(0, 1, len(y_true))\n",
    "        y_pred = np.interp(x_new, x_old, y_pred)\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan, np.nan\n",
    "    y_true_clean = y_true[mask]\n",
    "    y_pred_clean = y_pred[mask]\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
    "    r2 = r2_score(y_true_clean, y_pred_clean)\n",
    "    return rmse, r2\n",
    "\n",
    "def fix_time_scale(df, expected_inc=0.01, factor=10):\n",
    "    \"\"\"\n",
    "    Check the median time increment of the DataFrame.\n",
    "    If it is significantly lower than expected_inc, multiply the 'time'\n",
    "    column by the specified factor. This is used for TD data.\n",
    "    \"\"\"\n",
    "    dt = df['time'].diff().median()\n",
    "    if dt < expected_inc * 0.5:\n",
    "        df = df.copy()\n",
    "        df['time'] *= factor\n",
    "    return df\n",
    "\n",
    "def compute_so_joint_moments(so_force, moment_arms, joint_suffix):\n",
    "    \"\"\"\n",
    "    Compute SO joint moments by summing the product of force and moment arm\n",
    "    for each joint and return the results as a DataFrame.\n",
    "    \"\"\"\n",
    "    so_moments = {\"time\": so_force[\"time\"]}\n",
    "    for joint_key in joint_suffix:\n",
    "        so_name = joint_suffix[joint_key][\"so\"]\n",
    "        ma_df = moment_arms[so_name]\n",
    "        # Determine common muscle columns that exist in both so_force and the moment arm file,\n",
    "        # excluding the 'time' column.\n",
    "        common_muscles = [m for m in ma_df.columns if m in so_force.columns and m != \"time\"]\n",
    "        # Use the original sum() without np.nansum if youâ€™re confident there are no NaNs.\n",
    "        moment = sum(so_force[m] * ma_df[m] for m in common_muscles)\n",
    "        so_moments[so_name] = moment.values\n",
    "    return pd.DataFrame(so_moments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjects & trials \n",
    "cp_subjects = ['PC002', 'PC003', 'PC006', 'PC013']\n",
    "td_subjects = ['TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "\n",
    "cp_trials = ['trial1_r1', 'trial2_r1', 'trial3_r1']\n",
    "td_crouch_trials = ['crouch1_r1', 'crouch2_r1', 'crouch3_r1']\n",
    "td_normal_trials = ['normal1_r1', 'normal2_r1', 'normal3_r1']\n",
    "\n",
    "# Create a dictionary mapping group labels\n",
    "group_trials = {\n",
    "    'CP': [(s, t) for s in cp_subjects for t in cp_trials],\n",
    "    'TD_crouch': [(s, t) for s in td_subjects for t in td_crouch_trials],\n",
    "    'TD_normal': [(s, t) for s in td_subjects for t in td_normal_trials]\n",
    "}\n",
    "\n",
    "emg_mappings = {\n",
    "    'glut_med1_r': 'RGLTMED', 'glut_med2_r': 'RGLTMED', 'glut_med3_r': 'RGLTMED',\n",
    "    'glut_min1_r': 'RGLTMED', 'glut_min2_r': 'RGLTMED', 'glut_min3_r': 'RGLTMED',\n",
    "    'glut_max1_r': 'RGLTMED', 'glut_max2_r': 'RGLTMED', 'glut_max3_r': 'RGLTMED',\n",
    "    'add_brev_r': 'RADDLONG', 'add_long_r': 'RADDLONG', 'grac_r': 'RADDLONG',\n",
    "    'bifemlh_r': 'RBF', 'bifemsh_r': 'RBF', 'semimem_r': 'RBF', 'semiten_r': 'RBF',\n",
    "    'tib_ant_r': 'RTA', 'ext_dig_r': 'RTA', 'ext_hal_r': 'RTA',\n",
    "    'vas_med_r': 'RRF', 'vas_int_r': 'RRF', 'vas_lat_r': 'RRF', 'rect_fem_r': 'RRF',\n",
    "    'med_gas_r': 'RGM', 'lat_gas_r': 'RGM', 'soleus_r': 'RGM'\n",
    "}\n",
    "\n",
    "\n",
    "valid_muscles = list(emg_mappings.keys())\n",
    "\n",
    "joint_suffix = {\n",
    "    'hip':   {'so': 'hip_flexion_r',  'ceinms': 'hip_flexion_r',  'id': 'hip_flexion_r_moment'},\n",
    "    'knee':  {'so': 'knee_angle_r',   'ceinms': 'knee_angle_r',   'id': 'knee_angle_r_moment'},\n",
    "    'ankle': {'so': 'ankle_angle_r',  'ceinms': 'ankle_angle_r',  'id': 'ankle_angle_r_moment'}\n",
    "}\n",
    "\n",
    "\n",
    "# TRIAL PROCESSING FUNCTION\n",
    "\n",
    "\n",
    "def process_trial(subject, trial):\n",
    "    \"\"\"\n",
    "    Process a single trial:\n",
    "      - Loads activation, EMG, joint moment, and force files.\n",
    "      - For subjects in TD groups, fixes the time scale.\n",
    "      - Computes muscle activation metrics (SO and CEINMS vs. EMG) for each muscle.\n",
    "      - Computes SO joint moments using a helper function (or computes them if not precomputed)\n",
    "        and then computes joint moment metrics (SO and CEINMS vs. inverse dynamics).\n",
    "    Returns a dictionary with RMSE and RÂ² metrics.\n",
    "    \"\"\"\n",
    "    trial_folder = simulations_dir / subject / trial\n",
    "\n",
    "    # ----- Load files for muscle activations -----\n",
    "    so_activation_path = trial_folder / \"Results_SO_and_MA\" / \"StaticOptimization_activation.sto\"\n",
    "    ceinms_activation_path = trial_folder / \"ceinms\" / \"execution\" / \"Activations.sto\"\n",
    "    emg_path = trial_folder / \"processed_emg_signals.mot\"\n",
    "\n",
    "    try:\n",
    "        so_act = load_sto(str(so_activation_path))\n",
    "        ceinms_act = load_sto(str(ceinms_activation_path))\n",
    "        emg = load_sto(str(emg_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading activation files for {subject} {trial}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # If subject belongs to TD group, fix time scale (multiply time by 10)\n",
    "    if subject in td_subjects:\n",
    "        so_act = fix_time_scale(so_act)\n",
    "        ceinms_act = fix_time_scale(ceinms_act)\n",
    "        emg = fix_time_scale(emg)\n",
    "\n",
    "    # Crop activation data to a common time window\n",
    "    start_time_act = max(so_act['time'].iloc[0], ceinms_act['time'].iloc[0], emg['time'].iloc[0])\n",
    "    end_time_act = min(so_act['time'].iloc[-1], ceinms_act['time'].iloc[-1], emg['time'].iloc[-1])\n",
    "    so_act = crop_time(so_act, start_time_act, end_time_act)\n",
    "    ceinms_act = crop_time(ceinms_act, start_time_act, end_time_act)\n",
    "    emg = crop_time(emg, start_time_act, end_time_act)\n",
    "    \n",
    "    # Compute muscle activation metrics over all muscles from the EMG mapping.\n",
    "    so_act_rmse_vals, so_act_r2_vals = [], []\n",
    "    ceinms_act_rmse_vals, ceinms_act_r2_vals = [], []\n",
    "    for muscle in list(emg_mappings.keys()):\n",
    "        emg_channel = emg_mappings[muscle]\n",
    "        if (muscle in so_act.columns) and (emg_channel in emg.columns):\n",
    "            rmse_val, r2_val = compute_rmse_r2(emg[emg_channel], so_act[muscle])\n",
    "            so_act_rmse_vals.append(rmse_val)\n",
    "            so_act_r2_vals.append(r2_val)\n",
    "        if (muscle in ceinms_act.columns) and (emg_channel in emg.columns):\n",
    "            rmse_val, r2_val = compute_rmse_r2(emg[emg_channel], ceinms_act[muscle])\n",
    "            ceinms_act_rmse_vals.append(rmse_val)\n",
    "            ceinms_act_r2_vals.append(r2_val)\n",
    "    \n",
    "    so_act_rmse_avg = np.mean(so_act_rmse_vals) if so_act_rmse_vals else np.nan\n",
    "    so_act_r2_avg = np.mean(so_act_r2_vals) if so_act_r2_vals else np.nan\n",
    "    ceinms_act_rmse_avg = np.mean(ceinms_act_rmse_vals) if ceinms_act_rmse_vals else np.nan\n",
    "    ceinms_act_r2_avg = np.mean(ceinms_act_r2_vals) if ceinms_act_r2_vals else np.nan\n",
    "\n",
    "    # ----- Load files for joint moments -----\n",
    "    so_force_path = trial_folder / \"Results_SO_and_MA\" / \"StaticOptimization_force.sto\"\n",
    "    ceinms_torque_path = trial_folder / \"ceinms\" / \"execution\" / \"Torques.sto\"\n",
    "    id_path = trial_folder / \"inverse_dynamics.sto\"\n",
    "    \n",
    "    try:\n",
    "        so_force = load_sto(str(so_force_path))\n",
    "        ceinms_torques = load_sto(str(ceinms_torque_path))\n",
    "        inverse_dynamics = load_sto(str(id_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading joint moment files for {subject} {trial}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Fix time scales for TD joint moment files (if needed)\n",
    "    if subject in td_subjects:\n",
    "        so_force = fix_time_scale(so_force)\n",
    "        ceinms_torques = fix_time_scale(ceinms_torques)\n",
    "        inverse_dynamics = fix_time_scale(inverse_dynamics)\n",
    "\n",
    "    # Load moment arm files for joints from SO (for hip, knee, and ankle)\n",
    "    moment_arms = {}\n",
    "    for joint in joint_suffix.keys():\n",
    "        ma_filename = f\"MuscleAnalysis_MomentArm_{joint_suffix[joint]['so']}.sto\"\n",
    "        ma_path = trial_folder / \"Results_SO_and_MA\" / ma_filename\n",
    "        try:\n",
    "            moment_arms[joint_suffix[joint]['so']] = load_sto(str(ma_path))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading moment arm file {ma_filename} for {subject} {trial}: {e}\")\n",
    "            moment_arms[joint_suffix[joint]['so']] = None\n",
    "    \n",
    "    # Crop joint moment data to a common time window\n",
    "    start_time_mom = max(so_force['time'].iloc[0],\n",
    "                         ceinms_torques['time'].iloc[0],\n",
    "                         inverse_dynamics['time'].iloc[0])\n",
    "    end_time_mom = min(so_force['time'].iloc[-1],\n",
    "                       ceinms_torques['time'].iloc[-1],\n",
    "                       inverse_dynamics['time'].iloc[-1])\n",
    "    so_force = crop_time(so_force, start_time_mom, end_time_mom)\n",
    "    ceinms_torques = crop_time(ceinms_torques, start_time_mom, end_time_mom)\n",
    "    inverse_dynamics = crop_time(inverse_dynamics, start_time_mom, end_time_mom)\n",
    "    for key in moment_arms:\n",
    "        if moment_arms[key] is not None:\n",
    "            moment_arms[key] = crop_time(moment_arms[key], start_time_mom, end_time_mom)\n",
    "    \n",
    "    # Normalize time to percentage of single leg support\n",
    "    sls_duration = end_time_mom - start_time_mom\n",
    "    so_force = normalize_time(so_force, start_time_mom, sls_duration)\n",
    "    ceinms_torques = normalize_time(ceinms_torques, start_time_mom, sls_duration)\n",
    "    inverse_dynamics = normalize_time(inverse_dynamics, start_time_mom, sls_duration)\n",
    "    for key in moment_arms:\n",
    "        if moment_arms[key] is not None:\n",
    "            moment_arms[key] = normalize_time(moment_arms[key], start_time_mom, sls_duration)\n",
    "    \n",
    "    # ----- Compute SO joint moments using our helper function -----\n",
    "    so_joint_df = compute_so_joint_moments(so_force, moment_arms, joint_suffix)\n",
    "    \n",
    "    # Compute joint moment metrics by comparing model results vs. inverse dynamics.\n",
    "    so_mom_rmse_list, so_mom_r2_list = [], []\n",
    "    ceinms_mom_rmse_list, ceinms_mom_r2_list = [], []\n",
    "    for joint, cols in joint_suffix.items():\n",
    "        id_col = cols['id']\n",
    "        # For SO joint moments: compare so_joint_df vs inverse dynamics\n",
    "        if (cols['so'] in so_joint_df.columns) and (id_col in inverse_dynamics.columns):\n",
    "            rmse_val, r2_val = compute_rmse_r2(inverse_dynamics[id_col], so_joint_df[cols['so']])\n",
    "            so_mom_rmse_list.append(rmse_val)\n",
    "            so_mom_r2_list.append(r2_val)\n",
    "        # For CEINMS joint moments: compare ceinms_torques vs inverse dynamics\n",
    "        ceinms_col = cols['ceinms']\n",
    "        if (ceinms_col in ceinms_torques.columns) and (id_col in inverse_dynamics.columns):\n",
    "            rmse_val, r2_val = compute_rmse_r2(inverse_dynamics[id_col], ceinms_torques[ceinms_col])\n",
    "            ceinms_mom_rmse_list.append(rmse_val)\n",
    "            ceinms_mom_r2_list.append(r2_val)\n",
    "    \n",
    "    so_mom_rmse_avg = np.mean(so_mom_rmse_list) if so_mom_rmse_list else np.nan\n",
    "    so_mom_r2_avg = np.mean(so_mom_r2_list) if so_mom_r2_list else np.nan\n",
    "    ceinms_mom_rmse_avg = np.mean(ceinms_mom_rmse_list) if ceinms_mom_rmse_list else np.nan\n",
    "    ceinms_mom_r2_avg = np.mean(ceinms_mom_r2_list) if ceinms_mom_r2_list else np.nan\n",
    "\n",
    "    # Compose the trial result dictionary\n",
    "    trial_results = {\n",
    "        \"so_activation_rmse\": so_act_rmse_avg,\n",
    "        \"so_activation_r2\": so_act_r2_avg,\n",
    "        \"ceinms_activation_rmse\": ceinms_act_rmse_avg,\n",
    "        \"ceinms_activation_r2\": ceinms_act_r2_avg,\n",
    "        \"so_moments_rmse\": so_mom_rmse_avg,\n",
    "        \"so_moments_r2\": so_mom_r2_avg,\n",
    "        \"ceinms_moments_rmse\": ceinms_mom_rmse_avg,\n",
    "        \"ceinms_moments_r2\": ceinms_mom_r2_avg\n",
    "    }\n",
    "    return trial_results\n",
    "\n",
    "\n",
    "\n",
    "# PROCESS ALL TRIALS AND AGGREGATE RESULTS BY GROUP\n",
    "\n",
    "\n",
    "group_results = {}  # Will map group -> list of trial result dictionaries\n",
    "\n",
    "for group_label, trials in group_trials.items():\n",
    "    trial_results_list = []\n",
    "    for subject, trial in trials:\n",
    "        res = process_trial(subject, trial)\n",
    "        if res is not None:\n",
    "            trial_results_list.append(res)\n",
    "    group_results[group_label] = trial_results_list\n",
    "\n",
    "# Now, average the metrics for each group (averaging across trials)\n",
    "final_results = []\n",
    "for group_label, results_list in group_results.items():\n",
    "    if results_list:\n",
    "        df = pd.DataFrame(results_list)\n",
    "        final_results.append({\n",
    "            \"Group\": group_label,\n",
    "            \"SO_Activations_RMSE\": df[\"so_activation_rmse\"].mean(),\n",
    "            \"SO_Activations_R2\": df[\"so_activation_r2\"].mean(),\n",
    "            \"CEINMS_Activations_RMSE\": df[\"ceinms_activation_rmse\"].mean(),\n",
    "            \"CEINMS_Activations_R2\": df[\"ceinms_activation_r2\"].mean(),\n",
    "            \"SO_Moments_RMSE\": df[\"so_moments_rmse\"].mean(),\n",
    "            \"SO_Moments_R2\": df[\"so_moments_r2\"].mean(),\n",
    "            \"CEINMS_Moments_RMSE\": df[\"ceinms_moments_rmse\"].mean(),\n",
    "            \"CEINMS_Moments_R2\": df[\"ceinms_moments_r2\"].mean()\n",
    "        })\n",
    "    else:\n",
    "        final_results.append({\n",
    "            \"Group\": group_label,\n",
    "            \"SO_Activations_RMSE\": np.nan,\n",
    "            \"SO_Activations_R2\": np.nan,\n",
    "            \"CEINMS_Activations_RMSE\": np.nan,\n",
    "            \"CEINMS_Activations_R2\": np.nan,\n",
    "            \"SO_Moments_RMSE\": np.nan,\n",
    "            \"SO_Moments_R2\": np.nan,\n",
    "            \"CEINMS_Moments_RMSE\": np.nan,\n",
    "            \"CEINMS_Moments_R2\": np.nan\n",
    "        })\n",
    "\n",
    "df_final = pd.DataFrame(final_results)\n",
    "print(\"RMSE and RÂ² Metrics Across Groups\")\n",
    "print(df_final)\n",
    "\n",
    "\n",
    "# Plot the Results as a Table\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 2))\n",
    "ax.axis('off')\n",
    "table_data = [df_final.columns.to_list()] + df_final.values.tolist()\n",
    "the_table = ax.table(cellText=table_data, cellLoc='center', loc='upper left')\n",
    "the_table.auto_set_font_size(False)\n",
    "the_table.set_fontsize(9)\n",
    "for col in range(len(df_final.columns)):\n",
    "    the_table.auto_set_column_width(col)\n",
    "plt.title(\"RMSE and RÂ² Results for Activations and Joint Moments\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare calibrated and uncalibrated ceinms models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_model =r\"C:\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\Simulations\\PC013\\trial3_l1\\ceinms\\uncalibratedSubject.xml\"\n",
    "cal_model = uncal_model.replace('uncalibratedSubject.xml', 'calibratedSubject.xml')\n",
    "\n",
    "# open both xmls and compare each mtu\n",
    "ucal_model_xml = msk.bops.XMLTools().load(uncal_model)\n",
    "cal_model_xml = msk.bops.XMLTools().load(cal_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\opensim_tutorial\\tutorials\\Cerebral_Palsy_Project\\Simulations\\PC002\\trial2_analog_filtered_emg.csv\"\n",
    "emg_data = pd.read_csv(filename)\n",
    "\n",
    "print(emg_data)\n",
    "print(emg_data.max())\n",
    "\n",
    "emg_data_normalised = emg_data / emg_data.max().max()\n",
    "\n",
    "print(emg_data_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the root elements of the XML trees\n",
    "cal_root = cal_model_xml.getroot()\n",
    "ucal_root = ucal_model_xml.getroot()\n",
    "\n",
    "# Find all \"mtu\" elements in both models\n",
    "cal_mtu_elements = cal_root.findall(\".//mtu\")\n",
    "ucal_mtu_elements = ucal_root.findall(\".//mtu\")\n",
    "\n",
    "# Create dictionaries for easy lookup by muscle name\n",
    "cal_mtu_dict = {mtu.find(\"name\").text: mtu for mtu in cal_mtu_elements}\n",
    "ucal_mtu_dict = {mtu.find(\"name\").text: mtu for mtu in ucal_mtu_elements}\n",
    "\n",
    "# Loop through all muscles and compare \"maxIsometricForce\" and \"tendonSlackLength\"\n",
    "comparison_results = []\n",
    "for muscle_name, cal_mtu in cal_mtu_dict.items():\n",
    "    if muscle_name in ucal_mtu_dict:\n",
    "        ucal_mtu = ucal_mtu_dict[muscle_name]\n",
    "        \n",
    "        # Extract values for comparison\n",
    "        cal_max_iso_force = float(cal_mtu.find(\"maxIsometricForce\").text)\n",
    "        ucal_max_iso_force = float(ucal_mtu.find(\"maxIsometricForce\").text)\n",
    "        \n",
    "        cal_tendon_slack_length = float(cal_mtu.find(\"tendonSlackLength\").text)\n",
    "        ucal_tendon_slack_length = float(ucal_mtu.find(\"tendonSlackLength\").text)\n",
    "        \n",
    "        # Store the comparison results\n",
    "        comparison_results.append({\n",
    "            \"Muscle\": muscle_name,\n",
    "            \"Calibrated_MaxIsometricForce\": cal_max_iso_force,\n",
    "            \"Uncalibrated_MaxIsometricForce\": ucal_max_iso_force,\n",
    "            \"Calibrated_TendonSlackLength\": cal_tendon_slack_length,\n",
    "            \"Uncalibrated_TendonSlackLength\": ucal_tendon_slack_length\n",
    "        })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Display the comparison\n",
    "print(comparison_df)\n",
    "\n",
    "# make some plots\n",
    "# Plot comparison of maxIsometricForce\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(comparison_df[\"Calibrated_MaxIsometricForce\"], comparison_df[\"Uncalibrated_MaxIsometricForce\"], 'o')\n",
    "plt.xlabel(\"Calibrated Max Isometric Force (N)\")\n",
    "plt.ylabel(\"Uncalibrated Max Isometric Force (N)\")\n",
    "\n",
    "# Plot comparison of tendonSlackLength\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(comparison_df[\"Calibrated_TendonSlackLength\"], comparison_df[\"Uncalibrated_TendonSlackLength\"], 'o')\n",
    "plt.xlabel(\"Calibrated Tendon Slack Length (m)\")\n",
    "plt.ylabel(\"Uncalibrated Tendon Slack Length (m)\")\n",
    "# Save the graph to the folder where calibrated and uncalibrated subjects are\n",
    "def save_comparison_graph(cal_model_path, ucal_model_path, fig):\n",
    "    # Determine the directory to save the graph\n",
    "    save_dir = os.path.dirname(cal_model_path)\n",
    "    save_path = os.path.join(save_dir, \"ucal-cal.png\")\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Graph saved at: {save_path}\")\n",
    "\n",
    "# Create a figure for the plots\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot comparison of maxIsometricForce\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(comparison_df[\"Calibrated_MaxIsometricForce\"], comparison_df[\"Uncalibrated_MaxIsometricForce\"], 'o')\n",
    "ax1.set_xlabel(\"Calibrated Max Isometric Force (N)\")\n",
    "ax1.set_ylabel(\"Uncalibrated Max Isometric Force (N)\")\n",
    "ax1.set_title(\"Max Isometric Force Comparison\")\n",
    "\n",
    "# Plot comparison of tendonSlackLength\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(comparison_df[\"Calibrated_TendonSlackLength\"], comparison_df[\"Uncalibrated_TendonSlackLength\"], 'o')\n",
    "ax2.set_xlabel(\"Calibrated Tendon Slack Length (m)\")\n",
    "ax2.set_ylabel(\"Uncalibrated Tendon Slack Length (m)\")\n",
    "ax2.set_title(\"Tendon Slack Length Comparison\")\n",
    "\n",
    "# Save the graph\n",
    "save_comparison_graph(cal_model, uncal_model, fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
