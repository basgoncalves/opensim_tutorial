{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msk_modelling_python as msk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import opensim as osim\n",
    "from xml.etree import ElementTree as ET\n",
    "import c3d\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import xml.dom.minidom \n",
    "import scipy.signal as sig\n",
    "import neurokit2 as nk\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "one_dir_up = os.path.dirname(current_dir)\n",
    "print(one_dir_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative values on EMG signal\n",
    "# Add ceinms paths to the trial object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"C:\\Git\\opensim_tutorial\\tutorials\\repeated_sprinting\\Simulations\\PC013\\trial3_r1\\Results_SO_and_MA\"\n",
    "file_mapping = {\n",
    "    '_MuscleAnalysis': 'MuscleAnalysis'\n",
    "}\n",
    "# loop through all files in the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        if any(substring in file for substring in file_mapping.keys()):\n",
    "            print(file)\n",
    "            new_file = file.replace(list(file_mapping.keys())[0], list(file_mapping.values())[0])\n",
    "            print(os.path.join(root, file))\n",
    "            \n",
    "            os.rename(os.path.join(root, file), os.path.join(root, new_file))\n",
    "            print(f\"Renamed {file} to {new_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class File:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.name = os.path.basename(path)\n",
    "        self.extension = os.path.splitext(path)[1]\n",
    "        \n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"\\033[93mFile not found: {path}\\033[0m\")\n",
    "            return        \n",
    "        \n",
    "        try:\n",
    "            endheader_line = self.find_file_endheader_line(path)\n",
    "        except:\n",
    "            print(f\"Error finding endheader line for file: {path}\")\n",
    "            endheader_line = 0\n",
    "        # Read file based on extension\n",
    "        try:\n",
    "            if self.extension == '.csv':\n",
    "                self.data = msk.pd.read_csv(path)\n",
    "            elif self.extension == '.json':\n",
    "                self.data = msk.bops.import_json_file(path)\n",
    "            elif self.extension == '.xml':\n",
    "                self.data = msk.bops.XMLTools.load(path)\n",
    "            else:\n",
    "                try:\n",
    "                    self.data = msk.pd.read_csv(path, sep=\"\\t\", skiprows=endheader_line)\n",
    "                except:\n",
    "                    self.data = None\n",
    "                    \n",
    "            # add time range for the data\n",
    "            try:\n",
    "                self.time_range = [self.data['time'].iloc[0], self.data['time'].iloc[-1]]\n",
    "                try:\n",
    "                    self.time_range = [self.data['Time'].iloc[0], self.data['Time'].iloc[-1]]\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                self.time_range = None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {path}\")\n",
    "            print(e)\n",
    "            self.data = None\n",
    "            self.time_range = None\n",
    "    def find_file_endheader_line(self, path):\n",
    "        with open(path, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if 'endheader' in line:\n",
    "                    return i + 1\n",
    "        return 0    \n",
    "    \n",
    "class Trial:\n",
    "    '''\n",
    "    Class to store trial information and file paths, and export files to OpenSim format\n",
    "    \n",
    "    Inputs: trial_path (str) - path to the trial folder\n",
    "    \n",
    "    Attributes:\n",
    "    path (str) - path to the trial folder\n",
    "    name (str) - name of the trial folder\n",
    "    og_c3d (str) - path to the original c3d file\n",
    "    c3d (str) - path to the c3d file in the trial folder\n",
    "    markers (str) - path to the marker trc file\n",
    "    grf (str) - path to the ground reaction force mot file\n",
    "    ...\n",
    "    \n",
    "    Methods: use dir(Trial) to see all methods\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, trial_path):        \n",
    "        self.path = trial_path\n",
    "        self.name = os.path.basename(self.path)\n",
    "        self.subject = os.path.basename(os.path.dirname(self.path))\n",
    "        self.c3d = os.path.join(os.path.dirname(self.path), self.name + '.c3d')\n",
    "        self.markers = File(os.path.join(self.path,'markers_experimental.trc'))\n",
    "        self.grf = File(os.path.join(self.path,'Visual3d_SIMM_grf.mot'))\n",
    "        self.emg_csv = File(os.path.join(self.path,'processed_emg_signals.csv'))\n",
    "        self.emg = File(os.path.join(self.path,'processed_emg_signals.mot'))\n",
    "        self.ik = File(os.path.join(self.path,'Visual3d_SIMM_input.mot'))\n",
    "        self.id = File(os.path.join(self.path,'inverse_dynamics.sto'))\n",
    "        self.so_force = File(os.path.join(self.path,'Results_SO_and_MA', f'{self.subject}_StaticOptimization_force.sto'))\n",
    "        self.so_activation = File(os.path.join(self.path, 'Results_SO_and_MA', f'{self.subject}_StaticOptimization_activation.sto'))\n",
    "        self.jra = File(os.path.join(self.path,'joint_reacton_loads.sto'))\n",
    "        \n",
    "        # load muscle analysis files\n",
    "        self.ma_targets = ['_MomentArm_', '_Length.sto']\n",
    "        self.ma_files = []\n",
    "        try:\n",
    "            files = os.listdir(os.path.join(self.path, 'Results_SO_and_MA'))\n",
    "            for file in files:\n",
    "                if file.__contains__(self.ma_targets[0]) or file.__contains__(self.ma_targets[1]):\n",
    "                    self.ma_files.append(File(os.path.join(self.path, 'Results_SO_and_MA', file)))\n",
    "        except:\n",
    "            self.ma_files = None\n",
    "                    \n",
    "        # settings files\n",
    "        self.grf_xml = File(os.path.join(self.path,'GRF_Setup.xml'))\n",
    "        self.actuators_so = File(os.path.join(self.path,'actuators_SO.xml'))\n",
    "        \n",
    "        self.settings_json = File(os.path.join(self.path,'settings.json'))\n",
    "        \n",
    "        # CEINMS files\n",
    "        self.ceinms_cal_setup = File(os.path.join(self.path,'ceinms','calibrationSetup.xml'))\n",
    "        self.ceinms_cal_cfg = File(os.path.join(self.path,'ceinms','calibrationCfg.xml'))\n",
    "        self.ceinms_trial = File(os.path.join(self.path,'ceinms','trial.xml'))\n",
    "        self.ceinms_uncalibrated_subject = File(os.path.join(self.path,'ceinms','uncalibratedSubject.xml'))\n",
    "        self.ceinms_excitation_generator = File(os.path.join(self.path,'ceinms','excitationGenerator.xml'))\n",
    "                              \n",
    "    def check_files(self):\n",
    "        '''\n",
    "        Output: True if all files exist, False if any file is missing\n",
    "        '''\n",
    "        files = self.__dict__.values()\n",
    "        all_files_exist = True\n",
    "        for file in files:\n",
    "            try:\n",
    "                if not os.path.isfile(file):\n",
    "                    print('File not found: ' + file)\n",
    "                    all_files_exist = False\n",
    "            except:\n",
    "                pass\n",
    "        return all_files_exist\n",
    "    \n",
    "    def header_mot(self,df,name):\n",
    "\n",
    "            num_rows = len(df)\n",
    "            num_cols = len(df.columns) \n",
    "            inital_time = df['Time'].iloc[0]\n",
    "            final_time = df['Time'].iloc[-1]\n",
    "            df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "            return f'name {name}\\n datacolumns {num_cols}\\n datarows {num_rows}\\n range {df_range} \\n endheader'\n",
    "        \n",
    "    def csv_to_mot(self):\n",
    "        \n",
    "        emg_data = msk.bops.pd.read_csv(self.emg_csv)\n",
    "\n",
    "        fs = int(1/(emg_data['time'][1] - emg_data['time'][0]))\n",
    "\n",
    "        time = emg_data['time']\n",
    "\n",
    "        # start time from new time point\n",
    "        start_time = time.iloc[0]\n",
    "        end_time = time.iloc[-1] - time.iloc[0] + start_time\n",
    "\n",
    "        num_samples = len(emg_data)\n",
    "        #num_samples = int((end_time - start_time) / (1/fs))\n",
    "        new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "        emg_data['time'] = new_time\n",
    "\n",
    "        # Define a new file path \n",
    "        new_file_path = os.path.join(self.emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "        # Save the modified DataFrame\n",
    "        emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "        # save to mot\n",
    "        header = self.header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "        mot_path = new_file_path.replace('.csv','.mot')\n",
    "        with open(mot_path, 'w') as f:\n",
    "            f.write(header + '\\n')  \n",
    "            # print column names \n",
    "            f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "            for index, row in emg_data.iterrows():\n",
    "                f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "        \n",
    "        print(f\"File saved: {mot_path}\")\n",
    "\n",
    "    def create_settings_json(self, overwrite=False):\n",
    "        if os.path.isfile(self.settings_json) and not overwrite:\n",
    "            print('settings.json already exists')\n",
    "            return\n",
    "        \n",
    "        settings_dict = self.__dict__\n",
    "        msk.bops.save_json_file(settings_dict, self.settings_json)\n",
    "        print('trial settings.json created in ' + self.path)\n",
    "    \n",
    "    def exportC3D(self):\n",
    "        msk.bops.c3d_osim_export(self.og_c3d) \n",
    "\n",
    "    def change_grf_xml_path(self):\n",
    "\n",
    "        try:\n",
    "            self.tree = ET.parse(self.grf_xml.path)\n",
    "            self.root = self.tree.getroot()\n",
    "            self.root.find('.//datafile').text = self.grf.path\n",
    "            \n",
    "            self.tree.write(self.grf_xml.path)\n",
    "            \n",
    "            print(f\"GRF file path updated in {self.grf_xml.path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading XML file: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_json_file(self, data, jsonFilePath):\n",
    "        data = data.__dict__\n",
    "\n",
    "        with open(jsonFilePath, 'w') as f:\n",
    "            msk.bops.json.dump(data, f, indent=4)\n",
    "\n",
    "        json_data = msk.bops.import_json_file(jsonFilePath)\n",
    "        return json_data\n",
    "    \n",
    "    def to_json(self):\n",
    "        msk.bops.save_json_file(self.__dict__, jsonFilePath = self.settings_json)\n",
    "        print('settings.json created in ' + self.settings_json)\n",
    "    \n",
    "    def run_IK(osim_modelPath, trc_file, resultsDir):\n",
    "        '''\n",
    "        Function to run Inverse Kinematics using the OpenSim API.\n",
    "        \n",
    "        Inputs:\n",
    "                osim_modelPath(str): path to the OpenSim model file\n",
    "                trc_file(str): path to the TRC file\n",
    "                resultsDir(str): path to the directory where the results will be saved\n",
    "        '''\n",
    "\n",
    "        # Load the TRC file\n",
    "        import pdb; pdb.set_trace()\n",
    "        tuple_data = msk.bops.import_trc_file(trc_file)\n",
    "        df = pd.DataFrame.from_records(tuple_data, columns=[x[0] for x in tuple_data])\n",
    "        column_names = [x[0] for x in tuple_data]\n",
    "        if len(set(column_names)) != len(column_names):\n",
    "            print(\"Error: Duplicate column names found.\")\n",
    "        # Load the model\n",
    "        osimModel = osim.Model(osim_modelPath)                              \n",
    "        state = osimModel.initSystem()\n",
    "\n",
    "        # Define the time range for the analysis\n",
    "        \n",
    "        initialTime = msk.TRCData.getIndependentColumn()\n",
    "        finalTime = msk.TRCData.getLastTime()\n",
    "\n",
    "        # Create the inverse kinematics tool\n",
    "        ikTool = osim.InverseKinematicsTool()\n",
    "        ikTool.setModel(osimModel)\n",
    "        ikTool.setStartTime(initialTime)\n",
    "        ikTool.setEndTime(finalTime)\n",
    "        ikTool.setMarkerDataFileName(trc_file)\n",
    "        ikTool.setResultsDir(resultsDir)\n",
    "        ikTool.set_accuracy(1e-6)\n",
    "        ikTool.setOutputMotionFileName(os.path.join(resultsDir, \"ik.mot\"))\n",
    "\n",
    "        # print setup\n",
    "        ikTool.printToXML(os.path.join(resultsDir, \"ik_setup.xml\"))         \n",
    "\n",
    "        # Run inverse kinematics\n",
    "        print(\"running ik...\")                                             \n",
    "        ikTool.run()\n",
    "\n",
    "    def run_inverse_kinematics(model_file, marker_file, output_motion_file):\n",
    "        # Load model and create an InverseKinematicsTool\n",
    "        model = osim.Model(model_file)\n",
    "        ik_tool = osim.InverseKinematicsTool()\n",
    "\n",
    "        # Set the model for the InverseKinematicsTool\n",
    "        ik_tool.setModel(model)\n",
    "\n",
    "        # Set the marker data file for the InverseKinematicsTool\n",
    "        ik_tool.setMarkerDataFileName(marker_file)\n",
    "\n",
    "        # Specify output motion file\n",
    "        ik_tool.setOutputMotionFileName(output_motion_file)\n",
    "\n",
    "        # Save setup file\n",
    "        ik_tool.printToXML('setup_ik.xml')\n",
    "\n",
    "        # Run Inverse Kinematics\n",
    "        ik_tool.run()\n",
    "\n",
    "    def run_ID(self, osim_modelPath, coordinates_file, external_loads_file, output_file, LowpassCutoffFrequency=6, run_tool=True):\n",
    "        \n",
    "        try: \n",
    "            model = osim.Model(osim_modelPath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {osim_modelPath}\")\n",
    "            print(e)\n",
    "            return\n",
    "        \n",
    "        results_folder = os.path.dirname(output_file)\n",
    "        \n",
    "        # Setup for excluding muscles from ID\n",
    "        exclude = osim.ArrayStr()\n",
    "        exclude.append(\"Muscles\")\n",
    "        # Setup for setting time range\n",
    "        IKData = osim.Storage(coordinates_file)\n",
    "\n",
    "        # Create inverse dynamics tool, set parameters and run\n",
    "        id_tool = osim.InverseDynamicsTool()\n",
    "        id_tool.setModel(model)\n",
    "        id_tool.setCoordinatesFileName(coordinates_file)\n",
    "        id_tool.setExternalLoadsFileName(external_loads_file)\n",
    "        id_tool.setOutputGenForceFileName(output_file)\n",
    "        id_tool.setLowpassCutoffFrequency(LowpassCutoffFrequency)\n",
    "        id_tool.setStartTime(IKData.getFirstTime())\n",
    "        id_tool.setEndTime(IKData.getLastTime())\n",
    "        id_tool.setExcludedForces(exclude)\n",
    "        id_tool.setResultsDir(results_folder)\n",
    "        id_tool.printToXML(os.path.join(results_folder, \"setup_ID.xml\"))\n",
    "        \n",
    "        if run_tool:\n",
    "            id_tool.run()\n",
    "    \n",
    "    def export_analog(self, c3dFilePath=None):\n",
    "        if not c3dFilePath:\n",
    "            print('C3D file path not provided')\n",
    "            return\n",
    "        \n",
    "        reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "        # get analog labels, trimmed and replace '.' with '_'\n",
    "        analog_labels = reader.analog_labels\n",
    "        analog_labels = [label.strip() for label in analog_labels]\n",
    "        analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "        # get analog labels, trimmed and replace '.' with '_'\n",
    "        fs = reader.analog_rate\n",
    "\n",
    "        # add time to dataframe\n",
    "        first_frame = reader.first_frame / fs\n",
    "        final_time = (reader.first_frame + reader.frame_count-1) / fs\n",
    "        time = msk.np.arange(first_frame / fs, final_time, 1 / fs)  \n",
    "        num_frames = len(time)\n",
    "        df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "        df['time'] = time\n",
    "\n",
    "        # move time to first column\n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        df = df[cols] \n",
    "\n",
    "        # loop through frames and add analog data to dataframe\n",
    "        for i_frame, points, analog in reader.read_frames():\n",
    "            \n",
    "            # get row number and print loading bar\n",
    "            i_row = i_frame - reader.first_frame\n",
    "            # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "            \n",
    "            # convert analog data to list\n",
    "            analog_list  = analog.data.tolist()\n",
    "            \n",
    "            # loop through analog channels and add to dataframe\n",
    "            for i_channel in range(len(analog_list)):\n",
    "                channel_name = analog_labels[i_channel]\n",
    "                \n",
    "                # add channel to dataframe\n",
    "                df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "                \n",
    "        # save emg data to csv\n",
    "        df.to_csv(self.emg_csv)\n",
    "        \n",
    "        # save to mot\n",
    "        #self.csv_to_mot()\n",
    "\n",
    "    # CREATE CEINMS XML files\n",
    "    def create_calibration_setup(self, save_path = None):\n",
    "            root = ET.Element(\"ceinmsCalibration\")\n",
    "            \n",
    "            subject_file = ET.SubElement(root, \"subjectFile\")\n",
    "            subject_file.text = \".\\\\uncalibratedSubject.xml\"\n",
    "            \n",
    "            excitation_generator_file = ET.SubElement(root, \"excitationGeneratorFile\")\n",
    "            excitation_generator_file.text = \".\\\\excitationGenerator.xml\"\n",
    "            \n",
    "            calibration_file = ET.SubElement(root, \"calibrationFile\")\n",
    "            calibration_file.text = \".\\\\calibrationCfg.xml\"\n",
    "            \n",
    "            output_subject_file = ET.SubElement(root, \"outputSubjectFile\")\n",
    "            output_subject_file.text = \".\\\\calibratedSubject.xml\"\n",
    "            \n",
    "            tree = ET.ElementTree(root)\n",
    "            if save_path is not None:\n",
    "                save_pretty_xml(tree, save_path)\n",
    "                print(f\"XML file created at: {save_path}\")\n",
    "                \n",
    "            return tree\n",
    "\n",
    "    def create_calibration_cfg(self, save_path=None, osimModelFile=None, leg='r'):\n",
    "\n",
    "\n",
    "        if osimModelFile is not None:\n",
    "            model = osim.Model(osimModelFile)\n",
    "            muscles = model.getMuscles()\n",
    "            muscle_groups = []\n",
    "            for muscle in muscles:\n",
    "                if muscle.getName().endswith(f\"_{leg}\"):\n",
    "                    muscle_groups.append(muscle.getName())\n",
    "                    \n",
    "            dofs = [f\"knee_angle_{leg}\"]\n",
    "            # Add other DOFs as needed\n",
    "                    \n",
    "        else:\n",
    "            print(\"\\033[93mNo OpenSim model file provided. Muscle groups will be from template.\\033[0m\")\n",
    "            print(\"\\033[93mDOFs will be added from template\\033[0m\")\n",
    "            \n",
    "            muscle_groups = [\n",
    "                f\"addbrev_{leg} addlong_{leg} addmagDist_{leg} addmagIsch_{leg} addmagMid_{leg} addmagProx_{leg} grac_{leg}\",\n",
    "                f\"bflh_{leg} semimem_{leg} semiten_{leg}\",\n",
    "                f\"bfsh_{leg}\",\n",
    "                f\"glmax1_{leg} glmax2_{leg} glmax3_{leg}\",\n",
    "                f\"glmed1_{leg} glmed2_{leg} glmed3_{leg}\",\n",
    "                f\"glmin1_{leg} glmin2_{leg} glmin3_{leg}\",\n",
    "                f\"sart_{leg} recfem_{leg} tfl_{leg}\",\n",
    "                f\"iliacus_{leg} psoas_{leg}\",\n",
    "                f\"perbrev_{leg} perlong_{leg} tibant_{leg} tibpost_{leg}\",\n",
    "                f\"edl_{leg} ehl_{leg} fdl_{leg} fhl_{leg}\",\n",
    "                f\"soleus_{leg} gaslat_{leg} gasmed_{leg}\",\n",
    "                f\"vasint_{leg} vaslat_{leg} vasmed_{leg}\"\n",
    "            ]        \n",
    "\n",
    "            dofs = [f\"knee_angle_{leg}\"] # Add other DOFs as needed\n",
    "        \n",
    "        \n",
    "        root = ET.Element(\"calibration\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "        \n",
    "        algorithm = ET.SubElement(root, \"algorithm\")\n",
    "        simulated_annealing = ET.SubElement(algorithm, \"simulatedAnnealing\")\n",
    "        ET.SubElement(simulated_annealing, \"noEpsilon\").text = \"4\"\n",
    "        ET.SubElement(simulated_annealing, \"rt\").text = \"0.3\"\n",
    "        ET.SubElement(simulated_annealing, \"T\").text = \"200000\"\n",
    "        ET.SubElement(simulated_annealing, \"NS\").text = \"15\"\n",
    "        ET.SubElement(simulated_annealing, \"NT\").text = \"5\"\n",
    "        ET.SubElement(simulated_annealing, \"epsilon\").text = \"1.E-5\"\n",
    "        ET.SubElement(simulated_annealing, \"maxNoEval\").text = \"200000\"\n",
    "        \n",
    "        nms_model = ET.SubElement(root, \"NMSmodel\")\n",
    "        model_type = ET.SubElement(nms_model, \"type\")\n",
    "        ET.SubElement(model_type, \"openLoop\")\n",
    "        tendon = ET.SubElement(nms_model, \"tendon\")\n",
    "        ET.SubElement(tendon, \"equilibriumElastic\")\n",
    "        activation = ET.SubElement(nms_model, \"activation\")\n",
    "        ET.SubElement(activation, \"exponential\")\n",
    "        \n",
    "        calibration_steps = ET.SubElement(root, \"calibrationSteps\")\n",
    "        step = ET.SubElement(calibration_steps, \"step\")\n",
    "        ET.SubElement(step, \"dofs\").text = \" \".join(dofs)\n",
    "        \n",
    "        objective_function = ET.SubElement(step, \"objectiveFunction\")\n",
    "        torque_error_normalised = ET.SubElement(objective_function, \"torqueErrorNormalised\")\n",
    "        ET.SubElement(torque_error_normalised, \"targets\").text = \"all\"\n",
    "        ET.SubElement(torque_error_normalised, \"weight\").text = \"1\"\n",
    "        ET.SubElement(torque_error_normalised, \"exponent\").text = \"1\"\n",
    "        \n",
    "        penalty = ET.SubElement(objective_function, \"penalty\")\n",
    "        ET.SubElement(penalty, \"targets\").text = \"all\"\n",
    "        ET.SubElement(penalty, \"targetsType\").text = \"normalisedFibreLength\"\n",
    "        ET.SubElement(penalty, \"weight\").text = \"100\"\n",
    "        ET.SubElement(penalty, \"exponent\").text = \"2\"\n",
    "        ET.SubElement(penalty, \"range\").text = \"0.6 1.4\"\n",
    "        \n",
    "        parameter_set = ET.SubElement(step, \"parameterSet\")\n",
    "                \n",
    "        parameters = [\n",
    "            {\"name\": \"c1\", \"range\": \"-0.95 -0.05\"},\n",
    "            {\"name\": \"c2\", \"range\": \"-0.95 -0.05\"},\n",
    "            {\"name\": \"shapeFactor\", \"range\": \"-2.999 -0.001\"},\n",
    "            {\"name\": \"tendonSlackLength\", \"range\": \"0.85 1.15\", \"relative\": True},\n",
    "            {\"name\": \"optimalFibreLength\", \"range\": \"0.85 1.15\", \"relative\": True},\n",
    "            {\"name\": \"strengthCoefficient\", \"range\": \"0.8 2\", \"muscleGroups\": muscle_groups}\n",
    "        ]\n",
    "        \n",
    "        for param in parameters:\n",
    "            parameter = ET.SubElement(parameter_set, \"parameter\")\n",
    "            ET.SubElement(parameter, \"name\").text = param[\"name\"]\n",
    "            \n",
    "            if \"muscleGroups\" in param:\n",
    "                muscle_groups = ET.SubElement(parameter, \"muscleGroups\")\n",
    "                for muscles in param[\"muscleGroups\"]:\n",
    "                    ET.SubElement(muscle_groups, \"muscles\").text = muscles\n",
    "                \n",
    "            else:\n",
    "                ET.SubElement(parameter, \"single\")\n",
    "                if \"relative\" in param and param[\"relative\"]:\n",
    "                    relative = ET.SubElement(parameter, \"relativeToSubjectValue\")\n",
    "                    ET.SubElement(relative, \"range\").text = param[\"range\"]\n",
    "                else:\n",
    "                    absolute = ET.SubElement(parameter, \"absolute\")\n",
    "                    ET.SubElement(absolute, \"range\").text = param[\"range\"]\n",
    "           \n",
    "        \n",
    "        ET.SubElement(root, \"trialSet\").text = \".\\\\trial.xml\"\n",
    "        \n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "        \n",
    "        return tree\n",
    "\n",
    "    def create_ceinms_trial_xml(self, savepath = None):\n",
    "        root = ET.Element(\"inputData\")\n",
    "\n",
    "        muscle_tendon_length_file = ET.SubElement(root, \"muscleTendonLengthFile\")\n",
    "        muscle_tendon_length_file.text = f\"../Results_SO_and_MA/MuscleAnalysis_Length.sto\"\n",
    "\n",
    "        excitations_file = ET.SubElement(root, \"excitationsFile\")\n",
    "        excitations_file.text = \"../processed_emg_signals.mot\"\n",
    "\n",
    "        moment_arms_files = ET.SubElement(root, \"momentArmsFiles\")\n",
    "        moment_arms_file = ET.SubElement(moment_arms_files, \"momentArmsFile\", dofName=\"knee_angle_r\")\n",
    "        moment_arms_file.text = f\"../Results_SO_and_MA/MuscleAnalysis_MomentArm_knee_angle_r.sto\"\n",
    "\n",
    "        external_torques_file = ET.SubElement(root, \"externalTorquesFile\")\n",
    "        external_torques_file.text = \"../inverse_dynamics.sto\"\n",
    "\n",
    "        external_loads_file = ET.SubElement(root, \"externalLoadsFile\")\n",
    "        external_loads_file.text = \"../GRF_Setup.xml\"\n",
    "\n",
    "        motion_file = ET.SubElement(root, \"motionFile\")\n",
    "        motion_file.text = \"../Visual3d_SIMM_input.mot\"\n",
    "\n",
    "        start_stop_time = ET.SubElement(root, \"startStopTime\")\n",
    "        start_stop_time.text = \"1.7 1.8\"\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        if savepath is not None:\n",
    "            save_pretty_xml(tree, savepath)\n",
    "            print(f\"XML file created at: {savepath}\")\n",
    "\n",
    "    def create_subject_uncalibrated(self, save_path=None, osimModelFile=None):\n",
    "        if osimModelFile == None:\n",
    "            print(\"\\033[93mNo OpenSim model not file provided. FAILED!!\\033[0m\")\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                model = osim.Model(osimModelFile)\n",
    "                coordinate_set = model.getCoordinateSet()\n",
    "                muscles = model.getMuscles() # ForceSet\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading OpenSim model: {e}\")\n",
    "                return None\n",
    "        \n",
    "        osim_model_file_name = os.path.basename(osimModelFile) \n",
    "        root = ET.Element(\"subject\", attrib={\"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"})\n",
    "        \n",
    "        mtu_default = ET.SubElement(root, \"mtuDefault\")\n",
    "        ET.SubElement(mtu_default, \"emDelay\").text = \"0.015\"\n",
    "        ET.SubElement(mtu_default, \"percentageChange\").text = \"0.15\"\n",
    "        ET.SubElement(mtu_default, \"damping\").text = \"0.1\"\n",
    "        \n",
    "        curves = [\n",
    "            {\n",
    "                \"name\": \"activeForceLength\",\n",
    "                \"xPoints\": \"-5 0 0.401 0.402 0.4035 0.52725 0.62875 0.71875 0.86125 1.045 1.2175 1.4387 1.6187 1.62 1.621 2.2 5\",\n",
    "                \"yPoints\": \"0 0 0 0 0 0.22667 0.63667 0.85667 0.95 0.99333 0.77 0.24667 0 0 0 0 0\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"passiveForceLength\",\n",
    "                \"xPoints\": \"-5 0.998 0.999 1 1.1 1.2 1.3 1.4 1.5 1.6 1.601 1.602 5\",\n",
    "                \"yPoints\": \"0 0 0 0 0.035 0.12 0.26 0.55 1.17 2 2 2 2\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"forceVelocity\",\n",
    "                \"xPoints\": \"-10 -1 -0.6 -0.3 -0.1 0 0.1 0.3 0.6 0.8 10\",\n",
    "                \"yPoints\": \"0 0 0.08 0.2 0.55 1 1.4 1.6 1.7 1.75 1.75\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"tendonForceStrain\",\n",
    "                \"xPoints\": \"0 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009 0.01 0.011 0.012 0.013 0.014 0.015 0.016 0.017 0.018 0.019 0.02 0.021 0.022 0.023 0.024 0.025 0.026 0.027 0.028 0.029 0.03 0.031 0.032 0.033 0.034 0.035 0.036 0.037 0.038 0.039 0.04 0.041 0.042 0.043 0.044 0.045 0.046 0.047 0.048 0.049 0.05 0.051 0.052 0.053 0.054 0.055 0.056 0.057 0.058 0.059 0.06 0.061 0.062 0.063 0.064 0.065 0.066 0.067 0.068 0.069 0.07 0.071 0.072 0.073 0.074 0.075 0.076 0.077 0.078 0.079 0.08 0.081 0.082 0.083 0.084 0.085 0.086 0.087 0.088 0.089 0.09 0.091 0.092 0.093 0.094 0.095 0.096 0.097 0.098 0.099 0.1\",\n",
    "                \"yPoints\": \"0 0.0012652 0.0073169 0.016319 0.026613 0.037604 0.049078 0.060973 0.073315 0.086183 0.099678 0.11386 0.12864 0.14386 0.15928 0.17477 0.19041 0.20658 0.22365 0.24179 0.26094 0.28089 0.30148 0.32254 0.34399 0.36576 0.38783 0.41019 0.43287 0.45591 0.4794 0.50344 0.52818 0.55376 0.58022 0.60747 0.63525 0.66327 0.69133 0.71939 0.74745 0.77551 0.80357 0.83163 0.85969 0.88776 0.91582 0.94388 0.97194 1 1.0281 1.0561 1.0842 1.1122 1.1403 1.1684 1.1964 1.2245 1.2526 1.2806 1.3087 1.3367 1.3648 1.3929 1.4209 1.449 1.477 1.5051 1.5332 1.5612 1.5893 1.6173 1.6454 1.6735 1.7015 1.7296 1.7577 1.7857 1.8138 1.8418 1.8699 1.898 1.926 1.9541 1.9821 2.0102 2.0383 2.0663 2.0944 2.1224 2.1505 2.1786 2.2066 2.2347 2.2628 2.2908 2.3189 2.3469 2.375 2.4031 2.4311\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for curve in curves:\n",
    "            curve_element = ET.SubElement(mtu_default, \"curve\")\n",
    "            ET.SubElement(curve_element, \"name\").text = curve[\"name\"]\n",
    "            ET.SubElement(curve_element, \"xPoints\").text = curve[\"xPoints\"]\n",
    "            ET.SubElement(curve_element, \"yPoints\").text = curve[\"yPoints\"]\n",
    "        \n",
    "        mtu_set = ET.SubElement(root, \"mtuSet\")\n",
    "        try:\n",
    "            mtus = []\n",
    "            for muscle in muscles:\n",
    "                mtu = {\n",
    "                    \"name\": muscle.getName(),\n",
    "                    \"c1\": \"-0.5\",\n",
    "                    \"c2\": \"-0.5\",\n",
    "                    \"shapeFactor\": \"0.1\",\n",
    "                    \"optimalFibreLength\": str(muscle.getOptimalFiberLength()),\n",
    "                    \"pennationAngle\": str(muscle.getPennationAngleAtOptimalFiberLength()),\n",
    "                    \"tendonSlackLength\": str(muscle.getTendonSlackLength()),\n",
    "                    \"tendonSlackLength\": str(muscle.getTendonSlackLength()),\n",
    "                    \"maxIsometricForce\": str(muscle.getMaxIsometricForce()),\n",
    "                    \"strengthCoefficient\": \"1\"\n",
    "                    }\n",
    "                mtus.append(mtu)\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding opensim muscles: {e}\")\n",
    "            return None\n",
    "                        \n",
    "        for mtu in mtus:\n",
    "            mtu_element = ET.SubElement(mtu_set, \"mtu\")\n",
    "            ET.SubElement(mtu_element, \"name\").text = mtu[\"name\"]\n",
    "            ET.SubElement(mtu_element, \"c1\").text = mtu[\"c1\"]\n",
    "            ET.SubElement(mtu_element, \"c2\").text = mtu[\"c2\"]\n",
    "            ET.SubElement(mtu_element, \"shapeFactor\").text = mtu[\"shapeFactor\"]\n",
    "            ET.SubElement(mtu_element, \"optimalFibreLength\").text = mtu[\"optimalFibreLength\"]\n",
    "            ET.SubElement(mtu_element, \"pennationAngle\").text = mtu[\"pennationAngle\"]\n",
    "            ET.SubElement(mtu_element, \"tendonSlackLength\").text = mtu[\"tendonSlackLength\"]\n",
    "            ET.SubElement(mtu_element, \"maxIsometricForce\").text = mtu[\"maxIsometricForce\"]\n",
    "            ET.SubElement(mtu_element, \"strengthCoefficient\").text = mtu[\"strengthCoefficient\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        dof_set = ET.SubElement(root, \"dofSet\")\n",
    "        \n",
    "        dofs = [\n",
    "            {\"name\": \"knee_angle_r\", \n",
    "            \"mtuNameSet\": \"bifemlh_r bifemsh_r lat_gas_r  med_gas_r grac_r rect_fem_r sar_r semimem_r semiten_r tfl_r vas_int_r vas_lat_r vas_med_r\"}\n",
    "            # Add other DOFs here...\n",
    "        ]\n",
    "        \n",
    "        for dof in dofs:\n",
    "            dof_element = ET.SubElement(dof_set, \"dof\")\n",
    "            ET.SubElement(dof_element, \"name\").text = dof[\"name\"]\n",
    "            ET.SubElement(dof_element, \"mtuNameSet\").text = dof[\"mtuNameSet\"]\n",
    "        \n",
    "        calibration_info = ET.SubElement(root, \"calibrationInfo\")\n",
    "        uncalibrated = ET.SubElement(calibration_info, \"uncalibrated\")\n",
    "        ET.SubElement(uncalibrated, \"subjectID\").text = osim_model_file_name\n",
    "        ET.SubElement(uncalibrated, \"additionalInfo\").text = \"TendonSlackLength and OptimalFibreLength scaled with Winby-Modenese\"\n",
    "        \n",
    "        ET.SubElement(root, \"contactModelFile\").text = \".\\\\contact_model.xml\"\n",
    "        ET.SubElement(root, \"opensimModelFile\").text = \"..\\\\..\\\\\" + osim_model_file_name\n",
    "        \n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:\n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "        \n",
    "        return tree\n",
    "\n",
    "    def create_excitation_generator(self, save_path=None, leg='r', input_signals=None):\n",
    "        if leg not in ['l', 'r']:\n",
    "            raise ValueError(\"Leg must be 'l' or 'r'\")\n",
    "\n",
    "        # Define the input signals and excitations\n",
    "        input_signals = ['GLTMED', 'RF', 'ADDLONG', 'ST', 'TA', 'GM']\n",
    "        excitations = [\n",
    "            'add_brev', 'add_long', 'bifemlh', 'bifemsh', 'ext_dig', 'ext_hal', \n",
    "            'flex_dig', 'flex_hal', 'lat_gas', 'med_gas', 'glut_max1', 'glut_max2', \n",
    "            'glut_max3', 'glut_med1', 'glut_med2', 'glut_med3', 'glut_min1', \n",
    "            'glut_min2', 'glut_min3', 'grac', 'iliacus', 'per_brev', 'per_long', \n",
    "            'psoas', 'rect_fem', 'sar', 'semimem', 'semiten', 'soleus', 'tfl', \n",
    "            'tib_ant', 'tib_post', 'vas_int', 'vas_lat', 'vas_med', 'add_mag1', \n",
    "            'add_mag2', 'add_mag3', 'pect', 'quad_fem', 'gem', 'peri', 'per_tert', \n",
    "            'ercspn', 'intobl', 'extobl'\n",
    "        ]\n",
    "        # Define the correct mapping of muscles to EMG signals\n",
    "        muscle_to_signal = {\n",
    "            \"add_brev\": \"ADDLONG\",\n",
    "            \"add_long\": \"ADDLONG\",\n",
    "            \"grac\": \"ADDLONG\",\n",
    "            \"bifemlh\": \"ST\",\n",
    "            \"bifemsh\": \"ST\",\n",
    "            \"semimem\": \"ST\",\n",
    "            \"semiten\": \"ST\",\n",
    "            \"ext_dig\": \"TA\",\n",
    "            \"ext_hal\": \"TA\",\n",
    "            \"tib_ant\": \"TA\",\n",
    "            \"lat_gas\": \"GM\",\n",
    "            \"med_gas\": \"GM\",\n",
    "            \"soleus\": \"GM\",\n",
    "            \"glut_max1\": \"GLTMED\",\n",
    "            \"glut_max2\": \"GLTMED\",\n",
    "            \"glut_max3\": \"GLTMED\",\n",
    "            \"glut_med1\": \"GLTMED\",\n",
    "            \"glut_med2\": \"GLTMED\",\n",
    "            \"glut_med3\": \"GLTMED\",\n",
    "            \"glut_min1\": \"GLTMED\",\n",
    "            \"glut_min2\": \"GLTMED\",\n",
    "            \"glut_min3\": \"GLTMED\",\n",
    "            \"vas_int\": \"RF\",\n",
    "            \"vas_lat\": \"RF\",\n",
    "            \"vas_med\": \"RF\",\n",
    "            \"pect\": \"RF\",\n",
    "        }\n",
    "        # Create the root element\n",
    "        root = ET.Element('excitationGenerator', {\n",
    "            'xmlns:xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n",
    "            'xsi:noNamespaceSchemaLocation': 'excitationGenerator.xsd'\n",
    "        })\n",
    "\n",
    "        # Create the inputSignals element (Only include signals for the selected leg)\n",
    "        input_signals_element = ET.SubElement(root, 'inputSignals', {'type': 'EMG'})\n",
    "        input_signals_element.text = ' '.join([f'{leg.upper()}{signal}' for signal in input_signals])\n",
    "\n",
    "        # Create the mapping element\n",
    "        mapping_element = ET.SubElement(root, 'mapping')\n",
    "\n",
    "        # Add excitations to the mapping element\n",
    "        for excitation in excitations:\n",
    "            excitation_element = ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_{leg}'})\n",
    "            if excitation in muscle_to_signal:\n",
    "                input_element = ET.SubElement(excitation_element, 'input')\n",
    "                input_element.set('weight', '1')\n",
    "                input_element.text = f\"{leg.upper()}{muscle_to_signal[excitation]}\"\n",
    "\n",
    "        # Add left leg muscles without assigning any input\n",
    "        if leg == 'r':\n",
    "            for excitation in excitations:\n",
    "                ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_l'})\n",
    "        elif leg == 'l':\n",
    "            for excitation in excitations:\n",
    "                ET.SubElement(mapping_element, 'excitation', {'id': f'{excitation}_r'})\n",
    "\n",
    "        # Create the tree and write to file\n",
    "        tree = ET.ElementTree(root)\n",
    "        if save_path is not None:    \n",
    "            save_pretty_xml(tree, save_path)\n",
    "            print(f\"XML file created at: {save_path}\")\n",
    "\n",
    "    def create_ceinms_files(self, osim_model_path = None, leg=None, input_signals = None):\n",
    "        \n",
    "        if not osim_model_path:\n",
    "            print(\"No OpenSim model file provided.\")\n",
    "            return\n",
    "        \n",
    "        if not input_signals:\n",
    "            print(\"No input signals provided.\")\n",
    "            return\n",
    "\n",
    "        if not leg:\n",
    "            print(\"No leg provided.\")\n",
    "            return\n",
    "        \n",
    "        # Calibration Setup\n",
    "        savepath = self.ceinms_cal_setup.path\n",
    "        self.create_calibration_setup(savepath)\n",
    "\n",
    "        # Calibration Configuration\n",
    "        savepath = self.ceinms_cal_cfg.path\n",
    "        self.create_calibration_cfg(savepath, osimModelFile=osim_model_path)\n",
    "\n",
    "        # Trial\n",
    "        savepath = self.ceinms_trial.path\n",
    "        self.create_ceinms_trial_xml(savepath)\n",
    "\n",
    "        # Uncalibrated Model \n",
    "        savepath = self.ceinms_uncalibrated_subject.path\n",
    "        self.create_subject_uncalibrated(save_path=savepath,osimModelFile=osim_model_path)\n",
    "\n",
    "        # Excitation Generator\n",
    "        savepath = self.ceinms_excitation_generator.path\n",
    "        self.create_excitation_generator(save_path=savepath, leg=leg, input_signals=input_signals)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class openSim:\n",
    "    def __init__(self, legs = ['r', 'l'], subjects =['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026'], trials_to_load = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3'], trial_number = 1):\n",
    "        try:\n",
    "            self.code_path = os.path.dirname(__file__)\n",
    "        except:\n",
    "            self.code_path = os.getcwd()\n",
    "        \n",
    "        self.simulations_path = os.path.join(os.path.dirname(self.code_path), 'Simulations')\n",
    "        self.subjects = {}\n",
    "        \n",
    "        for subject in subjects:\n",
    "            self.subjects[subject] = {}\n",
    "            self.subjects[subject]['model'] = os.path.join(self.simulations_path, subject, subject + '_scaled.osim')\n",
    "            for leg in legs: \n",
    "                for trial in trials_to_load:            \n",
    "                    self.trial_path = os.path.join(self.simulations_path, subject, f'{trial}_{leg}{trial_number}')\n",
    "                    try:\n",
    "                        trial = Trial(self.trial_path)\n",
    "                        self.subjects[subject][trial.name] = trial \n",
    "                    except Exception as e:\n",
    "                        self.subjects[subject][trial] =  None\n",
    "                        # print(f\"Error loading trial: {self.trial_path}\")\n",
    "                        # print(e)\n",
    "            \n",
    "        \n",
    "        self.ik_columns = [\"hip_flexion_leg\", \"hip_adduction_leg\", \"hip_rotation_leg\", \"knee_angle_leg\", \"ankle_angle_leg\"]\n",
    "        self.id_columns = [\"hip_flexion_leg\" + \"_moment\", \"hip_adduction_leg\" + \"_moment\", \"hip_rotation_leg\" + \"_moment\", \"knee_angle_leg\" + \"_moment\", \"ankle_angle_leg\" + \"_moment\"]\n",
    "        self.force_columns = [\"add_long_leg\", \"rect_fem_leg\", \"med_gas_leg\", \"semiten_leg\",\"tib_ant_leg\"]\n",
    "\n",
    "\n",
    "        self.titles = [\"Hip Flexion\", \"Hip Adduction\", \"Hip Rotation\", \"Knee Flexion\", \"Ankle Plantarflexion\"]\n",
    "        self.titles_muscles = [\"Adductor Longus\", \"Rectus Femoris\", \"Medial Gastrocnemius\", \"Semitendinosus\", \"Tibialis Anterior\"]\n",
    "\n",
    "    # Time Normalisation Function \n",
    "    def time_normalised_df(self, df, fs=None):\n",
    "        if not isinstance(df, msk.pd.DataFrame):\n",
    "            raise Exception('Input must be a pandas DataFrame')\n",
    "        \n",
    "        if not fs:\n",
    "            try:\n",
    "                fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "            except KeyError:\n",
    "                raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "            \n",
    "        normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        for column in df.columns:\n",
    "            if column == 'time':  # Skip time column\n",
    "                continue\t\n",
    "            normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "            currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "            timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "            Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "            normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "        return normalised_df\n",
    "\n",
    "    def plot_single_trial(self, show = False):\n",
    "        #Read .mot files\n",
    "        with open(self.mot_file, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the line where actual data starts (usually after 'endheader')\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"endheader\" in line:\n",
    "                start_row = i + 1  # Data starts after this line\n",
    "                break\n",
    "        else:\n",
    "            start_row = 0  # If 'endheader' is not found, assume no header\n",
    "\n",
    "        # Load data using Pandas\n",
    "        self.df_ik = msk.pd.read_csv(self.mot_file, delim_whitespace=True, start_row=start_row)\n",
    "        self.df_id = msk.pd.read_csv(self.id_file, sep=\"\\t\", start_row=6)\n",
    "        self.df_force = msk.pd.read_csv(self.force_file, sep=\"\\t\", start_row=14)\n",
    "\n",
    "        # Apply normalisation to both IK (angles) and ID (moments) data\n",
    "        self.df_ik_normalized = self.time_normalised_df(df=self.df_ik)\n",
    "        self.df_id_normalized = self.time_normalised_df(df=self.df_id)\n",
    "        self.df_force_normalized = self.time_normalised_df(df=self.df_force)\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)  \n",
    " \n",
    "        # select the specified columns         \n",
    "        self.ik_data = self.df_ik_normalized[self.ik_columns]\n",
    "        self.id_data = self.df_id_normalized[self.id_columns]\n",
    "        self.force_data = self.df_force_normalized[self.force_columns]\n",
    "            \n",
    "        # Define the layout \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(15, 4)) \n",
    "\n",
    "        #Plot IK (angles)\n",
    "        for i, col in enumerate(self.ik_columns):\n",
    "            ax = axes[0,i]\n",
    "            ax.plot(time_normalized, self.ik_data[col], color='red')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Angle (deg)\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        #Plot ID (moments)\n",
    "        for i, col in enumerate(self.id_columns):\n",
    "            ax = axes[1,i]\n",
    "            ax.plot(time_normalized, self.id_data[col], color='blue')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Moment (Nm)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        # PLOT MUSCLE FORCES \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 4), sharex=True)\n",
    "\n",
    "        for i, col in enumerate(self.force_columns):\n",
    "            ax = axes[i]\n",
    "            ax.plot(time_normalized, self.force_data[col], color='green')\n",
    "            ax.set_title(self.titles_muscles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Force (N)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_multiple_trials(self, show=False):\n",
    "        self.df_ik_list = []  # Store loaded DataFrames\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "            for trial in self.subjects[subject]:\n",
    "                trial_obj = self.subjects[subject][trial]\n",
    "                if trial_obj:\n",
    "                    self.df_ik_list.append(trial_obj.ik.data)\n",
    "                    \n",
    "        for file in self.mot_files:  # Loop through each file\n",
    "            with open(file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Load data using Pandas\n",
    "            df = msk.pd.read_csv(file, delim_whitespace=True, skiprows=5)\n",
    "            self.df_ik_list.append(df)\n",
    "\n",
    "        # Normalize all loaded IK data\n",
    "        self.df_ik_normalized_list = []  # Store normalized DataFrames\n",
    "\n",
    "        for df in self.df_ik_list:  # Loop through each loaded DataFrame\n",
    "            df_normalized = self.time_normalised_df(df=df)  # Apply normalization\n",
    "            self.df_ik_normalized_list.append(df_normalized)  # Store normalized DataFrame\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)\n",
    "\n",
    "        # Select the specified columns from normalized data\n",
    "        self.ik_data_list = []  # Store DataFrames with only the required columns\n",
    "\n",
    "        for df_normalized in self.df_ik_normalized_list:  # Loop through each normalized DataFrame\n",
    "            if set(self.ik_columns).issubset(df_normalized.columns):  # Check if columns exist\n",
    "                self.ik_data_list.append(df_normalized[self.ik_columns])  # Select only specified columns\n",
    "            else:\n",
    "                print(\"Warning: Some specified columns are missing in a file.\")\n",
    "\n",
    "        # Plot mean and sd\n",
    "        # Check if IK data exists\n",
    "        if not self.ik_data_list:\n",
    "            print(\"No IK data available to plot!\")\n",
    "        else:\n",
    "            # Convert list of DataFrames to a single NumPy array\n",
    "            combined_df = np.array([df.values for df in self.ik_data_list])  # Shape: (num_trials, num_timepoints, num_columns)\n",
    "\n",
    "            # Check if data is properly structured\n",
    "            if combined_df.shape[0] < 2:\n",
    "                print(\"Not enough trials to calculate mean and standard deviation!\")\n",
    "            else:\n",
    "                # Compute Mean and Standard Deviation\n",
    "                mean_values = np.mean(combined_df, axis=0)\n",
    "                std_values = np.std(combined_df, axis=0)\n",
    "\n",
    "                # Normalize time from 0 to 100% Gait Cycle\n",
    "                time_values = np.linspace(0, 100, combined_df.shape[1])\n",
    "\n",
    "                # Create a shared figure for all subplots\n",
    "                fig, axes = plt.subplots(nrows=1, ncols=len(self.ik_columns), figsize=(20, 5), sharex=True)\n",
    "\n",
    "                if len(self.ik_columns) == 1:\n",
    "                    axes = [axes]  # If only one column, ensure it's iterable\n",
    "\n",
    "                for i, col in enumerate(self.ik_columns):\n",
    "                    ax = axes[i]\n",
    "\n",
    "                    # Plot mean line\n",
    "                    ax.plot(time_values, mean_values[:, i], color='red', label=\"Mean\", linewidth=2)\n",
    "\n",
    "                    # Shade the standard deviation range\n",
    "                    ax.fill_between(time_values, mean_values[:, i] - std_values[:, i],\n",
    "                                    mean_values[:, i] + std_values[:, i], color='red', alpha=0.2, label=\"SD Range\")\n",
    "\n",
    "                    # Formatting\n",
    "                    ax.set_title(col)\n",
    "                    ax.set_xlabel(\"Gait Cycle (%)\")\n",
    "                    ax.set_xlim(0, 100)  # X-axis from 0% to 100% of the gait cycle\n",
    "                    ax.grid(True)\n",
    "\n",
    "                    # Set Y-label only for the first subplot\n",
    "                    if i == 0:\n",
    "                        ax.set_ylabel(\"Angle (Degrees)\")\n",
    "                        ax.legend()\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                if show:\n",
    "                    plt.show()\n",
    "\n",
    "def export_c3d(c3dFilePath):\n",
    "    analog_file_path = os.path.join(os.path.dirname(c3dFilePath),'analog.csv')\n",
    "    \n",
    "    # if the file already exists, return the file\n",
    "    if os.path.isfile(analog_file_path):\n",
    "        df = msk.pd.read_csv(analog_file_path)\n",
    "        return df\n",
    "    \n",
    "    print('Exporting analog data to csv ...')\n",
    "    \n",
    "    # read c3d file\n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    first_frame = reader.first_frame\n",
    "    num_frames = reader.frame_count\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    initial_time = first_frame / fs\n",
    "    final_time = (first_frame + num_frames-1) / fs\n",
    "    time = np.arange(first_frame / fs, final_time, 1 / fs) \n",
    "\n",
    "    df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "    df['time'] = time\n",
    "    \n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]    \n",
    "    \n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # convert analog data to list\n",
    "        analog_list  = analog.data.tolist()\n",
    "        \n",
    "        # loop through analog channels and add to dataframe\n",
    "        for i_channel in range(len(analog_list)):\n",
    "            channel_name = analog_labels[i_channel]\n",
    "            \n",
    "            # add channel to dataframe\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # save emg data to csv   \n",
    "    df.to_csv(analog_file_path)\n",
    "    print('analog.csv exported to ' + analog_file_path)  \n",
    "    \n",
    "    return df\n",
    "\n",
    "def export_analog(c3dFilePath=None, columns_to_mot='all'):\n",
    "    if not c3dFilePath:\n",
    "        print('C3D file path not provided')\n",
    "        return\n",
    "    \n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "    \n",
    "    # remove those not in columns_to_mot (fix: use column names to filter and get indices)\n",
    "    if columns_to_mot != 'all':\n",
    "        indices = [i for i, label in enumerate(analog_labels) if label in columns_to_mot]\n",
    "        analog_labels = [analog_labels[i] for i in indices]\n",
    "    else:\n",
    "        indices = list(range(len(analog_labels)))\n",
    "        columns_to_mot = analog_labels\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    first_time = reader.first_frame / fs\n",
    "    final_time = (reader.first_frame + reader.frame_count-1) / fs\n",
    "    time = msk.np.arange(first_time / fs, final_time, 1 / fs)  \n",
    "    num_frames = len(time)\n",
    "    df = msk.pd.DataFrame(index=range(num_frames), columns=analog_labels)\n",
    "    df['time'] = time\n",
    "\n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols] \n",
    "\n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # loop through selected analog channels and add to dataframe (fix: iterate over filtered indices)\n",
    "        for idx, i_channel in enumerate(indices):\n",
    "            channel_name = analog_labels[idx]\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # remove rows with NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # save emg data to csv\n",
    "    analog_csv_path = c3dFilePath.replace('.c3d', '_analog.csv')\n",
    "    df.to_csv(analog_csv_path, index=False)\n",
    "    \n",
    "    # save to mot\n",
    "    # self.csv_to_mot()\n",
    "    \n",
    "    return analog_csv_path\n",
    "\n",
    "def header_mot(df,name):\n",
    "\n",
    "        num_rows = len(df)\n",
    "        num_cols = len(df.columns) \n",
    "        inital_time = df['time'].iloc[0]\n",
    "        final_time = df['time'].iloc[-1]\n",
    "        df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "        return f'name {name}\\nnRows={num_rows}\\nnColumns={num_cols}\\n \\nendheader'\n",
    "\n",
    "def csv_to_mot(emg_csv):\n",
    "    \n",
    "    emg_data = msk.bops.pd.read_csv(emg_csv)\n",
    "    \n",
    "    time = emg_data['time']\n",
    "\n",
    "    # start time from new time point\n",
    "    start_time = time.iloc[0]\n",
    "    end_time = time.iloc[-1]\n",
    "\n",
    "    num_samples = len(emg_data)\n",
    "    new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "    emg_data['time'] = new_time\n",
    "\n",
    "    # Define a new file path \n",
    "    new_file_path = os.path.join(emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "    # Save the modified DataFrame\n",
    "    emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "    # save to mot\n",
    "    header = header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "    mot_path = new_file_path.replace('.csv','.mot')\n",
    "    with open(mot_path, 'w') as f:\n",
    "        f.write(header + '\\n')  \n",
    "        # print column names \n",
    "        f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "        for index, row in emg_data.iterrows():\n",
    "            f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "    \n",
    "    print(f\"File saved: {mot_path}\")\n",
    "    \n",
    "    return mot_path\n",
    "\n",
    "def time_normalised_df(df, fs=None):\n",
    "    if not isinstance(df, msk.pd.DataFrame):\n",
    "        raise Exception('Input must be a pandas DataFrame')\n",
    "    \n",
    "    if not fs:\n",
    "        try:\n",
    "            fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "        except KeyError:\n",
    "            raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "        \n",
    "    normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for column in df.columns:\n",
    "        normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "        currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "        timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "        Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "        normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "    return normalised_df\n",
    "\n",
    "def save_pretty_xml(tree, save_path):\n",
    "            \"\"\"Saves the XML tree to a file with proper indentation.\"\"\"\n",
    "            # Convert to string and format with proper indents\n",
    "            rough_string = ET.tostring(tree.getroot(), 'utf-8')\n",
    "            reparsed = xml.dom.minidom.parseString(rough_string)\n",
    "            pretty_xml = reparsed.toprettyxml(indent=\"   \")\n",
    "\n",
    "            # Write to file\n",
    "            with open(save_path, 'w') as file:\n",
    "                file.write(pretty_xml)\n",
    "\n",
    "def filter_emg(signal, sample_rate=1000, low_pass_cutoff=6):\n",
    "    \"\"\"\n",
    "    Processes EMG signal: clean, rectify, and filter to get the envelope.\n",
    "    \"\"\"\n",
    "    cleaned_signal = nk.emg_clean(signal, sampling_rate=sample_rate, method='biosppy')\n",
    "    rectified_signal = np.abs(cleaned_signal)\n",
    "    low_pass = low_pass_cutoff / (sample_rate / 2)\n",
    "    b, a = sig.butter(4, low_pass, btype='lowpass')\n",
    "    emg_envelope = sig.filtfilt(b, a, rectified_signal)\n",
    "    return emg_envelope\n",
    "\n",
    "def filter_emg_signals(csv_file, muscles, sample_rate=1000):\n",
    "    df = msk.pd.read_csv(csv_file)\n",
    "    filtered_data = {'time': df['time']}  # Add time column\n",
    "    \n",
    "    for muscle in muscles:\n",
    "        if muscle in df.columns:\n",
    "            filtered_data[muscle] = filter_emg(df[muscle].values, sample_rate)\n",
    "    \n",
    "    df_filtered = msk.pd.DataFrame(filtered_data)\n",
    "    \n",
    "    filtered_emg_path = csv_file.replace('.csv', '_filtered_emg.csv')\n",
    "    df_filtered.to_csv(filtered_emg_path, index=False)\n",
    "    \n",
    "    return filtered_emg_path\n",
    "\n",
    "def amplitude_normalise(processed_emg_path):\n",
    "    emg_data = pd.read_csv(processed_emg_path)\n",
    "    emg_data_normalised = emg_data.copy()\n",
    "    emg_data_normalised = emg_data_normalised.drop(columns=['time'])\n",
    "    \n",
    "    # normalise data\n",
    "    emg_data_normalised = emg_data_normalised / emg_data_normalised.max().max()\n",
    "    \n",
    "    # add time col back and move to first column\n",
    "    emg_data_normalised['time'] = emg_data['time']\n",
    "    cols = emg_data_normalised.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    emg_data_normalised = emg_data_normalised[cols]\n",
    "    \n",
    "    # save path \n",
    "    normalised_emg_path = processed_emg_path.replace('.csv', '_normalised.csv')\n",
    "    emg_data_normalised.to_csv(normalised_emg_path, index=False)\t\n",
    "    \n",
    "    return normalised_emg_path\n",
    "\n",
    "\n",
    "# END\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name coordinates for the respective leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik_columns = [\"hip_flexion_leg\", \"hip_adduction_leg\", \"hip_rotation_leg\", \"knee_angle_leg\", \"ankle_angle_leg\"]\n",
    "ik_columns = [col.replace('_leg', '_r') for col in ik_columns]\n",
    "ik_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert c3d files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3dFilePath = msk.ui.select_file()\n",
    "\n",
    "subject = os.path.basename(os.path.dirname(c3dFilePath))\n",
    "trial_folder = os.path.basename(c3dFilePath).replace('.c3d','')\n",
    "\n",
    "print(f\"Subject: {subject}\")\n",
    "print(f\"Trial: {trial_folder}\")\n",
    "legs = ['r', 'l']\n",
    "\n",
    "for leg in legs:\n",
    "    leg_folder_name = trial_folder + f'_{leg}1'\n",
    "    leg_folder = os.path.join(os.path.dirname(c3dFilePath), leg_folder_name)\n",
    "    if not os.path.exists(leg_folder):\n",
    "        os.mkdir(leg_folder)\n",
    "        print(f\"Folder created: {leg_folder}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {leg_folder}\")\n",
    "        \n",
    "    if leg == 'r':\n",
    "        columns_to_mot = ['RGLTMED','RRF','RADDLONG','RBF','RTA','RGM']\n",
    "    else:\n",
    "        columns_to_mot = ['LGLTMED','LRF','LADDLONG','LBF','LTA','LGM'] \n",
    "    \n",
    "    \n",
    "    # Export analog data to csv\n",
    "    analog_csv_path = export_analog(c3dFilePath, columns_to_mot=columns_to_mot)\n",
    "    \n",
    "    # Process EMG signals\n",
    "    filtered_emg_path = filter_emg_signals(analog_csv_path, columns_to_mot)\n",
    "\n",
    "    # Normalise amplitude of EMG signals\n",
    "    normalised_emg_path = amplitude_normalise(filtered_emg_path)\n",
    "    \n",
    "    # convert to mot\n",
    "    emg_mot_path = csv_to_mot(normalised_emg_path)\n",
    "    \n",
    "    # move the file to the leg folder\n",
    "    want_it = True\n",
    "    if want_it:\n",
    "        # move the file to the folder\n",
    "        new_analog_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'analog_emg_signals.csv')\n",
    "        new_emg_mot_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'processed_emg_signals.mot')\n",
    "\n",
    "        try:\n",
    "            shutil.move(analog_csv_path, new_analog_path)\n",
    "            shutil.move(emg_mot_path, new_emg_mot_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start all files from Zero (NOT NEEDED ANYMORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_l1'\n",
    "data = os_analysis.subjects[subject][trial_name].emg_csv.data\n",
    "if data is None:\n",
    "    print(f\"EMG data for subject {subject}, trial {trial_name} is not loaded correctly.\")\n",
    "else:\n",
    "    print(\"EMG data loaded successfully.\")\n",
    "data['time'] = data['time'] - data['time'].iloc[0]\n",
    "data.to_csv(os_analysis.subjects[subject][trial_name].emg_csv, index=False)\n",
    "\n",
    "csv_to_mot(os_analysis.subjects[subject][trial_name].emg_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()\n",
    "\n",
    "subject = 'PC003'\n",
    "trial_name = 'trial1_l1'\n",
    "\n",
    "# Define relative paths to the files\n",
    "id_file = os_analysis.subjects[subject][trial_name].id.path\n",
    "ik_file = os_analysis.subjects[subject][trial_name].ik.path\n",
    "emg_file = os_analysis.subjects[subject][trial_name].emg.path\n",
    "\n",
    "# Load the files into Pandas DataFrames\n",
    "id_df = pd.read_csv(id_file, sep=\"\\t\", skiprows=6)  \n",
    "ik_df = pd.read_csv(ik_file, sep=\"\\t\", skiprows=5)\n",
    "emg_df = pd.read_csv(emg_file, sep=\"\\t\", skiprows=5) \n",
    "\n",
    "# Extract the time columns\n",
    "id_time = id_df['time'] if 'time' in id_df.columns else id_df.iloc[:, 0]\n",
    "ik_time = ik_df['time'] if 'time' in ik_df.columns else ik_df.iloc[:, 0]\n",
    "emg_time = emg_df['time'] if 'time' in emg_df.columns else emg_df.iloc[:, 0]\n",
    "\n",
    "\n",
    "# Convert time columns to float, handling any non-numeric values\n",
    "def convert_to_numeric(series):\n",
    "    return pd.to_numeric(series, errors='coerce').dropna()  # Convert and drop NaNs\n",
    "\n",
    "id_time = convert_to_numeric(id_time)\n",
    "ik_time = convert_to_numeric(ik_time)\n",
    "emg_time = convert_to_numeric(emg_time)\n",
    "\n",
    "# Combine time values into a set to remove duplicates\n",
    "unique_times = sorted(set(id_time).union(set(ik_time), set(emg_time)))\n",
    "\n",
    "# Convert to numpy array\n",
    "unique_time_array = np.array(unique_times)\n",
    "\n",
    "# Create a base DataFrame with unique_time_array as the time column\n",
    "new_df = pd.DataFrame({'time': unique_time_array})\n",
    "\n",
    "# Merge with id_df, ik_df, and emg_df using left join on 'time' column\n",
    "new_id_df = new_df.merge(id_df, on='time', how='left')\n",
    "new_ik_df = new_df.merge(ik_df, on='time', how='left')\n",
    "new_emg_df = new_df.merge(emg_df, on='time', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "def fill_nan_values(*dfs):\n",
    "    return [df.fillna(0) for df in dfs]\n",
    "\n",
    "new_id_df, new_ik_df, new_emg_df = fill_nan_values(new_id_df, new_ik_df, new_emg_df)\n",
    "\n",
    "# Save the synchronized DataFrames\n",
    "def save_files(base_path, id_df, ik_df, emg_df):\n",
    "    id_path = os.path.join(base_path, \"inverse_dynamics_synced.sto\")\n",
    "    ik_path = os.path.join(base_path, \"Visual3d_SIMM_input_synced.mot\")\n",
    "    emg_path = os.path.join(base_path, \"processed_emg_signals_synced.csv\")\n",
    "    \n",
    "    # Save EMG DataFrame as CSV\n",
    "    emg_df.to_csv(emg_path, index=False)\n",
    "    \n",
    "    # Save ID DataFrame as .sto\n",
    "    with open(id_path, 'w') as f:\n",
    "        f.write(\"inverse dynamics data\\nversion=1\\nnRows={}\\nnColumns={}\\ninDegrees=yes\\nendheader\\n\".format(len(id_df), len(id_df.columns)))\n",
    "        id_df.to_csv(f, sep='\\t', index=False)\n",
    "    \n",
    "    # Save IK DataFrame as .mot\n",
    "    with open(ik_path, 'w') as f:\n",
    "        f.write(\"Coordinates\\nversion=1\\nnRows={}\\nnColumns={}\\ninDegrees=yes\\nendheader\\n\".format(len(ik_df), len(ik_df.columns)))\n",
    "        ik_df.to_csv(f, sep='\\t', index=False)\n",
    "    \n",
    "    print(f\"Files saved:\\n{id_path}\\n{ik_path}\\n{emg_path}\")\n",
    "\n",
    "# Define the base path where the files will be saved\n",
    "base_path = os.path.join(one_dir_up, \"Simulations\", \"PC002\", \"trial2_r1\")\n",
    "\n",
    "# Save the synchronized DataFrames\n",
    "save_files(base_path, new_id_df, new_ik_df, new_emg_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check times in all files for simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()\n",
    "\n",
    "subject = 'PC003'\n",
    "trial_name = 'trial1_l1'\n",
    "\n",
    "#check times\n",
    "print(os_analysis.subjects[subject][trial_name].ik.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].id.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].emg.time_range)\n",
    "\n",
    "# Define relative paths to the files\n",
    "id_file = os_analysis.subjects[subject][trial_name].id.path\n",
    "ik_file = os_analysis.subjects[subject][trial_name].ik.path\n",
    "emg_file = os_analysis.subjects[subject][trial_name].emg.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial in trial_list:\n",
    "        try:\n",
    "            os_analysis.subjects[subject][trial].change_grf_xml_path()\n",
    "            os_analysis.subjects[subject][trial].run_ID(osim_modelPath=os_analysis.subjects[subject]['model'], \n",
    "                                                            coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "                                                            output_file=os_analysis.subjects[subject][trial].id.path, \n",
    "                                                            external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "                                                            LowpassCutoffFrequency=6, \n",
    "                                                            run_tool=True)\n",
    "            \n",
    "            print(f\"ID ran successfully for {subject} - {trial}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running ID for {subject} - {trial}\")\n",
    "            print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_SO(model_path, coordinates_file, actuators_file_path, run_tool=True):\n",
    "    '''\n",
    "    Function to run Static Optimization using the OpenSim API.\n",
    "    \n",
    "    Inputs:\n",
    "            modelpath(str): path to the OpenSim model file\n",
    "            trialpath(str): path to the trial folder\n",
    "            actuators_file_path(str): path to the actuators file\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    trialpath = os.path.dirname(coordinates_file)   \n",
    "    # create directories\n",
    "    results_directory = os.path.relpath(trialpath, trialpath)\n",
    "    coordinates_file =  os.path.relpath(trialpath, coordinates_file)\n",
    "    modelpath_relative = os.path.relpath(model_path, trialpath)\n",
    "\n",
    "    # create a local copy of the actuator file path and update name\n",
    "    actuators_file_path = os.path.relpath(actuators_file_path, trialpath)\n",
    "\n",
    "    # start model\n",
    "    OsimModel = msk.osim.Model(modelpath_relative)\n",
    "\n",
    "    # Get mot data to determine time range\n",
    "    motData = msk.osim.Storage(coordinates_file)\n",
    "\n",
    "    # Get initial and intial time\n",
    "    initial_time = motData.getFirstTime()\n",
    "    final_time = motData.getLastTime()\n",
    "\n",
    "    # Static Optimization\n",
    "    so = msk.osim.StaticOptimization()\n",
    "    so.setName('StaticOptimization')\n",
    "    so.setModel(OsimModel)\n",
    "\n",
    "    # Set other parameters as needed\n",
    "    so.setStartTime(initial_time)\n",
    "    so.setEndTime(final_time)\n",
    "    so.setMaxIterations(25)\n",
    "\n",
    "    analyzeTool_SO = msk.classes.osimSetup.create_analysis_tool(coordinates_file,modelpath_relative,results_directory)\n",
    "    analyzeTool_SO.getAnalysisSet().cloneAndAppend(so)\n",
    "    analyzeTool_SO.getForceSetFiles().append(actuators_file_path)\n",
    "    analyzeTool_SO.setReplaceForceSet(False)\n",
    "    OsimModel.addAnalysis(so)\n",
    "\n",
    "    analyzeTool_SO.printToXML(\".\\setup_so.xml\")\n",
    "\n",
    "    analyzeTool_SO = msk.osim.AnalyzeTool(\".\\setup_so.xml\")\n",
    "\n",
    "    trial = os.path.basename(trialpath)\n",
    "    print(f\"so for {trial}\")\n",
    "\n",
    "    # run\n",
    "    if run_tool:\n",
    "        analyzeTool_SO.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_SO(model_path=os_analysis.subjects[subject]['model'], \n",
    "        coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "        actuators_file_path=os_analysis.subjects[subject][trial].id.path, \n",
    "        external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "        LowpassCutoffFrequency=6, \n",
    "        run_tool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print trial to Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFilePath = os.path.join(os_analysis.simulations_path, 'PC002', 'trial2_r1', 'settings.json')\n",
    "trial = Trial(os.path.join(os_analysis.simulations_path, 'PC002', 'trial2_r1'))\n",
    "trial.__dict__['jra'].__dict__\n",
    "\n",
    "data = trial.__dict__\n",
    "print(trial.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_SO(model_path=os_analysis.subjects['PC002']['model'],\n",
    "        coordinates_file = os_analysis.subjects['PC002']['trial2'].ik.path,\n",
    "        actuators_file_path = os_analysis.subjects['PC002']['trial2'].so_force.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CEINMS XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'File' object has no attribute 'time_range'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m clear_output()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#check times\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos_analysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m[\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrial_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mik\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_range\u001b[49m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(os_analysis\u001b[38;5;241m.\u001b[39msubjects[subject][trial_name]\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mtime_range)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(os_analysis\u001b[38;5;241m.\u001b[39msubjects[subject][trial_name]\u001b[38;5;241m.\u001b[39memg\u001b[38;5;241m.\u001b[39mtime_range)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'File' object has no attribute 'time_range'"
     ]
    }
   ],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_r1'\n",
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#check times\n",
    "print(os_analysis.subjects[subject][trial_name].ik.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].id.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].emg.time_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ['GLTMED', 'RF', 'ADDLONG', 'ST', 'TA', 'GM']\n",
    "\n",
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "            leg = trial_name[-2]\n",
    "            try:\n",
    "                trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "                subject_path = os.path.dirname(trial_path)\n",
    "                model = os.path.join(subject_path, f'{subject}_v3.osim')\n",
    "                \n",
    "                # check if IK file exists\n",
    "                if not os.path.exists(os_analysis.subjects[subject][trial_name].ik.path):\n",
    "                    try:\n",
    "                        shutil.rmtree(trial_path)\n",
    "                    except:\n",
    "                        pass \n",
    "                    \n",
    "                    print(f\"IK file not found for {subject} - {trial_name}. Skipping...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    # make ceims folder \n",
    "                    os.makedirs(os.path.join(trial_path, 'ceinms'), exist_ok=True)\n",
    "                \n",
    "                os_analysis.subjects[subject][trial_name].create_ceinms_files(osim_model_path=model,\n",
    "                                                                            leg=leg,\n",
    "                                                                            input_signals=signals)\n",
    "            except:\n",
    "                print(f\"Error creating CEINMS files for {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            print(f\"CEINMS files created for {subject} - {trial_name} - {leg}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEINMS calibration run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.getcwd()\n",
    "xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_cal_setup.path\n",
    "os.path.join(os.path.dirname(code_path), 'Simulations', subject, trial_name, 'ceinms', 'calibrationSetup.xml')\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "print(str(command))\n",
    "#print(os.getcwd())\n",
    "result = subprocess.run(command, capture_output=True, text=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating CEINMS files for PC002 - model - e\n",
      "CEINMS files created for PC002 - model - e\n",
      "Error creating CEINMS files for PC002 - trial1_r1 - r\n",
      "CEINMS files created for PC002 - trial1_r1 - r\n",
      "Error creating CEINMS files for PC002 - trial2_r1 - r\n",
      "CEINMS files created for PC002 - trial2_r1 - r\n",
      "Error creating CEINMS files for PC002 - trial3_r1 - r\n",
      "CEINMS files created for PC002 - trial3_r1 - r\n",
      "Error creating CEINMS files for PC002 - normal1_r1 - r\n",
      "CEINMS files created for PC002 - normal1_r1 - r\n",
      "Error creating CEINMS files for PC002 - normal2_r1 - r\n",
      "CEINMS files created for PC002 - normal2_r1 - r\n",
      "Error creating CEINMS files for PC002 - normal3_r1 - r\n",
      "CEINMS files created for PC002 - normal3_r1 - r\n",
      "Error creating CEINMS files for PC002 - crouch1_r1 - r\n",
      "CEINMS files created for PC002 - crouch1_r1 - r\n",
      "Error creating CEINMS files for PC002 - crouch2_r1 - r\n",
      "CEINMS files created for PC002 - crouch2_r1 - r\n",
      "Error creating CEINMS files for PC002 - crouch3_r1 - r\n",
      "CEINMS files created for PC002 - crouch3_r1 - r\n",
      "Error creating CEINMS files for PC002 - trial1_l1 - l\n",
      "CEINMS files created for PC002 - trial1_l1 - l\n",
      "Error creating CEINMS files for PC002 - trial2_l1 - l\n",
      "CEINMS files created for PC002 - trial2_l1 - l\n",
      "Error creating CEINMS files for PC002 - trial3_l1 - l\n",
      "CEINMS files created for PC002 - trial3_l1 - l\n",
      "Error creating CEINMS files for PC002 - normal1_l1 - l\n",
      "CEINMS files created for PC002 - normal1_l1 - l\n",
      "Error creating CEINMS files for PC002 - normal2_l1 - l\n",
      "CEINMS files created for PC002 - normal2_l1 - l\n",
      "Error creating CEINMS files for PC002 - normal3_l1 - l\n",
      "CEINMS files created for PC002 - normal3_l1 - l\n",
      "Error creating CEINMS files for PC002 - crouch1_l1 - l\n",
      "CEINMS files created for PC002 - crouch1_l1 - l\n",
      "Error creating CEINMS files for PC002 - crouch2_l1 - l\n",
      "CEINMS files created for PC002 - crouch2_l1 - l\n",
      "Error creating CEINMS files for PC002 - crouch3_l1 - l\n",
      "CEINMS files created for PC002 - crouch3_l1 - l\n",
      "Error creating CEINMS files for PC003 - model - e\n",
      "CEINMS files created for PC003 - model - e\n",
      "Error creating CEINMS files for PC003 - trial1_r1 - r\n",
      "CEINMS files created for PC003 - trial1_r1 - r\n",
      "Error creating CEINMS files for PC003 - trial2_r1 - r\n",
      "CEINMS files created for PC003 - trial2_r1 - r\n",
      "Error creating CEINMS files for PC003 - trial3_r1 - r\n",
      "CEINMS files created for PC003 - trial3_r1 - r\n",
      "Error creating CEINMS files for PC003 - normal1_r1 - r\n",
      "CEINMS files created for PC003 - normal1_r1 - r\n",
      "Error creating CEINMS files for PC003 - normal2_r1 - r\n",
      "CEINMS files created for PC003 - normal2_r1 - r\n",
      "Error creating CEINMS files for PC003 - normal3_r1 - r\n",
      "CEINMS files created for PC003 - normal3_r1 - r\n",
      "Error creating CEINMS files for PC003 - crouch1_r1 - r\n",
      "CEINMS files created for PC003 - crouch1_r1 - r\n",
      "Error creating CEINMS files for PC003 - crouch2_r1 - r\n",
      "CEINMS files created for PC003 - crouch2_r1 - r\n",
      "Error creating CEINMS files for PC003 - crouch3_r1 - r\n",
      "CEINMS files created for PC003 - crouch3_r1 - r\n",
      "Error creating CEINMS files for PC003 - trial1_l1 - l\n",
      "CEINMS files created for PC003 - trial1_l1 - l\n",
      "Error creating CEINMS files for PC003 - trial2_l1 - l\n",
      "CEINMS files created for PC003 - trial2_l1 - l\n",
      "Error creating CEINMS files for PC003 - trial3_l1 - l\n",
      "CEINMS files created for PC003 - trial3_l1 - l\n",
      "Error creating CEINMS files for PC003 - normal1_l1 - l\n",
      "CEINMS files created for PC003 - normal1_l1 - l\n",
      "Error creating CEINMS files for PC003 - normal2_l1 - l\n",
      "CEINMS files created for PC003 - normal2_l1 - l\n",
      "Error creating CEINMS files for PC003 - normal3_l1 - l\n",
      "CEINMS files created for PC003 - normal3_l1 - l\n",
      "Error creating CEINMS files for PC003 - crouch1_l1 - l\n",
      "CEINMS files created for PC003 - crouch1_l1 - l\n",
      "Error creating CEINMS files for PC003 - crouch2_l1 - l\n",
      "CEINMS files created for PC003 - crouch2_l1 - l\n",
      "Error creating CEINMS files for PC003 - crouch3_l1 - l\n",
      "CEINMS files created for PC003 - crouch3_l1 - l\n",
      "Error creating CEINMS files for PC006 - model - e\n",
      "CEINMS files created for PC006 - model - e\n",
      "Error creating CEINMS files for PC006 - trial1_r1 - r\n",
      "CEINMS files created for PC006 - trial1_r1 - r\n",
      "Error creating CEINMS files for PC006 - trial2_r1 - r\n",
      "CEINMS files created for PC006 - trial2_r1 - r\n",
      "Error creating CEINMS files for PC006 - trial3_r1 - r\n",
      "CEINMS files created for PC006 - trial3_r1 - r\n",
      "Error creating CEINMS files for PC006 - normal1_r1 - r\n",
      "CEINMS files created for PC006 - normal1_r1 - r\n",
      "Error creating CEINMS files for PC006 - normal2_r1 - r\n",
      "CEINMS files created for PC006 - normal2_r1 - r\n",
      "Error creating CEINMS files for PC006 - normal3_r1 - r\n",
      "CEINMS files created for PC006 - normal3_r1 - r\n",
      "Error creating CEINMS files for PC006 - crouch1_r1 - r\n",
      "CEINMS files created for PC006 - crouch1_r1 - r\n",
      "Error creating CEINMS files for PC006 - crouch2_r1 - r\n",
      "CEINMS files created for PC006 - crouch2_r1 - r\n",
      "Error creating CEINMS files for PC006 - crouch3_r1 - r\n",
      "CEINMS files created for PC006 - crouch3_r1 - r\n",
      "Error creating CEINMS files for PC006 - trial1_l1 - l\n",
      "CEINMS files created for PC006 - trial1_l1 - l\n",
      "Error creating CEINMS files for PC006 - trial2_l1 - l\n",
      "CEINMS files created for PC006 - trial2_l1 - l\n",
      "Error creating CEINMS files for PC006 - trial3_l1 - l\n",
      "CEINMS files created for PC006 - trial3_l1 - l\n",
      "Error creating CEINMS files for PC006 - normal1_l1 - l\n",
      "CEINMS files created for PC006 - normal1_l1 - l\n",
      "Error creating CEINMS files for PC006 - normal2_l1 - l\n",
      "CEINMS files created for PC006 - normal2_l1 - l\n",
      "Error creating CEINMS files for PC006 - normal3_l1 - l\n",
      "CEINMS files created for PC006 - normal3_l1 - l\n",
      "Error creating CEINMS files for PC006 - crouch1_l1 - l\n",
      "CEINMS files created for PC006 - crouch1_l1 - l\n",
      "Error creating CEINMS files for PC006 - crouch2_l1 - l\n",
      "CEINMS files created for PC006 - crouch2_l1 - l\n",
      "Error creating CEINMS files for PC006 - crouch3_l1 - l\n",
      "CEINMS files created for PC006 - crouch3_l1 - l\n",
      "Error creating CEINMS files for PC013 - model - e\n",
      "CEINMS files created for PC013 - model - e\n",
      "Error creating CEINMS files for PC013 - trial1_r1 - r\n",
      "CEINMS files created for PC013 - trial1_r1 - r\n",
      "Error creating CEINMS files for PC013 - trial2_r1 - r\n",
      "CEINMS files created for PC013 - trial2_r1 - r\n",
      "Error creating CEINMS files for PC013 - trial3_r1 - r\n",
      "CEINMS files created for PC013 - trial3_r1 - r\n",
      "Error creating CEINMS files for PC013 - normal1_r1 - r\n",
      "CEINMS files created for PC013 - normal1_r1 - r\n",
      "Error creating CEINMS files for PC013 - normal2_r1 - r\n",
      "CEINMS files created for PC013 - normal2_r1 - r\n",
      "Error creating CEINMS files for PC013 - normal3_r1 - r\n",
      "CEINMS files created for PC013 - normal3_r1 - r\n",
      "Error creating CEINMS files for PC013 - crouch1_r1 - r\n",
      "CEINMS files created for PC013 - crouch1_r1 - r\n",
      "Error creating CEINMS files for PC013 - crouch2_r1 - r\n",
      "CEINMS files created for PC013 - crouch2_r1 - r\n",
      "Error creating CEINMS files for PC013 - crouch3_r1 - r\n",
      "CEINMS files created for PC013 - crouch3_r1 - r\n",
      "Error creating CEINMS files for PC013 - trial1_l1 - l\n",
      "CEINMS files created for PC013 - trial1_l1 - l\n",
      "Error creating CEINMS files for PC013 - trial2_l1 - l\n",
      "CEINMS files created for PC013 - trial2_l1 - l\n",
      "Error creating CEINMS files for PC013 - trial3_l1 - l\n",
      "CEINMS files created for PC013 - trial3_l1 - l\n",
      "Error creating CEINMS files for PC013 - normal1_l1 - l\n",
      "CEINMS files created for PC013 - normal1_l1 - l\n",
      "Error creating CEINMS files for PC013 - normal2_l1 - l\n",
      "CEINMS files created for PC013 - normal2_l1 - l\n",
      "Error creating CEINMS files for PC013 - normal3_l1 - l\n",
      "CEINMS files created for PC013 - normal3_l1 - l\n",
      "Error creating CEINMS files for PC013 - crouch1_l1 - l\n",
      "CEINMS files created for PC013 - crouch1_l1 - l\n",
      "Error creating CEINMS files for PC013 - crouch2_l1 - l\n",
      "CEINMS files created for PC013 - crouch2_l1 - l\n",
      "Error creating CEINMS files for PC013 - crouch3_l1 - l\n",
      "CEINMS files created for PC013 - crouch3_l1 - l\n",
      "Error creating CEINMS files for TD006 - model - e\n",
      "CEINMS files created for TD006 - model - e\n",
      "Error creating CEINMS files for TD006 - trial1_r1 - r\n",
      "CEINMS files created for TD006 - trial1_r1 - r\n",
      "Error creating CEINMS files for TD006 - trial2_r1 - r\n",
      "CEINMS files created for TD006 - trial2_r1 - r\n",
      "Error creating CEINMS files for TD006 - trial3_r1 - r\n",
      "CEINMS files created for TD006 - trial3_r1 - r\n",
      "Error creating CEINMS files for TD006 - normal1_r1 - r\n",
      "CEINMS files created for TD006 - normal1_r1 - r\n",
      "Error creating CEINMS files for TD006 - normal2_r1 - r\n",
      "CEINMS files created for TD006 - normal2_r1 - r\n",
      "Error creating CEINMS files for TD006 - normal3_r1 - r\n",
      "CEINMS files created for TD006 - normal3_r1 - r\n",
      "Error creating CEINMS files for TD006 - crouch1_r1 - r\n",
      "CEINMS files created for TD006 - crouch1_r1 - r\n",
      "Error creating CEINMS files for TD006 - crouch2_r1 - r\n",
      "CEINMS files created for TD006 - crouch2_r1 - r\n",
      "Error creating CEINMS files for TD006 - crouch3_r1 - r\n",
      "CEINMS files created for TD006 - crouch3_r1 - r\n",
      "Error creating CEINMS files for TD006 - trial1_l1 - l\n",
      "CEINMS files created for TD006 - trial1_l1 - l\n",
      "Error creating CEINMS files for TD006 - trial2_l1 - l\n",
      "CEINMS files created for TD006 - trial2_l1 - l\n",
      "Error creating CEINMS files for TD006 - trial3_l1 - l\n",
      "CEINMS files created for TD006 - trial3_l1 - l\n",
      "Error creating CEINMS files for TD006 - normal1_l1 - l\n",
      "CEINMS files created for TD006 - normal1_l1 - l\n",
      "Error creating CEINMS files for TD006 - normal2_l1 - l\n",
      "CEINMS files created for TD006 - normal2_l1 - l\n",
      "Error creating CEINMS files for TD006 - normal3_l1 - l\n",
      "CEINMS files created for TD006 - normal3_l1 - l\n",
      "Error creating CEINMS files for TD006 - crouch1_l1 - l\n",
      "CEINMS files created for TD006 - crouch1_l1 - l\n",
      "Error creating CEINMS files for TD006 - crouch2_l1 - l\n",
      "CEINMS files created for TD006 - crouch2_l1 - l\n",
      "Error creating CEINMS files for TD006 - crouch3_l1 - l\n",
      "CEINMS files created for TD006 - crouch3_l1 - l\n",
      "Error creating CEINMS files for TD013 - model - e\n",
      "CEINMS files created for TD013 - model - e\n",
      "Error creating CEINMS files for TD013 - trial1_r1 - r\n",
      "CEINMS files created for TD013 - trial1_r1 - r\n",
      "Error creating CEINMS files for TD013 - trial2_r1 - r\n",
      "CEINMS files created for TD013 - trial2_r1 - r\n",
      "Error creating CEINMS files for TD013 - trial3_r1 - r\n",
      "CEINMS files created for TD013 - trial3_r1 - r\n",
      "Error creating CEINMS files for TD013 - normal1_r1 - r\n",
      "CEINMS files created for TD013 - normal1_r1 - r\n",
      "Error creating CEINMS files for TD013 - normal2_r1 - r\n",
      "CEINMS files created for TD013 - normal2_r1 - r\n",
      "Error creating CEINMS files for TD013 - normal3_r1 - r\n",
      "CEINMS files created for TD013 - normal3_r1 - r\n",
      "Error creating CEINMS files for TD013 - crouch1_r1 - r\n",
      "CEINMS files created for TD013 - crouch1_r1 - r\n",
      "Error creating CEINMS files for TD013 - crouch2_r1 - r\n",
      "CEINMS files created for TD013 - crouch2_r1 - r\n",
      "Error creating CEINMS files for TD013 - crouch3_r1 - r\n",
      "CEINMS files created for TD013 - crouch3_r1 - r\n",
      "Error creating CEINMS files for TD013 - trial1_l1 - l\n",
      "CEINMS files created for TD013 - trial1_l1 - l\n",
      "Error creating CEINMS files for TD013 - trial2_l1 - l\n",
      "CEINMS files created for TD013 - trial2_l1 - l\n",
      "Error creating CEINMS files for TD013 - trial3_l1 - l\n",
      "CEINMS files created for TD013 - trial3_l1 - l\n",
      "Error creating CEINMS files for TD013 - normal1_l1 - l\n",
      "CEINMS files created for TD013 - normal1_l1 - l\n",
      "Error creating CEINMS files for TD013 - normal2_l1 - l\n",
      "CEINMS files created for TD013 - normal2_l1 - l\n",
      "Error creating CEINMS files for TD013 - normal3_l1 - l\n",
      "CEINMS files created for TD013 - normal3_l1 - l\n",
      "Error creating CEINMS files for TD013 - crouch1_l1 - l\n",
      "CEINMS files created for TD013 - crouch1_l1 - l\n",
      "Error creating CEINMS files for TD013 - crouch2_l1 - l\n",
      "CEINMS files created for TD013 - crouch2_l1 - l\n",
      "Error creating CEINMS files for TD013 - crouch3_l1 - l\n",
      "CEINMS files created for TD013 - crouch3_l1 - l\n",
      "Error creating CEINMS files for TD017 - model - e\n",
      "CEINMS files created for TD017 - model - e\n",
      "Error creating CEINMS files for TD017 - trial1_r1 - r\n",
      "CEINMS files created for TD017 - trial1_r1 - r\n",
      "Error creating CEINMS files for TD017 - trial2_r1 - r\n",
      "CEINMS files created for TD017 - trial2_r1 - r\n",
      "Error creating CEINMS files for TD017 - trial3_r1 - r\n",
      "CEINMS files created for TD017 - trial3_r1 - r\n",
      "Error creating CEINMS files for TD017 - normal1_r1 - r\n",
      "CEINMS files created for TD017 - normal1_r1 - r\n",
      "Error creating CEINMS files for TD017 - normal2_r1 - r\n",
      "CEINMS files created for TD017 - normal2_r1 - r\n",
      "Error creating CEINMS files for TD017 - normal3_r1 - r\n",
      "CEINMS files created for TD017 - normal3_r1 - r\n",
      "Error creating CEINMS files for TD017 - crouch1_r1 - r\n",
      "CEINMS files created for TD017 - crouch1_r1 - r\n",
      "Error creating CEINMS files for TD017 - crouch2_r1 - r\n",
      "CEINMS files created for TD017 - crouch2_r1 - r\n",
      "Error creating CEINMS files for TD017 - crouch3_r1 - r\n",
      "CEINMS files created for TD017 - crouch3_r1 - r\n",
      "Error creating CEINMS files for TD017 - trial1_l1 - l\n",
      "CEINMS files created for TD017 - trial1_l1 - l\n",
      "Error creating CEINMS files for TD017 - trial2_l1 - l\n",
      "CEINMS files created for TD017 - trial2_l1 - l\n",
      "Error creating CEINMS files for TD017 - trial3_l1 - l\n",
      "CEINMS files created for TD017 - trial3_l1 - l\n",
      "Error creating CEINMS files for TD017 - normal1_l1 - l\n",
      "CEINMS files created for TD017 - normal1_l1 - l\n",
      "Error creating CEINMS files for TD017 - normal2_l1 - l\n",
      "CEINMS files created for TD017 - normal2_l1 - l\n",
      "Error creating CEINMS files for TD017 - normal3_l1 - l\n",
      "CEINMS files created for TD017 - normal3_l1 - l\n",
      "Error creating CEINMS files for TD017 - crouch1_l1 - l\n",
      "CEINMS files created for TD017 - crouch1_l1 - l\n",
      "Error creating CEINMS files for TD017 - crouch2_l1 - l\n",
      "CEINMS files created for TD017 - crouch2_l1 - l\n",
      "Error creating CEINMS files for TD017 - crouch3_l1 - l\n",
      "CEINMS files created for TD017 - crouch3_l1 - l\n",
      "Error creating CEINMS files for TD021 - model - e\n",
      "CEINMS files created for TD021 - model - e\n",
      "Error creating CEINMS files for TD021 - trial1_r1 - r\n",
      "CEINMS files created for TD021 - trial1_r1 - r\n",
      "Error creating CEINMS files for TD021 - trial2_r1 - r\n",
      "CEINMS files created for TD021 - trial2_r1 - r\n",
      "Error creating CEINMS files for TD021 - trial3_r1 - r\n",
      "CEINMS files created for TD021 - trial3_r1 - r\n",
      "Error creating CEINMS files for TD021 - normal1_r1 - r\n",
      "CEINMS files created for TD021 - normal1_r1 - r\n",
      "Error creating CEINMS files for TD021 - normal2_r1 - r\n",
      "CEINMS files created for TD021 - normal2_r1 - r\n",
      "Error creating CEINMS files for TD021 - normal3_r1 - r\n",
      "CEINMS files created for TD021 - normal3_r1 - r\n",
      "Error creating CEINMS files for TD021 - crouch1_r1 - r\n",
      "CEINMS files created for TD021 - crouch1_r1 - r\n",
      "Error creating CEINMS files for TD021 - crouch2_r1 - r\n",
      "CEINMS files created for TD021 - crouch2_r1 - r\n",
      "Error creating CEINMS files for TD021 - crouch3_r1 - r\n",
      "CEINMS files created for TD021 - crouch3_r1 - r\n",
      "Error creating CEINMS files for TD021 - trial1_l1 - l\n",
      "CEINMS files created for TD021 - trial1_l1 - l\n",
      "Error creating CEINMS files for TD021 - trial2_l1 - l\n",
      "CEINMS files created for TD021 - trial2_l1 - l\n",
      "Error creating CEINMS files for TD021 - trial3_l1 - l\n",
      "CEINMS files created for TD021 - trial3_l1 - l\n",
      "Error creating CEINMS files for TD021 - normal1_l1 - l\n",
      "CEINMS files created for TD021 - normal1_l1 - l\n",
      "Error creating CEINMS files for TD021 - normal2_l1 - l\n",
      "CEINMS files created for TD021 - normal2_l1 - l\n",
      "Error creating CEINMS files for TD021 - normal3_l1 - l\n",
      "CEINMS files created for TD021 - normal3_l1 - l\n",
      "Error creating CEINMS files for TD021 - crouch1_l1 - l\n",
      "CEINMS files created for TD021 - crouch1_l1 - l\n",
      "Error creating CEINMS files for TD021 - crouch2_l1 - l\n",
      "CEINMS files created for TD021 - crouch2_l1 - l\n",
      "Error creating CEINMS files for TD021 - crouch3_l1 - l\n",
      "CEINMS files created for TD021 - crouch3_l1 - l\n",
      "Error creating CEINMS files for TD023 - model - e\n",
      "CEINMS files created for TD023 - model - e\n",
      "Error creating CEINMS files for TD023 - trial1_r1 - r\n",
      "CEINMS files created for TD023 - trial1_r1 - r\n",
      "Error creating CEINMS files for TD023 - trial2_r1 - r\n",
      "CEINMS files created for TD023 - trial2_r1 - r\n",
      "Error creating CEINMS files for TD023 - trial3_r1 - r\n",
      "CEINMS files created for TD023 - trial3_r1 - r\n",
      "Error creating CEINMS files for TD023 - normal1_r1 - r\n",
      "CEINMS files created for TD023 - normal1_r1 - r\n",
      "Error creating CEINMS files for TD023 - normal2_r1 - r\n",
      "CEINMS files created for TD023 - normal2_r1 - r\n",
      "Error creating CEINMS files for TD023 - normal3_r1 - r\n",
      "CEINMS files created for TD023 - normal3_r1 - r\n",
      "Error creating CEINMS files for TD023 - crouch1_r1 - r\n",
      "CEINMS files created for TD023 - crouch1_r1 - r\n",
      "Error creating CEINMS files for TD023 - crouch2_r1 - r\n",
      "CEINMS files created for TD023 - crouch2_r1 - r\n",
      "Error creating CEINMS files for TD023 - crouch3_r1 - r\n",
      "CEINMS files created for TD023 - crouch3_r1 - r\n",
      "Error creating CEINMS files for TD023 - trial1_l1 - l\n",
      "CEINMS files created for TD023 - trial1_l1 - l\n",
      "Error creating CEINMS files for TD023 - trial2_l1 - l\n",
      "CEINMS files created for TD023 - trial2_l1 - l\n",
      "Error creating CEINMS files for TD023 - trial3_l1 - l\n",
      "CEINMS files created for TD023 - trial3_l1 - l\n",
      "Error creating CEINMS files for TD023 - normal1_l1 - l\n",
      "CEINMS files created for TD023 - normal1_l1 - l\n",
      "Error creating CEINMS files for TD023 - normal2_l1 - l\n",
      "CEINMS files created for TD023 - normal2_l1 - l\n",
      "Error creating CEINMS files for TD023 - normal3_l1 - l\n",
      "CEINMS files created for TD023 - normal3_l1 - l\n",
      "Error creating CEINMS files for TD023 - crouch1_l1 - l\n",
      "CEINMS files created for TD023 - crouch1_l1 - l\n",
      "Error creating CEINMS files for TD023 - crouch2_l1 - l\n",
      "CEINMS files created for TD023 - crouch2_l1 - l\n",
      "Error creating CEINMS files for TD023 - crouch3_l1 - l\n",
      "CEINMS files created for TD023 - crouch3_l1 - l\n",
      "Error creating CEINMS files for TD026 - model - e\n",
      "CEINMS files created for TD026 - model - e\n",
      "Error creating CEINMS files for TD026 - trial1_r1 - r\n",
      "CEINMS files created for TD026 - trial1_r1 - r\n",
      "Error creating CEINMS files for TD026 - trial2_r1 - r\n",
      "CEINMS files created for TD026 - trial2_r1 - r\n",
      "Error creating CEINMS files for TD026 - trial3_r1 - r\n",
      "CEINMS files created for TD026 - trial3_r1 - r\n",
      "Error creating CEINMS files for TD026 - normal1_r1 - r\n",
      "CEINMS files created for TD026 - normal1_r1 - r\n",
      "Error creating CEINMS files for TD026 - normal2_r1 - r\n",
      "CEINMS files created for TD026 - normal2_r1 - r\n",
      "Error creating CEINMS files for TD026 - normal3_r1 - r\n",
      "CEINMS files created for TD026 - normal3_r1 - r\n",
      "Error creating CEINMS files for TD026 - crouch1_r1 - r\n",
      "CEINMS files created for TD026 - crouch1_r1 - r\n",
      "Error creating CEINMS files for TD026 - crouch2_r1 - r\n",
      "CEINMS files created for TD026 - crouch2_r1 - r\n",
      "Error creating CEINMS files for TD026 - crouch3_r1 - r\n",
      "CEINMS files created for TD026 - crouch3_r1 - r\n",
      "Error creating CEINMS files for TD026 - trial1_l1 - l\n",
      "CEINMS files created for TD026 - trial1_l1 - l\n",
      "Error creating CEINMS files for TD026 - trial2_l1 - l\n",
      "CEINMS files created for TD026 - trial2_l1 - l\n",
      "Error creating CEINMS files for TD026 - trial3_l1 - l\n",
      "CEINMS files created for TD026 - trial3_l1 - l\n",
      "Error creating CEINMS files for TD026 - normal1_l1 - l\n",
      "CEINMS files created for TD026 - normal1_l1 - l\n",
      "Error creating CEINMS files for TD026 - normal2_l1 - l\n",
      "CEINMS files created for TD026 - normal2_l1 - l\n",
      "Error creating CEINMS files for TD026 - normal3_l1 - l\n",
      "CEINMS files created for TD026 - normal3_l1 - l\n",
      "Error creating CEINMS files for TD026 - crouch1_l1 - l\n",
      "CEINMS files created for TD026 - crouch1_l1 - l\n",
      "Error creating CEINMS files for TD026 - crouch2_l1 - l\n",
      "CEINMS files created for TD026 - crouch2_l1 - l\n",
      "Error creating CEINMS files for TD026 - crouch3_l1 - l\n",
      "CEINMS files created for TD026 - crouch3_l1 - l\n"
     ]
    }
   ],
   "source": [
    "code_path = os.getcwd()\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "\n",
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial_name in trial_list:\n",
    "            leg = trial_name[-2]\n",
    "            try:\n",
    "                trial_path = os_analysis.subjects[subject][trial_name].path\n",
    "                # change working directory to trial path\n",
    "                os.chdir(trial_path)\n",
    "                \n",
    "                xml_setup_file = os_analysis.subjects[subject][trial_name].ceinms_cal_setup.path\n",
    "                \n",
    "                command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "                \n",
    "                result = subprocess.run(command, capture_output=True, text=True, check=True)            \n",
    "\n",
    "                print(f\"Calibration successful for {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            except:\n",
    "                print(f\"Error creating CEINMS files for {subject} - {trial_name} - {leg}\")\n",
    "                \n",
    "            print(f\"CEINMS files created for {subject} - {trial_name} - {leg}\")\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msk_modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
