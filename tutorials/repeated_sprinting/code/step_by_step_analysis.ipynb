{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Git\\opensim_tutorial\\tutorials\\repeated_sprinting\\code\n",
      "c:\\Git\\opensim_tutorial\\tutorials\\repeated_sprinting\n"
     ]
    }
   ],
   "source": [
    "import msk_modelling_python as msk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import opensim as osim\n",
    "from xml.etree import ElementTree as ET\n",
    "import c3d\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import xml.dom.minidom \n",
    "import scipy.signal as sig\n",
    "import neurokit2 as nk\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "one_dir_up = os.path.dirname(current_dir)\n",
    "print(one_dir_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"C:\\Git\\opensim_tutorial\\tutorials\\repeated_sprinting\\Simulations\\PC013\\trial3_r1\\Results_SO_and_MA\"\n",
    "file_mapping = {\n",
    "    '_MuscleAnalysis': 'MuscleAnalysis'\n",
    "}\n",
    "# loop through all files in the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        if any(substring in file for substring in file_mapping.keys()):\n",
    "            print(file)\n",
    "            new_file = file.replace(list(file_mapping.keys())[0], list(file_mapping.values())[0])\n",
    "            print(os.path.join(root, file))\n",
    "            \n",
    "            os.rename(os.path.join(root, file), os.path.join(root, new_file))\n",
    "            print(f\"Renamed {file} to {new_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class File:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.name = os.path.basename(path)\n",
    "        self.extension = os.path.splitext(path)[1]\n",
    "        \n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"\\033[93mFile not found: {path}\\033[0m\")\n",
    "            return        \n",
    "        \n",
    "        try:\n",
    "            endheader_line = self.find_file_endheader_line(path)\n",
    "        except:\n",
    "            print(f\"Error finding endheader line for file: {path}\")\n",
    "            endheader_line = 0\n",
    "        # Read file based on extension\n",
    "        try:\n",
    "            if self.extension == '.csv':\n",
    "                self.data = msk.pd.read_csv(path)\n",
    "            elif self.extension == '.json':\n",
    "                self.data = msk.bops.import_json_file(path)\n",
    "            elif self.extension == '.xml':\n",
    "                self.data = msk.bops.XMLTools.load(path)\n",
    "            else:\n",
    "                try:\n",
    "                    self.data = msk.pd.read_csv(path, sep=\"\\t\", skiprows=endheader_line)\n",
    "                except:\n",
    "                    self.data = None\n",
    "                    \n",
    "            # add time range for the data\n",
    "            try:\n",
    "                self.time_range = [self.data['time'].iloc[0], self.data['time'].iloc[-1]]\n",
    "                try:\n",
    "                    self.time_range = [self.data['Time'].iloc[0], self.data['Time'].iloc[-1]]\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                self.time_range = None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {path}\")\n",
    "            print(e)\n",
    "            self.data = None\n",
    "            self.time_range = None\n",
    "    def find_file_endheader_line(self, path):\n",
    "        with open(path, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if 'endheader' in line:\n",
    "                    return i + 1\n",
    "        return 0    \n",
    "    \n",
    "class Trial:\n",
    "    '''\n",
    "    Class to store trial information and file paths, and export files to OpenSim format\n",
    "    \n",
    "    Inputs: trial_path (str) - path to the trial folder\n",
    "    \n",
    "    Attributes:\n",
    "    path (str) - path to the trial folder\n",
    "    name (str) - name of the trial folder\n",
    "    og_c3d (str) - path to the original c3d file\n",
    "    c3d (str) - path to the c3d file in the trial folder\n",
    "    markers (str) - path to the marker trc file\n",
    "    grf (str) - path to the ground reaction force mot file\n",
    "    ...\n",
    "    \n",
    "    Methods: use dir(Trial) to see all methods\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, trial_path):        \n",
    "        self.path = trial_path\n",
    "        self.name = os.path.basename(self.path)\n",
    "        self.subject = os.path.basename(os.path.dirname(self.path))\n",
    "        self.c3d = os.path.join(os.path.dirname(self.path), self.name + '.c3d')\n",
    "        self.markers = File(os.path.join(self.path,'markers_experimental.trc'))\n",
    "        self.grf = File(os.path.join(self.path,'Visual3d_SIMM_grf.mot'))\n",
    "        self.emg_csv = File(os.path.join(self.path,'processed_emg_signals.csv'))\n",
    "        self.emg = File(os.path.join(self.path,'processed_emg_signals.mot'))\n",
    "        self.ik = File(os.path.join(self.path,'Visual3d_SIMM_input.mot'))\n",
    "        self.id = File(os.path.join(self.path,'inverse_dynamics.sto'))\n",
    "        self.so_force = File(os.path.join(self.path,'Results_SO_and_MA', f'{self.subject}_StaticOptimization_force.sto'))\n",
    "        self.so_activation = File(os.path.join(self.path, 'Results_SO_and_MA', f'{self.subject}_StaticOptimization_activation.sto'))\n",
    "        self.jra = File(os.path.join(self.path,'joint_reacton_loads.sto'))\n",
    "        \n",
    "        # load muscle analysis files\n",
    "        self.ma_targets = ['_MomentArm_', '_Length.sto']\n",
    "        self.ma_files = []\n",
    "        try:\n",
    "            files = os.listdir(os.path.join(self.path, 'Results_SO_and_MA'))\n",
    "            for file in files:\n",
    "                if file.__contains__(self.ma_targets[0]) or file.__contains__(self.ma_targets[1]):\n",
    "                    self.ma_files.append(File(os.path.join(self.path, 'Results_SO_and_MA', file)))\n",
    "        except:\n",
    "            self.ma_files = None\n",
    "                    \n",
    "        # settings files\n",
    "        self.grf_xml = File(os.path.join(self.path,'GRF_Setup.xml'))\n",
    "        self.actuators_so = File(os.path.join(self.path,'actuators_SO.xml'))\n",
    "        \n",
    "        self.settings_json = File(os.path.join(self.path,'settings.json'))\n",
    "                             \n",
    "    def check_files(self):\n",
    "        '''\n",
    "        Output: True if all files exist, False if any file is missing\n",
    "        '''\n",
    "        files = self.__dict__.values()\n",
    "        all_files_exist = True\n",
    "        for file in files:\n",
    "            try:\n",
    "                if not os.path.isfile(file):\n",
    "                    print('File not found: ' + file)\n",
    "                    all_files_exist = False\n",
    "            except:\n",
    "                pass\n",
    "        return all_files_exist\n",
    "    \n",
    "    def header_mot(self,df,name):\n",
    "\n",
    "            num_rows = len(df)\n",
    "            num_cols = len(df.columns) \n",
    "            inital_time = df['Time'].iloc[0]\n",
    "            final_time = df['Time'].iloc[-1]\n",
    "            df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "            return f'name {name}\\n datacolumns {num_cols}\\n datarows {num_rows}\\n range {df_range} \\n endheader'\n",
    "        \n",
    "    def csv_to_mot(self):\n",
    "        \n",
    "        emg_data = msk.bops.pd.read_csv(self.emg_csv)\n",
    "\n",
    "        fs = int(1/(emg_data['time'][1] - emg_data['time'][0]))\n",
    "\n",
    "        time = emg_data['time']\n",
    "\n",
    "        # start time from new time point\n",
    "        start_time = time.iloc[0]\n",
    "        end_time = time.iloc[-1] - time.iloc[0] + start_time\n",
    "\n",
    "        num_samples = len(emg_data)\n",
    "        #num_samples = int((end_time - start_time) / (1/fs))\n",
    "        new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "        emg_data['time'] = new_time\n",
    "\n",
    "        # Define a new file path \n",
    "        new_file_path = os.path.join(self.emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "        # Save the modified DataFrame\n",
    "        emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "        # save to mot\n",
    "        header = self.header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "        mot_path = new_file_path.replace('.csv','.mot')\n",
    "        with open(mot_path, 'w') as f:\n",
    "            f.write(header + '\\n')  \n",
    "            # print column names \n",
    "            f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "            for index, row in emg_data.iterrows():\n",
    "                f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "        \n",
    "        print(f\"File saved: {mot_path}\")\n",
    "\n",
    "    def create_settings_json(self, overwrite=False):\n",
    "        if os.path.isfile(self.settings_json) and not overwrite:\n",
    "            print('settings.json already exists')\n",
    "            return\n",
    "        \n",
    "        settings_dict = self.__dict__\n",
    "        msk.bops.save_json_file(settings_dict, self.settings_json)\n",
    "        print('trial settings.json created in ' + self.path)\n",
    "    \n",
    "    def exportC3D(self):\n",
    "        msk.bops.c3d_osim_export(self.og_c3d) \n",
    "\n",
    "    def change_grf_xml_path(self):\n",
    "\n",
    "        try:\n",
    "            self.tree = ET.parse(self.grf_xml.path)\n",
    "            self.root = self.tree.getroot()\n",
    "            self.root.find('.//datafile').text = self.grf.path\n",
    "            \n",
    "            self.tree.write(self.grf_xml.path)\n",
    "            \n",
    "            print(f\"GRF file path updated in {self.grf_xml.path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading XML file: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_json_file(self, data, jsonFilePath):\n",
    "        data = data.__dict__\n",
    "\n",
    "        with open(jsonFilePath, 'w') as f:\n",
    "            msk.bops.json.dump(data, f, indent=4)\n",
    "\n",
    "        json_data = msk.bops.import_json_file(jsonFilePath)\n",
    "        return json_data\n",
    "    \n",
    "    def to_json(self):\n",
    "        msk.bops.save_json_file(self.__dict__, jsonFilePath = self.settings_json)\n",
    "        print('settings.json created in ' + self.settings_json)\n",
    "    \n",
    "    def run_IK(osim_modelPath, trc_file, resultsDir):\n",
    "        '''\n",
    "        Function to run Inverse Kinematics using the OpenSim API.\n",
    "        \n",
    "        Inputs:\n",
    "                osim_modelPath(str): path to the OpenSim model file\n",
    "                trc_file(str): path to the TRC file\n",
    "                resultsDir(str): path to the directory where the results will be saved\n",
    "        '''\n",
    "\n",
    "        # Load the TRC file\n",
    "        import pdb; pdb.set_trace()\n",
    "        tuple_data = msk.bops.import_trc_file(trc_file)\n",
    "        df = pd.DataFrame.from_records(tuple_data, columns=[x[0] for x in tuple_data])\n",
    "        column_names = [x[0] for x in tuple_data]\n",
    "        if len(set(column_names)) != len(column_names):\n",
    "            print(\"Error: Duplicate column names found.\")\n",
    "        # Load the model\n",
    "        osimModel = osim.Model(osim_modelPath)                              \n",
    "        state = osimModel.initSystem()\n",
    "\n",
    "        # Define the time range for the analysis\n",
    "        \n",
    "        initialTime = msk.TRCData.getIndependentColumn()\n",
    "        finalTime = msk.TRCData.getLastTime()\n",
    "\n",
    "        # Create the inverse kinematics tool\n",
    "        ikTool = osim.InverseKinematicsTool()\n",
    "        ikTool.setModel(osimModel)\n",
    "        ikTool.setStartTime(initialTime)\n",
    "        ikTool.setEndTime(finalTime)\n",
    "        ikTool.setMarkerDataFileName(trc_file)\n",
    "        ikTool.setResultsDir(resultsDir)\n",
    "        ikTool.set_accuracy(1e-6)\n",
    "        ikTool.setOutputMotionFileName(os.path.join(resultsDir, \"ik.mot\"))\n",
    "\n",
    "        # print setup\n",
    "        ikTool.printToXML(os.path.join(resultsDir, \"ik_setup.xml\"))         \n",
    "\n",
    "        # Run inverse kinematics\n",
    "        print(\"running ik...\")                                             \n",
    "        ikTool.run()\n",
    "\n",
    "    def run_inverse_kinematics(model_file, marker_file, output_motion_file):\n",
    "        # Load model and create an InverseKinematicsTool\n",
    "        model = osim.Model(model_file)\n",
    "        ik_tool = osim.InverseKinematicsTool()\n",
    "\n",
    "        # Set the model for the InverseKinematicsTool\n",
    "        ik_tool.setModel(model)\n",
    "\n",
    "        # Set the marker data file for the InverseKinematicsTool\n",
    "        ik_tool.setMarkerDataFileName(marker_file)\n",
    "\n",
    "        # Specify output motion file\n",
    "        ik_tool.setOutputMotionFileName(output_motion_file)\n",
    "\n",
    "        # Save setup file\n",
    "        ik_tool.printToXML('setup_ik.xml')\n",
    "\n",
    "        # Run Inverse Kinematics\n",
    "        ik_tool.run()\n",
    "\n",
    "    def run_ID(self, osim_modelPath, coordinates_file, external_loads_file, output_file, LowpassCutoffFrequency=6, run_tool=True):\n",
    "        \n",
    "        try: \n",
    "            model = osim.Model(osim_modelPath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {osim_modelPath}\")\n",
    "            print(e)\n",
    "            return\n",
    "        \n",
    "        results_folder = os.path.dirname(output_file)\n",
    "        \n",
    "        # Setup for excluding muscles from ID\n",
    "        exclude = osim.ArrayStr()\n",
    "        exclude.append(\"Muscles\")\n",
    "        # Setup for setting time range\n",
    "        IKData = osim.Storage(coordinates_file)\n",
    "\n",
    "        # Create inverse dynamics tool, set parameters and run\n",
    "        id_tool = osim.InverseDynamicsTool()\n",
    "        id_tool.setModel(model)\n",
    "        id_tool.setCoordinatesFileName(coordinates_file)\n",
    "        id_tool.setExternalLoadsFileName(external_loads_file)\n",
    "        id_tool.setOutputGenForceFileName(output_file)\n",
    "        id_tool.setLowpassCutoffFrequency(LowpassCutoffFrequency)\n",
    "        id_tool.setStartTime(IKData.getFirstTime())\n",
    "        id_tool.setEndTime(IKData.getLastTime())\n",
    "        id_tool.setExcludedForces(exclude)\n",
    "        id_tool.setResultsDir(results_folder)\n",
    "        id_tool.printToXML(os.path.join(results_folder, \"setup_ID.xml\"))\n",
    "        \n",
    "        if run_tool:\n",
    "            id_tool.run()\n",
    "    \n",
    "    def export_analog(self, c3dFilePath=None):\n",
    "        if not c3dFilePath:\n",
    "            print('C3D file path not provided')\n",
    "            return\n",
    "        \n",
    "        reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "        # get analog labels, trimmed and replace '.' with '_'\n",
    "        analog_labels = reader.analog_labels\n",
    "        analog_labels = [label.strip() for label in analog_labels]\n",
    "        analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "        # get analog labels, trimmed and replace '.' with '_'\n",
    "        fs = reader.analog_rate\n",
    "\n",
    "        # add time to dataframe\n",
    "        first_frame = reader.first_frame / fs\n",
    "        final_time = (reader.first_frame + reader.frame_count-1) / fs\n",
    "        time = msk.np.arange(first_frame / fs, final_time, 1 / fs)  \n",
    "        num_frames = len(time)\n",
    "        df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "        df['time'] = time\n",
    "\n",
    "        # move time to first column\n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        df = df[cols] \n",
    "\n",
    "        # loop through frames and add analog data to dataframe\n",
    "        for i_frame, points, analog in reader.read_frames():\n",
    "            \n",
    "            # get row number and print loading bar\n",
    "            i_row = i_frame - reader.first_frame\n",
    "            # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "            \n",
    "            # convert analog data to list\n",
    "            analog_list  = analog.data.tolist()\n",
    "            \n",
    "            # loop through analog channels and add to dataframe\n",
    "            for i_channel in range(len(analog_list)):\n",
    "                channel_name = analog_labels[i_channel]\n",
    "                \n",
    "                # add channel to dataframe\n",
    "                df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "                \n",
    "        # save emg data to csv\n",
    "        df.to_csv(self.emg_csv)\n",
    "        \n",
    "        # save to mot\n",
    "        #self.csv_to_mot()\n",
    "    \n",
    "class openSim:\n",
    "    def __init__(self, legs = ['r', 'l'], subjects =['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026'], trials_to_load = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3'], trial_number = 1):\n",
    "        try:\n",
    "            self.code_path = os.path.dirname(__file__)\n",
    "        except:\n",
    "            self.code_path = os.getcwd()\n",
    "        \n",
    "        self.simulations_path = os.path.join(os.path.dirname(self.code_path), 'Simulations')\n",
    "        self.subjects = {}\n",
    "        \n",
    "        for subject in subjects:\n",
    "            self.subjects[subject] = {}\n",
    "            self.subjects[subject]['model'] = os.path.join(self.simulations_path, subject, subject + '_scaled.osim')\n",
    "            for leg in legs: \n",
    "                for trial in trials_to_load:            \n",
    "                    self.trial_path = os.path.join(self.simulations_path, subject, f'{trial}_{leg}{trial_number}')\n",
    "                    try:\n",
    "                        trial = Trial(self.trial_path)\n",
    "                        self.subjects[subject][trial.name] = trial \n",
    "                    except Exception as e:\n",
    "                        self.subjects[subject][trial] =  None\n",
    "                        # print(f\"Error loading trial: {self.trial_path}\")\n",
    "                        # print(e)\n",
    "            \n",
    "        \n",
    "        self.ik_columns = [\"hip_flexion_leg\", \"hip_adduction_leg\", \"hip_rotation_leg\", \"knee_angle_leg\", \"ankle_angle_leg\"]\n",
    "        self.id_columns = [\"hip_flexion_leg\" + \"_moment\", \"hip_adduction_leg\" + \"_moment\", \"hip_rotation_leg\" + \"_moment\", \"knee_angle_leg\" + \"_moment\", \"ankle_angle_leg\" + \"_moment\"]\n",
    "        self.force_columns = [\"add_long_leg\", \"rect_fem_leg\", \"med_gas_leg\", \"semiten_leg\",\"tib_ant_leg\"]\n",
    "\n",
    "\n",
    "        self.titles = [\"Hip Flexion\", \"Hip Adduction\", \"Hip Rotation\", \"Knee Flexion\", \"Ankle Plantarflexion\"]\n",
    "        self.titles_muscles = [\"Adductor Longus\", \"Rectus Femoris\", \"Medial Gastrocnemius\", \"Semitendinosus\", \"Tibialis Anterior\"]\n",
    "\n",
    "    # Time Normalisation Function \n",
    "    def time_normalised_df(self, df, fs=None):\n",
    "        if not isinstance(df, msk.pd.DataFrame):\n",
    "            raise Exception('Input must be a pandas DataFrame')\n",
    "        \n",
    "        if not fs:\n",
    "            try:\n",
    "                fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "            except KeyError:\n",
    "                raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "            \n",
    "        normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        for column in df.columns:\n",
    "            if column == 'time':  # Skip time column\n",
    "                continue\t\n",
    "            normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "            currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "            timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "            Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "            normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "        return normalised_df\n",
    "\n",
    "    def plot_single_trial(self, show = False):\n",
    "        #Read .mot files\n",
    "        with open(self.mot_file, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the line where actual data starts (usually after 'endheader')\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"endheader\" in line:\n",
    "                start_row = i + 1  # Data starts after this line\n",
    "                break\n",
    "        else:\n",
    "            start_row = 0  # If 'endheader' is not found, assume no header\n",
    "\n",
    "        # Load data using Pandas\n",
    "        self.df_ik = msk.pd.read_csv(self.mot_file, delim_whitespace=True, start_row=start_row)\n",
    "        self.df_id = msk.pd.read_csv(self.id_file, sep=\"\\t\", start_row=6)\n",
    "        self.df_force = msk.pd.read_csv(self.force_file, sep=\"\\t\", start_row=14)\n",
    "\n",
    "        # Apply normalisation to both IK (angles) and ID (moments) data\n",
    "        self.df_ik_normalized = self.time_normalised_df(df=self.df_ik)\n",
    "        self.df_id_normalized = self.time_normalised_df(df=self.df_id)\n",
    "        self.df_force_normalized = self.time_normalised_df(df=self.df_force)\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)  \n",
    " \n",
    "        # select the specified columns         \n",
    "        self.ik_data = self.df_ik_normalized[self.ik_columns]\n",
    "        self.id_data = self.df_id_normalized[self.id_columns]\n",
    "        self.force_data = self.df_force_normalized[self.force_columns]\n",
    "            \n",
    "        # Define the layout \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(15, 4)) \n",
    "\n",
    "        #Plot IK (angles)\n",
    "        for i, col in enumerate(self.ik_columns):\n",
    "            ax = axes[0,i]\n",
    "            ax.plot(time_normalized, self.ik_data[col], color='red')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Angle (deg)\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        #Plot ID (moments)\n",
    "        for i, col in enumerate(self.id_columns):\n",
    "            ax = axes[1,i]\n",
    "            ax.plot(time_normalized, self.id_data[col], color='blue')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Moment (Nm)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        # PLOT MUSCLE FORCES \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 4), sharex=True)\n",
    "\n",
    "        for i, col in enumerate(self.force_columns):\n",
    "            ax = axes[i]\n",
    "            ax.plot(time_normalized, self.force_data[col], color='green')\n",
    "            ax.set_title(self.titles_muscles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Force (N)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_multiple_trials(self, show=False):\n",
    "        self.df_ik_list = []  # Store loaded DataFrames\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "            for trial in self.subjects[subject]:\n",
    "                trial_obj = self.subjects[subject][trial]\n",
    "                if trial_obj:\n",
    "                    self.df_ik_list.append(trial_obj.ik.data)\n",
    "                    \n",
    "        for file in self.mot_files:  # Loop through each file\n",
    "            with open(file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Load data using Pandas\n",
    "            df = msk.pd.read_csv(file, delim_whitespace=True, skiprows=5)\n",
    "            self.df_ik_list.append(df)\n",
    "\n",
    "        # Normalize all loaded IK data\n",
    "        self.df_ik_normalized_list = []  # Store normalized DataFrames\n",
    "\n",
    "        for df in self.df_ik_list:  # Loop through each loaded DataFrame\n",
    "            df_normalized = self.time_normalised_df(df=df)  # Apply normalization\n",
    "            self.df_ik_normalized_list.append(df_normalized)  # Store normalized DataFrame\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)\n",
    "\n",
    "        # Select the specified columns from normalized data\n",
    "        self.ik_data_list = []  # Store DataFrames with only the required columns\n",
    "\n",
    "        for df_normalized in self.df_ik_normalized_list:  # Loop through each normalized DataFrame\n",
    "            if set(self.ik_columns).issubset(df_normalized.columns):  # Check if columns exist\n",
    "                self.ik_data_list.append(df_normalized[self.ik_columns])  # Select only specified columns\n",
    "            else:\n",
    "                print(\"Warning: Some specified columns are missing in a file.\")\n",
    "\n",
    "        # Plot mean and sd\n",
    "        # Check if IK data exists\n",
    "        if not self.ik_data_list:\n",
    "            print(\"No IK data available to plot!\")\n",
    "        else:\n",
    "            # Convert list of DataFrames to a single NumPy array\n",
    "            combined_df = np.array([df.values for df in self.ik_data_list])  # Shape: (num_trials, num_timepoints, num_columns)\n",
    "\n",
    "            # Check if data is properly structured\n",
    "            if combined_df.shape[0] < 2:\n",
    "                print(\"Not enough trials to calculate mean and standard deviation!\")\n",
    "            else:\n",
    "                # Compute Mean and Standard Deviation\n",
    "                mean_values = np.mean(combined_df, axis=0)\n",
    "                std_values = np.std(combined_df, axis=0)\n",
    "\n",
    "                # Normalize time from 0 to 100% Gait Cycle\n",
    "                time_values = np.linspace(0, 100, combined_df.shape[1])\n",
    "\n",
    "                # Create a shared figure for all subplots\n",
    "                fig, axes = plt.subplots(nrows=1, ncols=len(self.ik_columns), figsize=(20, 5), sharex=True)\n",
    "\n",
    "                if len(self.ik_columns) == 1:\n",
    "                    axes = [axes]  # If only one column, ensure it's iterable\n",
    "\n",
    "                for i, col in enumerate(self.ik_columns):\n",
    "                    ax = axes[i]\n",
    "\n",
    "                    # Plot mean line\n",
    "                    ax.plot(time_values, mean_values[:, i], color='red', label=\"Mean\", linewidth=2)\n",
    "\n",
    "                    # Shade the standard deviation range\n",
    "                    ax.fill_between(time_values, mean_values[:, i] - std_values[:, i],\n",
    "                                    mean_values[:, i] + std_values[:, i], color='red', alpha=0.2, label=\"SD Range\")\n",
    "\n",
    "                    # Formatting\n",
    "                    ax.set_title(col)\n",
    "                    ax.set_xlabel(\"Gait Cycle (%)\")\n",
    "                    ax.set_xlim(0, 100)  # X-axis from 0% to 100% of the gait cycle\n",
    "                    ax.grid(True)\n",
    "\n",
    "                    # Set Y-label only for the first subplot\n",
    "                    if i == 0:\n",
    "                        ax.set_ylabel(\"Angle (Degrees)\")\n",
    "                        ax.legend()\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                if show:\n",
    "                    plt.show()\n",
    "\n",
    "def export_c3d(c3dFilePath):\n",
    "    analog_file_path = os.path.join(os.path.dirname(c3dFilePath),'analog.csv')\n",
    "    \n",
    "    # if the file already exists, return the file\n",
    "    if os.path.isfile(analog_file_path):\n",
    "        df = msk.pd.read_csv(analog_file_path)\n",
    "        return df\n",
    "    \n",
    "    print('Exporting analog data to csv ...')\n",
    "    \n",
    "    # read c3d file\n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    first_frame = reader.first_frame\n",
    "    num_frames = reader.frame_count\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    initial_time = first_frame / fs\n",
    "    final_time = (first_frame + num_frames-1) / fs\n",
    "    time = np.arange(first_frame / fs, final_time, 1 / fs) \n",
    "\n",
    "    df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "    df['time'] = time\n",
    "    \n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]    \n",
    "    \n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # convert analog data to list\n",
    "        analog_list  = analog.data.tolist()\n",
    "        \n",
    "        # loop through analog channels and add to dataframe\n",
    "        for i_channel in range(len(analog_list)):\n",
    "            channel_name = analog_labels[i_channel]\n",
    "            \n",
    "            # add channel to dataframe\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # save emg data to csv   \n",
    "    df.to_csv(analog_file_path)\n",
    "    print('analog.csv exported to ' + analog_file_path)  \n",
    "    \n",
    "    return df\n",
    "\n",
    "def export_analog(c3dFilePath=None, columns_to_mot='all'):\n",
    "    if not c3dFilePath:\n",
    "        print('C3D file path not provided')\n",
    "        return\n",
    "    \n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "    \n",
    "    # remove those not in columns_to_mot (fix: use column names to filter and get indices)\n",
    "    if columns_to_mot != 'all':\n",
    "        indices = [i for i, label in enumerate(analog_labels) if label in columns_to_mot]\n",
    "        analog_labels = [analog_labels[i] for i in indices]\n",
    "    else:\n",
    "        indices = list(range(len(analog_labels)))\n",
    "        columns_to_mot = analog_labels\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    first_time = reader.first_frame / fs\n",
    "    final_time = (reader.first_frame + reader.frame_count-1) / fs\n",
    "    time = msk.np.arange(first_time / fs, final_time, 1 / fs)  \n",
    "    num_frames = len(time)\n",
    "    df = msk.pd.DataFrame(index=range(num_frames), columns=analog_labels)\n",
    "    df['time'] = time\n",
    "\n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols] \n",
    "\n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # loop through selected analog channels and add to dataframe (fix: iterate over filtered indices)\n",
    "        for idx, i_channel in enumerate(indices):\n",
    "            channel_name = analog_labels[idx]\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # remove rows with NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # save emg data to csv\n",
    "    analog_csv_path = c3dFilePath.replace('.c3d', '_analog.csv')\n",
    "    df.to_csv(analog_csv_path, index=False)\n",
    "    \n",
    "    # save to mot\n",
    "    # self.csv_to_mot()\n",
    "    \n",
    "    return analog_csv_path\n",
    "\n",
    "def header_mot(df,name):\n",
    "\n",
    "        num_rows = len(df)\n",
    "        num_cols = len(df.columns) \n",
    "        inital_time = df['time'].iloc[0]\n",
    "        final_time = df['time'].iloc[-1]\n",
    "        df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "        return f'name {name}\\nnRows={num_rows}\\nnColumns={num_cols}\\n \\nendheader'\n",
    "\n",
    "def csv_to_mot(emg_csv):\n",
    "    \n",
    "    emg_data = msk.bops.pd.read_csv(emg_csv)\n",
    "    \n",
    "    time = emg_data['time']\n",
    "\n",
    "    # start time from new time point\n",
    "    start_time = time.iloc[0]\n",
    "    end_time = time.iloc[-1]\n",
    "\n",
    "    num_samples = len(emg_data)\n",
    "    new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "    emg_data['time'] = new_time\n",
    "\n",
    "    # Define a new file path \n",
    "    new_file_path = os.path.join(emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "    # Save the modified DataFrame\n",
    "    emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "    # save to mot\n",
    "    header = header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "    mot_path = new_file_path.replace('.csv','.mot')\n",
    "    with open(mot_path, 'w') as f:\n",
    "        f.write(header + '\\n')  \n",
    "        # print column names \n",
    "        f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "        for index, row in emg_data.iterrows():\n",
    "            f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "    \n",
    "    print(f\"File saved: {mot_path}\")\n",
    "    \n",
    "    return mot_path\n",
    "\n",
    "def time_normalised_df(df, fs=None):\n",
    "    if not isinstance(df, msk.pd.DataFrame):\n",
    "        raise Exception('Input must be a pandas DataFrame')\n",
    "    \n",
    "    if not fs:\n",
    "        try:\n",
    "            fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "        except KeyError:\n",
    "            raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "        \n",
    "    normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for column in df.columns:\n",
    "        normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "        currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "        timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "        Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "        normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "    return normalised_df\n",
    "\n",
    "def save_pretty_xml(tree, save_path):\n",
    "            \"\"\"Saves the XML tree to a file with proper indentation.\"\"\"\n",
    "            # Convert to string and format with proper indents\n",
    "            rough_string = ET.tostring(tree.getroot(), 'utf-8')\n",
    "            reparsed = xml.dom.minidom.parseString(rough_string)\n",
    "            pretty_xml = reparsed.toprettyxml(indent=\"   \")\n",
    "\n",
    "            # Write to file\n",
    "            with open(save_path, 'w') as file:\n",
    "                file.write(pretty_xml)\n",
    "\n",
    "def filter_emg(signal, sample_rate=1000, low_pass_cutoff=6):\n",
    "    \"\"\"\n",
    "    Processes EMG signal: clean, rectify, and filter to get the envelope.\n",
    "    \"\"\"\n",
    "    cleaned_signal = nk.emg_clean(signal, sampling_rate=sample_rate, method='biosppy')\n",
    "    rectified_signal = np.abs(cleaned_signal)\n",
    "    low_pass = low_pass_cutoff / (sample_rate / 2)\n",
    "    b, a = sig.butter(4, low_pass, btype='lowpass')\n",
    "    emg_envelope = sig.filtfilt(b, a, rectified_signal)\n",
    "    return emg_envelope\n",
    "\n",
    "def filter_emg_signals(csv_file, muscles, sample_rate=1000):\n",
    "    df = msk.pd.read_csv(csv_file)\n",
    "    filtered_data = {'time': df['time']}  # Add time column\n",
    "    \n",
    "    for muscle in muscles:\n",
    "        if muscle in df.columns:\n",
    "            filtered_data[muscle] = filter_emg(df[muscle].values, sample_rate)\n",
    "    \n",
    "    df_filtered = msk.pd.DataFrame(filtered_data)\n",
    "    \n",
    "    filtered_emg_path = csv_file.replace('.csv', '_filtered_emg.csv')\n",
    "    df_filtered.to_csv(filtered_emg_path, index=False)\n",
    "    \n",
    "    return filtered_emg_path\n",
    "\n",
    "def amplitude_normalise(processed_emg_path):\n",
    "    emg_data = pd.read_csv(processed_emg_path)\n",
    "    emg_data_normalised = emg_data.copy()\n",
    "    emg_data_normalised = emg_data_normalised.drop(columns=['time'])\n",
    "    \n",
    "    # normalise data\n",
    "    emg_data_normalised = emg_data_normalised / emg_data_normalised.max().max()\n",
    "    \n",
    "    # add time col back and move to first column\n",
    "    emg_data_normalised['time'] = emg_data['time']\n",
    "    cols = emg_data_normalised.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    emg_data_normalised = emg_data_normalised[cols]\n",
    "    \n",
    "    # save path \n",
    "    normalised_emg_path = processed_emg_path.replace('.csv', '_normalised.csv')\n",
    "    emg_data_normalised.to_csv(normalised_emg_path, index=False)\t\n",
    "    \n",
    "    return normalised_emg_path\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name coordinates for the respective leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik_columns = [\"hip_flexion_leg\", \"hip_adduction_leg\", \"hip_rotation_leg\", \"knee_angle_leg\", \"ankle_angle_leg\"]\n",
    "ik_columns = [col.replace('_leg', '_r') for col in ik_columns]\n",
    "ik_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert c3d files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: PC003\n",
      "Trial: trial1\n",
      "Folder already exists: C:/Git/opensim_tutorial/tutorials/repeated_sprinting/Simulations/PC003\\trial1_r1\n",
      "File saved: C:/Git/opensim_tutorial/tutorials/repeated_sprinting/Simulations/PC003/trial1_analog_filtered_emg_normalised.mot\n",
      "Folder already exists: C:/Git/opensim_tutorial/tutorials/repeated_sprinting/Simulations/PC003\\trial1_l1\n",
      "File saved: C:/Git/opensim_tutorial/tutorials/repeated_sprinting/Simulations/PC003/trial1_analog_filtered_emg_normalised.mot\n"
     ]
    }
   ],
   "source": [
    "c3dFilePath = msk.ui.select_file()\n",
    "\n",
    "subject = os.path.basename(os.path.dirname(c3dFilePath))\n",
    "trial_folder = os.path.basename(c3dFilePath).replace('.c3d','')\n",
    "\n",
    "print(f\"Subject: {subject}\")\n",
    "print(f\"Trial: {trial_folder}\")\n",
    "legs = ['r', 'l']\n",
    "\n",
    "for leg in legs:\n",
    "    leg_folder_name = trial_folder + f'_{leg}1'\n",
    "    leg_folder = os.path.join(os.path.dirname(c3dFilePath), leg_folder_name)\n",
    "    if not os.path.exists(leg_folder):\n",
    "        os.mkdir(leg_folder)\n",
    "        print(f\"Folder created: {leg_folder}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {leg_folder}\")\n",
    "        \n",
    "    if leg == 'r':\n",
    "        columns_to_mot = ['RGLTMED','RRF','RADDLONG','RBF','RTA','RGM']\n",
    "    else:\n",
    "        columns_to_mot = ['LGLTMED','LRF','LADDLONG','LBF','LTA','LGM'] \n",
    "    \n",
    "    \n",
    "    # Export analog data to csv\n",
    "    analog_csv_path = export_analog(c3dFilePath, columns_to_mot=columns_to_mot)\n",
    "    \n",
    "    # Process EMG signals\n",
    "    filtered_emg_path = filter_emg_signals(analog_csv_path, columns_to_mot)\n",
    "\n",
    "    # Normalise amplitude of EMG signals\n",
    "    normalised_emg_path = amplitude_normalise(filtered_emg_path)\n",
    "    \n",
    "    # convert to mot\n",
    "    emg_mot_path = csv_to_mot(normalised_emg_path)\n",
    "    \n",
    "    # move the file to the leg folder\n",
    "    want_it = True\n",
    "    if want_it:\n",
    "        # move the file to the folder\n",
    "        new_analog_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'analog_emg_signals.csv')\n",
    "        new_emg_mot_path = os.path.join(os_analysis.subjects[subject][leg_folder_name].path, 'processed_emg_signals.mot')\n",
    "\n",
    "        try:\n",
    "            shutil.move(analog_csv_path, new_analog_path)\n",
    "            shutil.move(emg_mot_path, new_emg_mot_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Git/opensim_tutorial/tutorials/repeated_sprinting/Simulations/PC003/trial1_analog.csv\n"
     ]
    }
   ],
   "source": [
    "analog_csv_path = export_analog(c3dFilePath, columns_to_mot=columns_to_mot)\n",
    "print(analog_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start all files from Zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = trial_folder + '_r1'\n",
    "os_analysis.subjects[subject][trial_name].emg_csv.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_l1'\n",
    "data = os_analysis.subjects[subject][trial_name].emg_csv.data\n",
    "if data is None:\n",
    "    print(f\"EMG data for subject {subject}, trial {trial_name} is not loaded correctly.\")\n",
    "else:\n",
    "    print(\"EMG data loaded successfully.\")\n",
    "data['time'] = data['time'] - data['time'].iloc[0]\n",
    "data.to_csv(os_analysis.subjects[subject][trial_name].emg_csv, index=False)\n",
    "\n",
    "csv_to_mot(os_analysis.subjects[subject][trial_name].emg_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check times in all files for simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "\n",
    "# clear output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.18 3.6\n",
      "3.18 3.6\n",
      "0.1578 7.047800000000006\n",
      "c:\\Git\\opensim_tutorial\\tutorials\\repeated_sprinting\\Simulations\\PC003\\trial1_l1\\processed_emg_signals.mot\n"
     ]
    }
   ],
   "source": [
    "subject = 'PC003'\n",
    "trial_name = 'trial1_l1'\n",
    "\n",
    "# Define relative paths to the files\n",
    "id_file = os_analysis.subjects[subject][trial_name].id.path\n",
    "ik_file = os_analysis.subjects[subject][trial_name].ik.path\n",
    "emg_file = os_analysis.subjects[subject][trial_name].emg.path\n",
    "\n",
    "# Load the files into Pandas DataFrames\n",
    "id_df = pd.read_csv(id_file, sep=\"\\t\", skiprows=6)  \n",
    "ik_df = pd.read_csv(ik_file, sep=\"\\t\", skiprows=5)\n",
    "emg_df = pd.read_csv(emg_file, sep=\"\\t\", skiprows=5) \n",
    "\n",
    "# Extract the time columns\n",
    "id_time = id_df['time'] if 'time' in id_df.columns else id_df.iloc[:, 0]\n",
    "ik_time = ik_df['time'] if 'time' in ik_df.columns else ik_df.iloc[:, 0]\n",
    "emg_time = emg_df['time'] if 'time' in emg_df.columns else emg_df.iloc[:, 0]\n",
    "\n",
    "print(id_time[0], id_time[len(id_time)-1])\n",
    "print(ik_time[0], ik_time[len(ik_time)-1])\n",
    "print(emg_time[0], emg_time[len(emg_time)-1])\n",
    "\n",
    "print(str(emg_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time columns to float, handling any non-numeric values\n",
    "def convert_to_numeric(series):\n",
    "    return pd.to_numeric(series, errors='coerce').dropna()  # Convert and drop NaNs\n",
    "\n",
    "id_time = convert_to_numeric(id_time)\n",
    "ik_time = convert_to_numeric(ik_time)\n",
    "emg_time = convert_to_numeric(emg_time)\n",
    "\n",
    "# Combine time values into a set to remove duplicates\n",
    "unique_times = sorted(set(id_time).union(set(ik_time), set(emg_time)))\n",
    "\n",
    "# Convert to numpy array\n",
    "unique_time_array = np.array(unique_times)\n",
    "\n",
    "# Create a base DataFrame with unique_time_array as the time column\n",
    "new_df = pd.DataFrame({'time': unique_time_array})\n",
    "\n",
    "# Merge with id_df, ik_df, and emg_df using left join on 'time' column\n",
    "new_id_df = new_df.merge(id_df, on='time', how='left')\n",
    "new_ik_df = new_df.merge(ik_df, on='time', how='left')\n",
    "new_emg_df = new_df.merge(emg_df, on='time', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "def fill_nan_values(*dfs):\n",
    "    return [df.fillna(0) for df in dfs]\n",
    "\n",
    "new_id_df, new_ik_df, new_emg_df = fill_nan_values(new_id_df, new_ik_df, new_emg_df)\n",
    "\n",
    "# Save the synchronized DataFrames\n",
    "def save_files(base_path, id_df, ik_df, emg_df):\n",
    "    id_path = os.path.join(base_path, \"inverse_dynamics_synced.sto\")\n",
    "    ik_path = os.path.join(base_path, \"Visual3d_SIMM_input_synced.mot\")\n",
    "    emg_path = os.path.join(base_path, \"processed_emg_signals_synced.csv\")\n",
    "    \n",
    "    # Save EMG DataFrame as CSV\n",
    "    emg_df.to_csv(emg_path, index=False)\n",
    "    \n",
    "    # Save ID DataFrame as .sto\n",
    "    with open(id_path, 'w') as f:\n",
    "        f.write(\"inverse dynamics data\\nversion=1\\nnRows={}\\nnColumns={}\\ninDegrees=yes\\nendheader\\n\".format(len(id_df), len(id_df.columns)))\n",
    "        id_df.to_csv(f, sep='\\t', index=False)\n",
    "    \n",
    "    # Save IK DataFrame as .mot\n",
    "    with open(ik_path, 'w') as f:\n",
    "        f.write(\"Coordinates\\nversion=1\\nnRows={}\\nnColumns={}\\ninDegrees=yes\\nendheader\\n\".format(len(ik_df), len(ik_df.columns)))\n",
    "        ik_df.to_csv(f, sep='\\t', index=False)\n",
    "    \n",
    "    print(f\"Files saved:\\n{id_path}\\n{ik_path}\\n{emg_path}\")\n",
    "\n",
    "# Define the base path where the files will be saved\n",
    "base_path = os.path.join(one_dir_up, \"Simulations\", \"PC002\", \"trial2_r1\")\n",
    "\n",
    "# Save the synchronized DataFrames\n",
    "save_files(base_path, new_id_df, new_ik_df, new_emg_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list:\n",
    "    trial_list = os_analysis.subjects[subject].keys()\n",
    "    for trial in trial_list:\n",
    "        try:\n",
    "            os_analysis.subjects[subject][trial].change_grf_xml_path()\n",
    "            os_analysis.subjects[subject][trial].run_ID(osim_modelPath=os_analysis.subjects[subject]['model'], \n",
    "                                                            coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "                                                            output_file=os_analysis.subjects[subject][trial].id.path, \n",
    "                                                            external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "                                                            LowpassCutoffFrequency=6, \n",
    "                                                            run_tool=True)\n",
    "            \n",
    "            print(f\"ID ran successfully for {subject} - {trial}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running ID for {subject} - {trial}\")\n",
    "            print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_SO(model_path, coordinates_file, actuators_file_path, run_tool=True):\n",
    "    '''\n",
    "    Function to run Static Optimization using the OpenSim API.\n",
    "    \n",
    "    Inputs:\n",
    "            modelpath(str): path to the OpenSim model file\n",
    "            trialpath(str): path to the trial folder\n",
    "            actuators_file_path(str): path to the actuators file\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    trialpath = os.path.dirname(coordinates_file)   \n",
    "    # create directories\n",
    "    results_directory = os.path.relpath(trialpath, trialpath)\n",
    "    coordinates_file =  os.path.relpath(trialpath, coordinates_file)\n",
    "    modelpath_relative = os.path.relpath(model_path, trialpath)\n",
    "\n",
    "    # create a local copy of the actuator file path and update name\n",
    "    actuators_file_path = os.path.relpath(actuators_file_path, trialpath)\n",
    "\n",
    "    # start model\n",
    "    OsimModel = msk.osim.Model(modelpath_relative)\n",
    "\n",
    "    # Get mot data to determine time range\n",
    "    motData = msk.osim.Storage(coordinates_file)\n",
    "\n",
    "    # Get initial and intial time\n",
    "    initial_time = motData.getFirstTime()\n",
    "    final_time = motData.getLastTime()\n",
    "\n",
    "    # Static Optimization\n",
    "    so = msk.osim.StaticOptimization()\n",
    "    so.setName('StaticOptimization')\n",
    "    so.setModel(OsimModel)\n",
    "\n",
    "    # Set other parameters as needed\n",
    "    so.setStartTime(initial_time)\n",
    "    so.setEndTime(final_time)\n",
    "    so.setMaxIterations(25)\n",
    "\n",
    "    analyzeTool_SO = msk.classes.osimSetup.create_analysis_tool(coordinates_file,modelpath_relative,results_directory)\n",
    "    analyzeTool_SO.getAnalysisSet().cloneAndAppend(so)\n",
    "    analyzeTool_SO.getForceSetFiles().append(actuators_file_path)\n",
    "    analyzeTool_SO.setReplaceForceSet(False)\n",
    "    OsimModel.addAnalysis(so)\n",
    "\n",
    "    analyzeTool_SO.printToXML(\".\\setup_so.xml\")\n",
    "\n",
    "    analyzeTool_SO = msk.osim.AnalyzeTool(\".\\setup_so.xml\")\n",
    "\n",
    "    trial = os.path.basename(trialpath)\n",
    "    print(f\"so for {trial}\")\n",
    "\n",
    "    # run\n",
    "    if run_tool:\n",
    "        analyzeTool_SO.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_SO(model_path=os_analysis.subjects[subject]['model'], \n",
    "        coordinates_file=os_analysis.subjects[subject][trial].ik.path, \n",
    "        actuators_file_path=os_analysis.subjects[subject][trial].id.path, \n",
    "        external_loads_file=os_analysis.subjects[subject][trial].grf_xml.path, \n",
    "        LowpassCutoffFrequency=6, \n",
    "        run_tool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print trial to Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFilePath = os.path.join(os_analysis.simulations_path, 'PC002', 'trial2_r1', 'settings.json')\n",
    "trial = Trial(os.path.join(os_analysis.simulations_path, 'PC002', 'trial2_r1'))\n",
    "trial.__dict__['jra'].__dict__\n",
    "\n",
    "data = trial.__dict__\n",
    "print(trial.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_SO(model_path=os_analysis.subjects['PC002']['model'],\n",
    "        coordinates_file = os_analysis.subjects['PC002']['trial2'].ik.path,\n",
    "        actuators_file_path = os_analysis.subjects['PC002']['trial2'].so_force.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEINMS calibration run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msk_modelling_python as msk\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'PC002'\n",
    "trial_name = 'trial2_r1'\n",
    "subject_list = ['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026']\n",
    "trial_list = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3']\n",
    "os_analysis = openSim(legs=['r','l'], subjects=subject_list, trials_to_load=trial_list, trial_number=1)\n",
    "#check times\n",
    "print(os_analysis.subjects[subject][trial_name].ik.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].id.time_range)\n",
    "print(os_analysis.subjects[subject][trial_name].emg.time_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.getcwd()\n",
    "xml_setup_file = os.path.join(os.path.dirname(code_path), 'Simulations', subject, trial_name, 'ceinms', 'calibrationSetup.xml')\n",
    "ceinms_install_path = os.path.join(msk.__path__[0], 'src', 'ceinms2', 'src')\n",
    "command = \" \".join([ceinms_install_path + \"\\CEINMScalibrate.exe -S\", xml_setup_file])\n",
    "print(str(command))\n",
    "#print(os.getcwd())\n",
    "result = subprocess.run(command, capture_output=True, text=True, check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msk_modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
